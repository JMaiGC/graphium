# This is a base shape file encoded in yaml
# - `null` indicates a dimension is "finite", i.e. a non-"width" dimension
# - a number indicates the base dimension of an "infinite" dimension, i.e. some notion of "width"
encoder_manager.pe_encoders.gaussian_pos.preprocess_3d_positions.gaussian.means.weight:
- null
- 32
encoder_manager.pe_encoders.gaussian_pos.preprocess_3d_positions.gaussian.stds.weight:
- null
- 32
encoder_manager.pe_encoders.gaussian_pos.preprocess_3d_positions.gaussian_proj.fully_connected.0.linear.bias:
- null
encoder_manager.pe_encoders.gaussian_pos.preprocess_3d_positions.gaussian_proj.fully_connected.0.linear.weight:
- null
- 32
encoder_manager.pe_encoders.gaussian_pos.preprocess_3d_positions.node_proj.bias:
- 32
encoder_manager.pe_encoders.gaussian_pos.preprocess_3d_positions.node_proj.weight:
- 32
- 32
encoder_manager.pe_encoders.la_pos.linear_in.linear.bias:
- 32
encoder_manager.pe_encoders.la_pos.linear_in.linear.weight:
- 32
- null
encoder_manager.pe_encoders.la_pos.pe_encoder.fully_connected.0.linear.bias:
- 32
encoder_manager.pe_encoders.la_pos.pe_encoder.fully_connected.0.linear.weight:
- 32
- 32
encoder_manager.pe_encoders.rw_pos.first_normalization.bias:
- null
encoder_manager.pe_encoders.rw_pos.first_normalization.weight:
- null
encoder_manager.pe_encoders.rw_pos.pe_encoder.first_normalization.bias:
- null
encoder_manager.pe_encoders.rw_pos.pe_encoder.first_normalization.weight:
- null
encoder_manager.pe_encoders.rw_pos.pe_encoder.fully_connected.0.linear.bias:
- 32
encoder_manager.pe_encoders.rw_pos.pe_encoder.fully_connected.0.linear.weight:
- 32
- null
gnn.layers.0.attn_layer.in_proj_bias:
- 96
gnn.layers.0.attn_layer.in_proj_weight:
- 96
- 32
gnn.layers.0.attn_layer.out_proj.bias:
- 32
gnn.layers.0.attn_layer.out_proj.weight:
- 32
- 32
gnn.layers.0.f_out.linear.bias:
- 32
gnn.layers.0.f_out.linear.weight:
- 32
- 32
gnn.layers.0.f_out.normalization.bias:
- 32
gnn.layers.0.f_out.normalization.weight:
- 32
gnn.layers.0.mlp.fully_connected.0.linear.bias:
- 64
gnn.layers.0.mlp.fully_connected.0.linear.weight:
- 64
- 32
gnn.layers.0.mlp.fully_connected.1.linear.bias:
- 32
gnn.layers.0.mlp.fully_connected.1.linear.weight:
- 32
- 64
gnn.layers.0.ff_out.linear.bias:
- 32
gnn.layers.0.ff_out.linear.weight:
- 32
- 32
gnn.layers.0.mpnn.edge_model.fully_connected.0.linear.bias:
- null
gnn.layers.0.mpnn.edge_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.0.mpnn.edge_model.fully_connected.0.normalization.bias:
- null
gnn.layers.0.mpnn.edge_model.fully_connected.0.normalization.weight:
- null
gnn.layers.0.mpnn.edge_model.fully_connected.1.linear.bias:
- null
gnn.layers.0.mpnn.edge_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.0.mpnn.node_model.fully_connected.0.linear.bias:
- null
gnn.layers.0.mpnn.node_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.0.mpnn.node_model.fully_connected.0.normalization.bias:
- null
gnn.layers.0.mpnn.node_model.fully_connected.0.normalization.weight:
- null
gnn.layers.0.mpnn.node_model.fully_connected.1.linear.bias:
- null
gnn.layers.0.mpnn.node_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.0.mpnn.norm_layer.bias:
- null
gnn.layers.0.mpnn.norm_layer.weight:
- null
gnn.layers.1.attn_layer.in_proj_bias:
- 96
gnn.layers.1.attn_layer.in_proj_weight:
- 96
- 32
gnn.layers.1.attn_layer.out_proj.bias:
- 32
gnn.layers.1.attn_layer.out_proj.weight:
- 32
- 32
gnn.layers.1.ff_linear1.linear.bias:
- 64
gnn.layers.1.ff_linear1.linear.weight:
- 64
- 32
gnn.layers.1.ff_linear2.linear.bias:
- 32
gnn.layers.1.ff_linear2.linear.weight:
- 32
- 64
gnn.layers.1.ff_out.linear.bias:
- 32
gnn.layers.1.ff_out.linear.weight:
- 32
- 32
gnn.layers.1.mpnn.edge_model.fully_connected.0.linear.bias:
- null
gnn.layers.1.mpnn.edge_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.1.mpnn.edge_model.fully_connected.0.normalization.bias:
- null
gnn.layers.1.mpnn.edge_model.fully_connected.0.normalization.weight:
- null
gnn.layers.1.mpnn.edge_model.fully_connected.1.linear.bias:
- null
gnn.layers.1.mpnn.edge_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.1.mpnn.node_model.fully_connected.0.linear.bias:
- null
gnn.layers.1.mpnn.node_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.1.mpnn.node_model.fully_connected.0.normalization.bias:
- null
gnn.layers.1.mpnn.node_model.fully_connected.0.normalization.weight:
- null
gnn.layers.1.mpnn.node_model.fully_connected.1.linear.bias:
- null
gnn.layers.1.mpnn.node_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.1.mpnn.norm_layer.bias:
- null
gnn.layers.1.mpnn.norm_layer.weight:
- null
gnn.layers.2.attn_layer.in_proj_bias:
- 96
gnn.layers.2.attn_layer.in_proj_weight:
- 96
- 32
gnn.layers.2.attn_layer.out_proj.bias:
- 32
gnn.layers.2.attn_layer.out_proj.weight:
- 32
- 32
gnn.layers.2.ff_linear1.linear.bias:
- 64
gnn.layers.2.ff_linear1.linear.weight:
- 64
- 32
gnn.layers.2.ff_linear2.linear.bias:
- 32
gnn.layers.2.ff_linear2.linear.weight:
- 32
- 64
gnn.layers.2.ff_out.linear.bias:
- 32
gnn.layers.2.ff_out.linear.weight:
- 32
- 32
gnn.layers.2.mpnn.edge_model.fully_connected.0.linear.bias:
- null
gnn.layers.2.mpnn.edge_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.2.mpnn.edge_model.fully_connected.0.normalization.bias:
- null
gnn.layers.2.mpnn.edge_model.fully_connected.0.normalization.weight:
- null
gnn.layers.2.mpnn.edge_model.fully_connected.1.linear.bias:
- null
gnn.layers.2.mpnn.edge_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.2.mpnn.node_model.fully_connected.0.linear.bias:
- null
gnn.layers.2.mpnn.node_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.2.mpnn.node_model.fully_connected.0.normalization.bias:
- null
gnn.layers.2.mpnn.node_model.fully_connected.0.normalization.weight:
- null
gnn.layers.2.mpnn.node_model.fully_connected.1.linear.bias:
- null
gnn.layers.2.mpnn.node_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.2.mpnn.norm_layer.bias:
- null
gnn.layers.2.mpnn.norm_layer.weight:
- null
gnn.layers.3.attn_layer.in_proj_bias:
- 96
gnn.layers.3.attn_layer.in_proj_weight:
- 96
- 32
gnn.layers.3.attn_layer.out_proj.bias:
- 32
gnn.layers.3.attn_layer.out_proj.weight:
- 32
- 32
gnn.layers.3.ff_linear1.linear.bias:
- 64
gnn.layers.3.ff_linear1.linear.weight:
- 64
- 32
gnn.layers.3.ff_linear2.linear.bias:
- 32
gnn.layers.3.ff_linear2.linear.weight:
- 32
- 64
gnn.layers.3.ff_out.linear.bias:
- 32
gnn.layers.3.ff_out.linear.weight:
- 32
- 32
gnn.layers.3.mpnn.edge_model.fully_connected.0.linear.bias:
- null
gnn.layers.3.mpnn.edge_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.3.mpnn.edge_model.fully_connected.0.normalization.bias:
- null
gnn.layers.3.mpnn.edge_model.fully_connected.0.normalization.weight:
- null
gnn.layers.3.mpnn.edge_model.fully_connected.1.linear.bias:
- null
gnn.layers.3.mpnn.edge_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.3.mpnn.node_model.fully_connected.0.linear.bias:
- null
gnn.layers.3.mpnn.node_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.3.mpnn.node_model.fully_connected.0.normalization.bias:
- null
gnn.layers.3.mpnn.node_model.fully_connected.0.normalization.weight:
- null
gnn.layers.3.mpnn.node_model.fully_connected.1.linear.bias:
- null
gnn.layers.3.mpnn.node_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.3.mpnn.norm_layer.bias:
- null
gnn.layers.3.mpnn.norm_layer.weight:
- null
gnn.out_linear.linear.bias:
- 32
gnn.out_linear.linear.weight:
- 32
- 32
gnn.out_linear.normalization.bias:
- 32
gnn.out_linear.normalization.weight:
- 32
post_nn.layers.0.linear.bias:
- 200
post_nn.layers.0.linear.weight:
- 200
- 32
post_nn.layers.0.normalization.bias:
- 200
post_nn.layers.0.normalization.weight:
- 200
post_nn.layers.1.linear.bias:
- 16
post_nn.layers.1.linear.weight:
- 16
- 200
pre_nn.layers.0.linear.bias:
- 32
pre_nn.layers.0.linear.weight:
- 32
- 87
pre_nn.layers.0.normalization.bias:
- 32
pre_nn.layers.0.normalization.weight:
- 32
pre_nn_edges.layers.0.linear.bias:
- 16
pre_nn_edges.layers.0.linear.weight:
- 16
- null
pre_nn_edges.layers.0.normalization.bias:
- 16
pre_nn_edges.layers.0.normalization.weight:
- 16
task_heads.task_heads.homo.layers.0.linear.bias:
- 16
task_heads.task_heads.homo.layers.0.linear.weight:
- 16
- 16
task_heads.task_heads.homo.layers.0.normalization.bias:
- 16
task_heads.task_heads.homo.layers.0.normalization.weight:
- 16
task_heads.task_heads.homo.layers.1.linear.bias:
- 0
task_heads.task_heads.homo.layers.1.linear.weight:
- 0
- 16
