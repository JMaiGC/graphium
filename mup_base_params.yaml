# This is a base shape file encoded in yaml
# - `null` indicates a dimension is "finite", i.e. a non-"width" dimension
# - a number indicates the base dimension of an "infinite" dimension, i.e. some notion of "width"
gnn.layers.0.f_out.linear.bias:
- 128
gnn.layers.0.f_out.linear.weight:
- 128
- 128
gnn.layers.0.f_out.normalization.bias:
- 128
gnn.layers.0.f_out.normalization.weight:
- 128
gnn.layers.0.mlp.fully_connected.0.linear.bias:
- 512
gnn.layers.0.mlp.fully_connected.0.linear.weight:
- 512
- 128
gnn.layers.0.mlp.fully_connected.1.linear.bias:
- 128
gnn.layers.0.mlp.fully_connected.1.linear.weight:
- 128
- 512
gnn.layers.0.mpnn.edge_model.fully_connected.0.linear.bias:
- null
gnn.layers.0.mpnn.edge_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.0.mpnn.edge_model.fully_connected.1.linear.bias:
- null
gnn.layers.0.mpnn.edge_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.0.mpnn.node_model.fully_connected.0.linear.bias:
- null
gnn.layers.0.mpnn.node_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.0.mpnn.node_model.fully_connected.1.linear.bias:
- null
gnn.layers.0.mpnn.node_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.1.f_out.linear.bias:
- 128
gnn.layers.1.f_out.linear.weight:
- 128
- 128
gnn.layers.1.f_out.normalization.bias:
- 128
gnn.layers.1.f_out.normalization.weight:
- 128
gnn.layers.1.mlp.fully_connected.0.linear.bias:
- 512
gnn.layers.1.mlp.fully_connected.0.linear.weight:
- 512
- 128
gnn.layers.1.mlp.fully_connected.1.linear.bias:
- 128
gnn.layers.1.mlp.fully_connected.1.linear.weight:
- 128
- 512
gnn.layers.1.mpnn.edge_model.fully_connected.0.linear.bias:
- null
gnn.layers.1.mpnn.edge_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.1.mpnn.edge_model.fully_connected.1.linear.bias:
- null
gnn.layers.1.mpnn.edge_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.1.mpnn.node_model.fully_connected.0.linear.bias:
- null
gnn.layers.1.mpnn.node_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.1.mpnn.node_model.fully_connected.1.linear.bias:
- null
gnn.layers.1.mpnn.node_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.2.f_out.linear.bias:
- 128
gnn.layers.2.f_out.linear.weight:
- 128
- 128
gnn.layers.2.f_out.normalization.bias:
- 128
gnn.layers.2.f_out.normalization.weight:
- 128
gnn.layers.2.mlp.fully_connected.0.linear.bias:
- 512
gnn.layers.2.mlp.fully_connected.0.linear.weight:
- 512
- 128
gnn.layers.2.mlp.fully_connected.1.linear.bias:
- 128
gnn.layers.2.mlp.fully_connected.1.linear.weight:
- 128
- 512
gnn.layers.2.mpnn.edge_model.fully_connected.0.linear.bias:
- null
gnn.layers.2.mpnn.edge_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.2.mpnn.edge_model.fully_connected.1.linear.bias:
- null
gnn.layers.2.mpnn.edge_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.2.mpnn.node_model.fully_connected.0.linear.bias:
- null
gnn.layers.2.mpnn.node_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.2.mpnn.node_model.fully_connected.1.linear.bias:
- null
gnn.layers.2.mpnn.node_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.3.f_out.linear.bias:
- 128
gnn.layers.3.f_out.linear.weight:
- 128
- 128
gnn.layers.3.f_out.normalization.bias:
- 128
gnn.layers.3.f_out.normalization.weight:
- 128
gnn.layers.3.mlp.fully_connected.0.linear.bias:
- 512
gnn.layers.3.mlp.fully_connected.0.linear.weight:
- 512
- 128
gnn.layers.3.mlp.fully_connected.1.linear.bias:
- 128
gnn.layers.3.mlp.fully_connected.1.linear.weight:
- 128
- 512
gnn.layers.3.mpnn.edge_model.fully_connected.0.linear.bias:
- null
gnn.layers.3.mpnn.edge_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.3.mpnn.edge_model.fully_connected.1.linear.bias:
- null
gnn.layers.3.mpnn.edge_model.fully_connected.1.linear.weight:
- null
- null
gnn.layers.3.mpnn.node_model.fully_connected.0.linear.bias:
- null
gnn.layers.3.mpnn.node_model.fully_connected.0.linear.weight:
- null
- null
gnn.layers.3.mpnn.node_model.fully_connected.1.linear.bias:
- null
gnn.layers.3.mpnn.node_model.fully_connected.1.linear.weight:
- null
- null
gnn.out_linear.linear.bias:
- 128
gnn.out_linear.linear.weight:
- 128
- 128
gnn.out_linear.normalization.bias:
- 128
gnn.out_linear.normalization.weight:
- 128
pe_encoders.la_pos.linear_A.linear.bias:
- null
pe_encoders.la_pos.linear_A.linear.weight:
- null
- null
pe_encoders.la_pos.pe_encoder.fully_connected.0.linear.bias:
- 50
pe_encoders.la_pos.pe_encoder.fully_connected.0.linear.weight:
- 50
- null
pe_encoders.rw_pos.pe_encoder.first_normalization.bias:
- null
pe_encoders.rw_pos.pe_encoder.first_normalization.weight:
- null
pe_encoders.rw_pos.pe_encoder.fully_connected.0.linear.bias:
- 50
pe_encoders.rw_pos.pe_encoder.fully_connected.0.linear.weight:
- 50
- null
pre_nn.layers.0.linear.bias:
- 128
pre_nn.layers.0.linear.weight:
- 128
- 105
pre_nn.layers.0.normalization.bias:
- 128
pre_nn.layers.0.normalization.weight:
- 128
pre_nn_edges.layers.0.linear.bias:
- 64
pre_nn_edges.layers.0.linear.weight:
- 64
- null
pre_nn_edges.layers.0.normalization.bias:
- 64
pre_nn_edges.layers.0.normalization.weight:
- 64
task_heads.task_heads.homolumo.layers.0.linear.bias:
- 16
task_heads.task_heads.homolumo.layers.0.linear.weight:
- 16
- 128
task_heads.task_heads.homolumo.layers.0.normalization.bias:
- 16
task_heads.task_heads.homolumo.layers.0.normalization.weight:
- 16
task_heads.task_heads.homolumo.layers.1.linear.bias:
- 0
task_heads.task_heads.homolumo.layers.1.linear.weight:
- 0
- 16
