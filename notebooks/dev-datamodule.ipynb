{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pathlib\n",
    "import functools\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import datamol as dm\n",
    "\n",
    "import goli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goli data modules\n",
    "    \n",
    "- All the below config are primitive types and can be easily embeded in a YAML config file.\n",
    "- Loading a datamodule should not require `config_load_dataset` and ideally would only require `goli.data.DGLFromSmilesDataModule(**dm_args)`.\n",
    "- At the moment we only have a single datamodule but we'll likely have others in the future. In that case we could eventually have a `config_load_dataset` that just select the appropriate data module.\n",
    "\n",
    "Here is a config (only for the data) that is similar to the current one in `goli/expts/config_micro_ZINC.yaml` but adjusted to be used directly with `DGLFromSmilesDataModule`:\n",
    "\n",
    "```yaml\n",
    "data:\n",
    "  module_type: \"DGLFromSmilesDataModule\"\n",
    "  args:\n",
    "    df_path: null  # could be set from the CLI. Ideally config files does not have paths.\n",
    "    cache_data_path: null  # could be set from the CLI. Ideally config files does not have paths.\n",
    "  \n",
    "    smiles_col: \"SMILES\"\n",
    "    label_cols: [\"SA\"]\n",
    "    split_val: 0.2\n",
    "    split_test: 0.2\n",
    "    split_seed: 19\n",
    "  \n",
    "    train_val_batch_size: 16\n",
    "    test_batch_size: 16\n",
    "  \n",
    "    featurization:\n",
    "      atom_property_list_float: []\n",
    "      atom_property_list_onehot: [\"atomic-number\", \"degree\"]\n",
    "      edge_property_list: [\"ring\", \"bond-type-onehot\"]\n",
    "      add_self_loop: false\n",
    "      use_bonds_weights: false\n",
    "      explicit_H: false\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<goli.data.datamodule.DGLFromSmilesDataModule at 0x7fde503dae80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup a temporary cache file. Only for\n",
    "# demo purposes, use a known path in prod.\n",
    "cache_data_path = pathlib.Path(tempfile.mkdtemp()) / \"cache.pkl\"\n",
    "\n",
    "# Load a dataframe\n",
    "df = goli.data.load_tiny_zinc()\n",
    "df.head()\n",
    "\n",
    "# Setup the featurization\n",
    "featurization_args = {}\n",
    "featurization_args[\"atom_property_list_float\"] = []  # [\"weight\", \"valence\"]\n",
    "featurization_args[\"atom_property_list_onehot\"] = [\"atomic-number\", \"degree\"]\n",
    "featurization_args[\"edge_property_list\"] = [\"ring\", \"bond-type-onehot\"]\n",
    "featurization_args[\"add_self_loop\"] = False\n",
    "featurization_args[\"use_bonds_weights\"] = False\n",
    "featurization_args[\"explicit_H\"] = False\n",
    "\n",
    "# Config for datamodule\n",
    "dm_args = {}\n",
    "dm_args[\"df\"] = df\n",
    "dm_args[\"cache_data_path\"] = None#cache_data_path  # unsed at the moment\n",
    "dm_args[\"featurization\"] = featurization_args\n",
    "dm_args[\"smiles_col\"] = \"SMILES\"\n",
    "dm_args[\"label_cols\"] = [\"SA\"]\n",
    "dm_args[\"split_val\"] = 0.2\n",
    "dm_args[\"split_test\"] = 0.2\n",
    "dm_args[\"split_seed\"] = 19\n",
    "dm_args[\"train_val_batch_size\"] = 16\n",
    "dm_args[\"test_batch_size\"] = 16\n",
    "dm_args[\"num_workers\"] = 0\n",
    "dm_args[\"pin_memory\"] = True\n",
    "dm_args[\"featurization_n_jobs\"] = 16\n",
    "dm_args[\"featurization_progress\"] = True\n",
    "\n",
    "\n",
    "dm = goli.data.DGLFromSmilesDataModule(**dm_args)\n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-16 18:39:34.142 | INFO     | goli.data.datamodule:prepare_data:171 - Prepare dataset with 100 data points.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0b57b4ef624f2dabe119afa9996132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and prepare the data\n",
    "dm.prepare_data()\n",
    "\n",
    "# Create the split torch datasets\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smiles': ['c1cc2c(cc1N[C@@H]1CCOC3(CCC3)C1)CCC2',\n",
       "  'CC(=O)N1CC[C@@H]([NH2+][C@@H](C)CSCC(C)C)C1',\n",
       "  'Cc1ccc(-c2nc3ccc(C)c(C)c3[nH]2)nc1',\n",
       "  'CCOC[C@H](O)[C@](C)(CC)[NH+]1CCCC1',\n",
       "  'Cc1cc(CC(=O)N[C@H](c2ccc(F)cc2)C2CCC2)no1',\n",
       "  'CCc1ccc(C(=O)/C(=C(/S)NC2CC2)[n+]2ccc(CC)cc2)cc1',\n",
       "  'Cc1ccc(NC(=O)c2ccc(F)cc2F)cc1S(=O)(=O)Nc1ccc(Cl)cc1',\n",
       "  'CC#CCCC(=O)Nc1cccc2c1C(=O)c1ccccc1C2=O',\n",
       "  'CCOc1cc(/C=C(\\\\C#N)C(=O)c2c[nH]c3cc(Cl)ccc23)ccc1OC',\n",
       "  'CNC(=O)[C@@H]1CCC[NH+]1Cc1ccc(C)c(F)c1',\n",
       "  'CC(C)(C)OC(=O)N[C@H]1CCN(c2cc(-c3cccs3)n[nH]2)C1',\n",
       "  'Cc1nn(-c2ccccc2)c(O)c1/C=[NH+]/Cc1ccncc1',\n",
       "  'COCC[NH+](C)Cc1c(C)cc(C)c(C(C)=O)c1C',\n",
       "  'Cc1nc(C)c(S(=O)(=O)/N=C(\\\\[O-])C[C@H]2CCCO2)s1',\n",
       "  'COc1cccc(CN2CCC[NH+](CC(=O)Nc3ccc(F)cc3)S2(=O)=O)c1',\n",
       "  'COc1cc(F)cc(CNC(=O)[C@H]2CCCN2C(=O)Cc2ccccc2)c1'],\n",
       " 'features': Graph(num_nodes=352, num_edges=754,\n",
       "       ndata_schemes={'feat': Scheme(shape=(50,), dtype=torch.float32)}\n",
       "       edata_schemes={'feat': Scheme(shape=(6,), dtype=torch.float32)}),\n",
       " 'labels': tensor([[3.3631],\n",
       "         [4.4837],\n",
       "         [2.3425],\n",
       "         [5.1279],\n",
       "         [2.6651],\n",
       "         [2.7752],\n",
       "         [1.9474],\n",
       "         [2.2990],\n",
       "         [2.3508],\n",
       "         [4.3913],\n",
       "         [3.2280],\n",
       "         [3.1176],\n",
       "         [3.9551],\n",
       "         [3.8130],\n",
       "         [3.5463],\n",
       "         [2.4272]], dtype=torch.float64)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a dataloader and get the first batch from it\n",
    "dl = dm.train_dataloader()\n",
    "it = iter(dl)\n",
    "batch = next(it)\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Launch a training\n",
    "\n",
    "In `goli.cli.train` I have added a `click` CLI command that take a config file as input and build the datamodule. Once I am done with the PL module I will complete the command.\n",
    "\n",
    "The way to use it is quite simple, you need to install goli with `pip install -e .` (omit`-e` in prod) and then:\n",
    "\n",
    "```bash\n",
    "goli train -c my_config.yaml\n",
    "```\n",
    "\n",
    "It's not here for now but usually I \"augment\" the CLI command with various config key you might want to set without having to modify the config file itself:\n",
    "\n",
    "```bash\n",
    "goli train -c my_config.yaml --training-path /home/hadim/data/goli/runs/exp_1\n",
    "```\n",
    "\n",
    "Later the same strategy could be done to launch an hparams tuning run (with a config file as above + a config file defning the search space).\n",
    "\n",
    "```bash\n",
    "goli tune -c my_config.yaml --tune-config tuning_space.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:goli]",
   "language": "python",
   "name": "conda-env-goli-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
