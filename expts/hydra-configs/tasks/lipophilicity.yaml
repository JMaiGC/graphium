# @package _global_

architecture:
  task_heads:
    qm9:
      task_level: graph
      out_dim: 19
      hidden_dims: 128
      depth: 2
      activation: relu
      last_activation: none
      dropout: &dropout 0.18
      normalization: &normalization layer_norm
      last_normalization: "none"
      residual_type: none
    tox21:
      task_level: graph
      out_dim: 12
      hidden_dims: 64
      depth: 2
      activation: relu
      last_activation: sigmoid
      dropout: *dropout
      normalization: *normalization
      last_normalization: "none"
      residual_type: none
    zinc:
      task_level: graph
      out_dim: 3
      hidden_dims: 32
      depth: 2
      activation: relu
      last_activation: none
      dropout: *dropout
      normalization: *normalization
      last_normalization: "none"
      residual_type: none
      ###########################
      last_layer_is_readout: false
      ###########################

  finetuning_head: # none
    task: lipophilicity_astrazeneca
    previous_module: task_heads
    incoming_level: graph
    model_type: mlp
    in_dim: 8
    out_dim: 1
    hidden_dims: 8
    depth: 2
    last_layer_is_readout: true

predictor:
  metrics_on_progress_bar:
    lipophilicity_astrazeneca: ["mae"]
  loss_fun:
    lipophilicity_astrazeneca: mae

  
metrics:
  lipophilicity_astrazeneca:
    - name: mae
      metric: mae
      target_nan_mask: null
      multitask_handling: flatten
      threshold_kwargs: null
    - name: spearman
      metric: spearmanr
      threshold_kwargs: null
      target_nan_mask: null
      multitask_handling: mean-per-label
    - name: pearson
      metric: pearsonr
      threshold_kwargs: null
      target_nan_mask: null
      multitask_handling: mean-per-label
    - name: r2_score
      metric: r2
      target_nan_mask: null
      multitask_handling: mean-per-label
      threshold_kwargs: null


datamodule:

  module_type: "ADMETBenchmarkDataModule"
  args:

    tdc_benchmark_names: [lipophilicity_astrazeneca]
    tdc_train_val_seed: ${constants.seed}
    
    batch_size_training: 200
    batch_size_inference: 200
    featurization_n_jobs: 0
    num_workers: 0

    prepare_dict_or_graph: pyg:graph
    featurization_progress: True
    featurization_backend: "loky"
    processed_graph_data_path: "../datacache/neurips2023-small/"
    persistent_workers: False
