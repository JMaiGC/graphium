{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Overview","text":"<p>A deep learning library focused on graph representation learning for real-world chemical tasks.</p> <ul> <li>\u2705 State-of-the-art GNN architectures.</li> <li>\ud83d\udc0d Extensible API: build your own GNN model and train it with ease.</li> <li>\u2697\ufe0f Rich featurization: powerful and flexible built-in molecular featurization.</li> <li>\ud83e\udde0 Pretrained models: for fast and easy inference or transfer learning.</li> <li>\u2b94 Read-to-use training loop based on Pytorch Lightning.</li> <li>\ud83d\udd0c Have a new dataset? Goli provides a simple plug-and-play interface. Change the path, the name of the columns to predict, the atomic featurization, and you\u2019re ready to play!</li> </ul>"},{"location":"index.html#try-online","title":"Try Online","text":"<p>Visit  and try Goli online.</p>"},{"location":"index.html#documentation","title":"Documentation","text":"<p>Visit https://valence-discovery.github.io/goli/.</p>"},{"location":"index.html#installation","title":"Installation","text":"<p>Use either <code>mamba</code> or <code>conda</code>:</p> <pre><code># Install Goli\nmamba install -c conda-forge goli\n</code></pre> <p>or pip:</p> <pre><code>pip install goli-life\n</code></pre>"},{"location":"cli_references.html","title":"CLI Reference","text":"<p>This page provides documentation for our command line tools.</p>"},{"location":"cli_references.html#data","title":"data","text":"<p>Goli datasets.</p> <p>Usage:</p> <pre><code>data [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <pre><code>  --help  Show this message and exit.\n</code></pre>"},{"location":"cli_references.html#download","title":"download","text":"<p>Download a Goli dataset.</p> <p>Usage:</p> <pre><code>data download [OPTIONS]\n</code></pre> <p>Options:</p> <pre><code>  -n, --name TEXT    Name of the goli dataset to download.  [required]\n  -o, --output TEXT  Where to download the Goli dataset.  [required]\n  --progress         Whether to extract the dataset if it's a zip file.\n  --help             Show this message and exit.\n</code></pre>"},{"location":"cli_references.html#list","title":"list","text":"<p>List available Goli dataset.</p> <p>Usage:</p> <pre><code>data list [OPTIONS]\n</code></pre> <p>Options:</p> <pre><code>  --help  Show this message and exit.\n</code></pre>"},{"location":"contribute.html","title":"Contribute","text":"<p>The below documents the development lifecycle of Datamol.</p>"},{"location":"contribute.html#setup-a-dev-environment","title":"Setup a dev environment","text":"<pre><code>conda create -n goli\nconda activate goli\n\nmamba env update -f env.yml\n\nconda deactivate &amp;&amp; conda activate goli\npip install -e .\n</code></pre>"},{"location":"contribute.html#run-tests","title":"Run tests","text":"<pre><code>pytest\n</code></pre>"},{"location":"contribute.html#build-the-documentation","title":"Build the documentation","text":"<p>You can build and serve the documentation locally with:</p> <pre><code># Build and serve the doc\nmike serve\n</code></pre>"},{"location":"contribute.html#release-a-new-version","title":"Release a new version","text":"<ul> <li>Run check: <code>rever check</code>.</li> <li>Bump and release new version: <code>rever VERSION_NUMBER</code>.</li> <li>Releasing a new version will do the following things in that order:</li> <li>Update <code>AUTHORS.rst</code>.</li> <li>Update <code>CHANGELOG.rst</code>.</li> <li>Bump the version number in <code>setup.py</code> and <code>_version.py</code>.</li> <li>Add a git tag.</li> <li>Push the git tag.</li> <li>Add a new release on the GH repo associated with the git tag.</li> <li>Update the conda forge feedstock.</li> </ul>"},{"location":"datasets.html","title":"GOLI Datasets","text":"<p>GOLI datasets are hosted at on Google Cloud Storage at <code>gs://goli-public/datasets</code>. GOLI provides a convenient utility functions to list and download those datasets:</p> <pre><code>import goli\n\ndataset_dir = \"/my/path\"\ndata_path = goli.data.utils.download_goli_dataset(\"goli-zinc-micro\", output_path=dataset_dir)\nprint(data_path)\n# /my/path/goli-zinc-micro\n</code></pre>"},{"location":"datasets.html#goli-zinc-micro","title":"<code>goli-zinc-micro</code>","text":"<p>ADD DESCRIPTION.</p> <ul> <li>Number of molecules: xxx</li> <li>Label columns: xxx</li> <li>Split informations.</li> </ul>"},{"location":"datasets.html#goli-zinc-bench-gnn","title":"<code>goli-zinc-bench-gnn</code>","text":"<p>ADD DESCRIPTION.</p> <ul> <li>Number of molecules: xxx</li> <li>Label columns: xxx- Split informations.</li> </ul>"},{"location":"datasets.html#goli-htsfp","title":"<code>goli-htsfp</code>","text":"<p>ADD DESCRIPTION.</p> <ul> <li>Number of molecules: xxx</li> <li>Label columns: xxx</li> <li>Split informations.</li> </ul>"},{"location":"design.html","title":"Goli Library Design","text":""},{"location":"design.html#diagram-for-data-processing-in-molgps","title":"Diagram for data processing in molGPS.","text":""},{"location":"design.html#diagram-for-muti-task-network-in-molgps","title":"Diagram for Muti-task network in molGPS","text":"<p>Section from the previous README:</p>"},{"location":"design.html#data-setup","title":"Data setup","text":"<p>Then, you need to download the data needed to run the code. Right now, we have 2 sets of data folders, present in the link here.</p> <ul> <li>micro_ZINC (Synthetic dataset)</li> <li>A small subset (1000 mols) of the ZINC dataset</li> <li>The score is the subtraction of the computed LogP and the synthetic accessibility score SA</li> <li> <p>The data must be downloaded to the folder <code>./goli/data/micro_ZINC/</code></p> </li> <li> <p>ZINC_bench_gnn (Synthetic dataset)</p> </li> <li>A subset (12000 mols) of the ZINC dataset</li> <li>The score is the subtraction of the computed LogP and the synthetic accessibility score SA</li> <li>These are the same 12k molecules provided by the Benchmarking-gnn repository.<ul> <li>We provide the pre-processed graphs in <code>ZINC_bench_gnn/data_from_benchmark</code></li> <li>We provide the SMILES in <code>ZINC_bench_gnn/smiles_score.csv</code>, with the train-val-test indexes in the file <code>indexes_train_val_test.csv</code>.</li> <li>The first 10k elements are the training set</li> <li>The next 1k the valid set</li> <li>The last 1k the test set.</li> </ul> </li> <li>The data must be downloaded to the folder <code>./goli/data/ZINC_bench_gnn/</code></li> </ul> <p>Then, you can run the main file to make sure that all the dependancies are correctly installed and that the code works as expected.</p> <pre><code>python expts/main_micro_zinc.py\n</code></pre> <p>TODO: explain the internal design of Goli so people can contribute to it more easily.</p>"},{"location":"design.html#structure-of-the-code","title":"Structure of the code","text":"<p>The code is built to rapidly iterate on different architectures of neural networks (NN) and graph neural networks (GNN) with Pytorch. The main focus of this work is molecular tasks, and we use the package <code>rdkit</code> to transform molecular SMILES into graphs.</p>"},{"location":"design.html#data_parser","title":"data_parser","text":"<p>This folder contains tools that allow tdependenciesrent kind of molecular data files, such as <code>.csv</code> or <code>.xlsx</code> with SMILES data, or <code>.sdf</code> files with 3D data.</p>"},{"location":"design.html#features","title":"features","text":"<p>Different utilities for molecules, such as Smiles to adjacency graph transformer, molecular property extraction, atomic properties, bond properties, ...</p> <p>The MolecularTransformer and AdjGraphTransformer come from ivbase, but I don't like them. I think we should replace them with something simpler and give more flexibility for combining one-hot embedding with physical properties embedding..</p>"},{"location":"design.html#trainer","title":"trainer","text":"<p>The trainer contains the interface to the <code>pytorch-lightning</code> library, with <code>PredictorModule</code> being the main class used for any NN model, either for regression or classification. It also contains some modifications to the logger from <code>pytorch-lightning</code> to enable more flexibility.</p>"},{"location":"design.html#utils","title":"utils","text":"<p>Any kind of utilities that can be used anywhere, including argument checkers and configuration loader</p>"},{"location":"design.html#visualization","title":"visualization","text":"<p>Plot visualization tools</p>"},{"location":"design.html#modifying-the-code","title":"Modifying the code","text":""},{"location":"design.html#adding-a-new-gnn-layer","title":"Adding a new GNN layer","text":"<p>Any new GNN layer must inherit from the class <code>goli.nn.base_graph_layer.BaseGraphLayer</code> and be implemented in the folder <code>goli/nn/pyg_layers</code>, imported in the file <code>goli/nn/architectures.py</code>, and in the same file, added to the function <code>FeedForwardGraph._parse_gnn_layer</code>.</p> <p>To be used in the configuration file as a <code>goli.model.layer_name</code>, it must also be implemented with some variable parameters in the file <code>expts/config_gnns.yaml</code>.</p>"},{"location":"design.html#adding-a-new-nn-architecture","title":"Adding a new NN architecture","text":"<p>All NN and GNN architectures compatible with the <code>pyg</code> library are provided in the file <code>goli/nn/global_architectures.py</code>. When implementing a new architecture, it is highly recommended to inherit from <code>goli.nn.architectures.FeedForwardNN</code> for regular neural networks, from <code>goli.nn.global_architectures.FeedForwardGraph</code> for pyg neural network, or from any of their sub-classes.</p>"},{"location":"design.html#changing-the-predictormodule-and-loss-function","title":"Changing the PredictorModule and loss function","text":"<p>The <code>PredictorModule</code> is a general pytorch-lightning module that should work with any kind of <code>pytorch.nn.Module</code> or <code>pl.LightningModule</code>. The class defines a structure of including models, loss functions, batch sizes, collate functions, metrics...</p> <p>Some loss functions are already implemented in the PredictorModule, including <code>mse, bce, mae, cosine</code>, but some tasks will require more complex loss functions. One can add any new function in <code>goli.trainer.predictor.PredictorModule._parse_loss_fun</code>.</p>"},{"location":"design.html#changing-the-metrics-used","title":"Changing the metrics used","text":"<p>!WARNING! The metrics implementation was done for pytorch-lightning v0.8. There has been major changes to how the metrics are used and defined, so the whole implementation must change.</p> <p>Our current code is compatible with the metrics defined by pytorch-lightning, which include a great set of metrics. We also added the PearsonR and SpearmanR as they are important correlation metrics. You can define any new metric in the file <code>goli/trainer/metrics.py</code>. The metric must inherit from <code>TensorMetric</code> and must be added to the dictionary <code>goli.trainer.metrics.METRICS_DICT</code>.</p> <p>To use the metric, you can easily add it's name from <code>METRICS_DICT</code> in the yaml configuration file, at the address <code>metrics.metrics_dict</code>. Each metric has an underlying dictionnary with a mandatory <code>threshold</code> key containing information on how to threshold the prediction/target before computing the metric. Any <code>kwargs</code> arguments of the metric must also be added.</p>"},{"location":"design.html#old-running-a-hyper-parameter-search","title":"(OLD) Running a hyper-parameter search","text":"<p>In the current repository, we use <code>hydra-core</code> to launch multiple experiments in a grid-search manner. It works by specifying the parameters that we want to change from a given YAML file.</p> <p>Below is an example of running a set of 3*2*2*2=24 experiments, 3 variations of the gnn type layer_name, 2 variations of the learning rate lr, 2 variations of the hidden dimension hidden_dim, 2 variations of the network depth hidden_depth. All parameters not mentionned in the code below are unchanged from the file <code>expts/main_micro_ZINC.py</code>.</p> <pre><code>python expts/main_micro_ZINC.py --multirun \\\nmodel.layer_name=gin,gcn,pna-conv3 \\\nconstants.exp_name=\"testing_hydra\" \\\nconstants.device=\"cuda:0\" \\\nconstants.ignore_train_error=true \\\npredictor.lr=1e-4,1e-3 \\\nmodel.gnn_kwargs.hidden_dim=32,64 \\\nmodel.gnn_kwargs.hidden_depth=4,8\n</code></pre> <p>The results of the run will be available in the folder <code>multirun/[CURRENT-DATE]/[CURRENT-TIME]</code>. To open the results in tensorflow, run the following command using bash or powershell</p> <p><code>tensorboard --logdir 'multirun/[CURRENT-DATE]/[CURRENT-TIME]/' --port 8000</code></p> <p>Then open a web-browser and enter the address <code>http://localhost:8000/</code>.</p>"},{"location":"license.html","title":"License","text":"<pre><code>Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2021 Valence\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n</code></pre>"},{"location":"pretrained_models.html","title":"GOLI pretrained models","text":"<p>GOLI provides a set of pretrained models that you can use for inference or transfer learning. The models are available on Google Cloud Storage at <code>gs://goli-public/pretrained-models</code>.</p> <p>You can load a pretrained models using the GOLI API:</p> <pre><code>import goli\n\npredictor = goli.trainer.PredictorModule.load_pretrained_models(\"goli-zinc-micro-dummy-test\")\n</code></pre>"},{"location":"pretrained_models.html#goli-zinc-micro-dummy-test","title":"<code>goli-zinc-micro-dummy-test</code>","text":"<p>Dummy model used for testing purposes (probably to delete in the future).</p>"},{"location":"api/goli.config.html","title":"goli.config","text":""},{"location":"api/goli.config.html#goli.config._loader","title":"<code>goli.config._loader</code>","text":""},{"location":"api/goli.config.html#goli.config._loader.get_accelerator","title":"<code>get_accelerator(config)</code>","text":"<p>Get the accelerator from the config file, and ensure that they are consistant. For example, specifying <code>cpu</code> as the accelerators, but <code>gpus&gt;0</code> as a Trainer option will yield an error.</p>"},{"location":"api/goli.config.html#goli.config._loader.load_architecture","title":"<code>load_architecture(config, in_dims)</code>","text":"<p>Loading the architecture used for training.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Union[omegaconf.DictConfig, Dict[str, Any]]</code> <p>The config file, with key <code>architecture</code></p> required <code>in_dims</code> <code>Dict[str, int]</code> <p>Dictionary of the input dimensions for various</p> required <p>Returns:</p> Name Type Description <code>architecture</code> <code>Union[FullGraphNetwork, torch.nn.Module]</code> <p>The datamodule used to process and load the data</p>"},{"location":"api/goli.config.html#goli.config._loader.load_datamodule","title":"<code>load_datamodule(config)</code>","text":"<p>Load the datamodule from the specified configurations at the key <code>datamodule: args</code>. If the accelerator is IPU, load the IPU options as well.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Union[omegaconf.DictConfig, Dict[str, Any]]</code> <p>The config file, with key <code>datamodule: args</code></p> required <p>Returns:</p> Name Type Description <code>datamodule</code> <code>BaseDataModule</code> <p>The datamodule used to process and load the data</p>"},{"location":"api/goli.config.html#goli.config._loader.load_metrics","title":"<code>load_metrics(config)</code>","text":"<p>Loading the metrics to be tracked.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Union[omegaconf.DictConfig, Dict[str, Any]]</code> <p>The config file, with key <code>metrics</code></p> required <p>Returns:</p> Name Type Description <code>metrics</code> <code>Dict[str, MetricWrapper]</code> <p>A dictionary of all the metrics</p>"},{"location":"api/goli.config.html#goli.config._loader.load_mup","title":"<code>load_mup(mup_base_path, predictor)</code>","text":"<p>Load the base shapes for the mup, based either on a <code>.ckpt</code> or <code>.yaml</code> file. If <code>.yaml</code>, it should be generated by <code>mup.save_base_shapes</code></p>"},{"location":"api/goli.config.html#goli.config._loader.load_predictor","title":"<code>load_predictor(config, model_class, model_kwargs, metrics)</code>","text":"<p>Defining the predictor module, which handles the training logic from <code>pytorch_lightning.LighningModule</code></p> <p>Parameters:</p> Name Type Description Default <code>model_class</code> <code>Type[torch.nn.Module]</code> <p>The torch Module containing the main forward function</p> required <p>Returns:</p> Name Type Description <code>predictor</code> <code>PredictorModule</code> <p>The predictor module</p>"},{"location":"api/goli.config.html#goli.config._loader.load_trainer","title":"<code>load_trainer(config, run_name)</code>","text":"<p>Defining the pytorch-lightning Trainer module.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Union[omegaconf.DictConfig, Dict[str, Any]]</code> <p>The config file, with key <code>trainer</code></p> required <code>run_name</code> <code>str</code> <p>The name of the current run. To be used for logging.</p> required <p>Returns:</p> Name Type Description <code>trainer</code> <code>Trainer</code> <p>the trainer module</p>"},{"location":"api/goli.config.html#goli.config._loader.save_params_to_wandb","title":"<code>save_params_to_wandb(logger, config, predictor, datamodule)</code>","text":"<p>Save a few stuff to weights-and-biases WandB</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger</code> <p>The object used to log the training. Usually WandbLogger</p> required <code>config</code> <code>Union[omegaconf.DictConfig, Dict[str, Any]]</code> <p>The config file, with key <code>trainer</code></p> required <code>predictor</code> <code>PredictorModule</code> <p>The predictor used to handle the train/val/test steps logic</p> required <code>datamodule</code> <code>MultitaskFromSmilesDataModule</code> <p>The datamodule used to load the data into training</p> required"},{"location":"api/goli.config.html#goli.config.config_convert","title":"<code>goli.config.config_convert</code>","text":""},{"location":"api/goli.config.html#goli.config.config_convert.recursive_config_reformating","title":"<code>recursive_config_reformating(configs)</code>","text":"<p>For a given configuration file, convert all <code>DictConfig</code> to <code>dict</code>, all <code>ListConfig</code> to <code>list</code>, and all <code>byte</code> to <code>str</code>.</p> <p>This helps avoid errors when dumping a yaml file.</p>"},{"location":"api/goli.config.html#goli.config._load","title":"<code>goli.config._load</code>","text":""},{"location":"api/goli.config.html#goli.config._load.load_config","title":"<code>load_config(name)</code>","text":"<p>Load a default config file by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the config to load.</p> required"},{"location":"api/goli.data.html","title":"goli.data","text":""},{"location":"api/goli.data.html#goli.data.collate","title":"<code>goli.data.collate</code>","text":""},{"location":"api/goli.data.html#goli.data.collate.collage_pyg_graph","title":"<code>collage_pyg_graph(pyg_graphs, batch_size_per_pack=None)</code>","text":"<p>Function to collate pytorch geometric graphs. Convert all numpy types to torch Convert edge indices to int64</p> <p>Parameters:</p> Name Type Description Default <code>pyg_graphs</code> <code>Iterable[Union[Data, Dict]]</code> <p>Iterable of PyG graphs</p> required <code>batch_size_per_pack</code> <code>Optional[int]</code> <p>The number of graphs to pack together. This is useful for using packing with the Transformer,</p> <code>None</code>"},{"location":"api/goli.data.html#goli.data.collate.collate_labels","title":"<code>collate_labels(labels, labels_size_dict=None)</code>","text":"<p>Collate labels for multitask learning.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>List[Dict[str, torch.Tensor]]</code> <p>List of labels</p> required <code>labels_size_dict</code> <code>Optional[Dict[str, Any]]</code> <p>Dict of the form Dict[tasks, sizes] which has task names as keys and the size of the label tensor as value. The size of the tensor corresponds to how many labels/values there are to predict for that task.</p> <code>None</code> <p>Returns:</p> Type Description <p>A dictionary of the form Dict[tasks, labels] where tasks is the name of the task and labels</p> <p>is a tensor of shape (batch_size, *labels_size_dict[task]).</p>"},{"location":"api/goli.data.html#goli.data.collate.goli_collate_fn","title":"<code>goli_collate_fn(elements, labels_size_dict=None, mask_nan='raise', do_not_collate_keys=[], batch_size_per_pack=None)</code>","text":"<p>This collate function is identical to the default pytorch collate function but add support for <code>pyg.data.Data</code> to batch graphs.</p> <p>Beside pyg graph collate, other objects are processed the same way as the original torch collate function. See https://pytorch.org/docs/stable/data.html#dataloader-collate-fn for more details.</p> Note <p>If goli needs to manipulate other tricky-to-batch objects. Support for them should be added to this single collate function.</p> <p>Parameters:</p> Name Type Description Default <code>elements</code> <code>Union[List[Any], Dict[str, List[Any]]]</code> <p>The elements to batch. See <code>torch.utils.data.dataloader.default_collate</code>.</p> required <code>labels_size_dict</code> <code>Optional[Dict[str, Any]]</code> <p>(Note): This is an attribute of the <code>MultitaskDataset</code>. A dictionary of the form Dict[tasks, sizes] which has task names as keys and the size of the label tensor as value. The size of the tensor corresponds to how many labels/values there are to predict for that task.</p> <code>None</code> <code>mask_nan</code> <code>Union[str, float, Type[None]]</code> <p>Deal with the NaN/Inf when calling the function <code>make_pyg_graph</code>. Some values become <code>Inf</code> when changing data type. This allows to deal with that.</p> <ul> <li>\"raise\": Raise an error when there is a nan or inf in the featurization</li> <li>\"warn\": Raise a warning when there is a nan or inf in the featurization</li> <li>\"None\": DEFAULT. Don't do anything</li> <li>\"Floating value\": Replace nans or inf by the specified value</li> </ul> <code>'raise'</code> <code>do_not_batch_keys</code> <p>Keys to ignore for the collate</p> required <p>Returns:</p> Type Description <code>Union[Any, Dict[str, Any]]</code> <p>A dictionary of the batch</p>"},{"location":"api/goli.data.html#goli.data.datamodule","title":"<code>goli.data.datamodule</code>","text":""},{"location":"api/goli.data.html#goli.data.datamodule.BaseDataModule","title":"<code>BaseDataModule</code>","text":"<p>         Bases: <code>pl.LightningDataModule</code></p>"},{"location":"api/goli.data.html#goli.data.datamodule.BaseDataModule.get_num_workers","title":"<code>get_num_workers</code>  <code>property</code>","text":"<p>get the number of workers to use</p>"},{"location":"api/goli.data.html#goli.data.datamodule.BaseDataModule.predict_ds","title":"<code>predict_ds</code>  <code>property</code> <code>writable</code>","text":"<p>Get the dataset used for the prediction</p>"},{"location":"api/goli.data.html#goli.data.datamodule.BaseDataModule.__init__","title":"<code>__init__(batch_size_training=16, batch_size_inference=16, num_workers=0, pin_memory=True, persistent_workers=False, collate_fn=None)</code>","text":"<p>base dataset module for all datasets (to be inherented)</p> <p>Parameters:</p> Name Type Description Default <code>batch_size_training</code> <code>int</code> <p>batch size for training</p> <code>16</code> <code>batch_size_inference</code> <code>int</code> <p>batch size for inference</p> <code>16</code> <code>num_workers</code> <code>int</code> <p>number of workers for data loading</p> <code>0</code> <code>pin_memory</code> <code>bool</code> <p>whether to pin memory</p> <code>True</code> <code>persistent_workers</code> <code>bool</code> <p>whether to use persistent workers</p> <code>False</code> <code>collate_fn</code> <code>Optional[Callable]</code> <p>collate function for batching</p> <code>None</code>"},{"location":"api/goli.data.html#goli.data.datamodule.BaseDataModule.get_dataloader","title":"<code>get_dataloader(dataset, shuffle, stage)</code>","text":"<p>Get the dataloader for a given dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The dataset from which to load the data</p> required <code>shuffle</code> <code>bool</code> <p>set to <code>True</code> to have the data reshuffled at every epoch.</p> required <code>stage</code> <code>RunningStage</code> <p>Whether in Training, Validating, Testing, Sanity-checking, Predicting, or Tuning phase.</p> required <p>Returns:</p> Type Description <code>DataLoader</code> <p>The dataloader to sample from</p>"},{"location":"api/goli.data.html#goli.data.datamodule.BaseDataModule.get_dataloader_kwargs","title":"<code>get_dataloader_kwargs(stage, shuffle, **kwargs)</code>","text":"<p>Get the options for the dataloader depending on the current stage.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>RunningStage</code> <p>Whether in Training, Validating, Testing, Sanity-checking, Predicting, or Tuning phase.</p> required <code>shuffle</code> <code>bool</code> <p>set to <code>True</code> to have the data reshuffled at every epoch.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Arguments to pass to the <code>DataLoader</code> during initialization</p>"},{"location":"api/goli.data.html#goli.data.datamodule.BaseDataModule.get_max_num_edges_datamodule","title":"<code>get_max_num_edges_datamodule(stages=None)</code>","text":"<p>Get the maximum number of edges across all datasets from the datamodule</p> <p>Parameters:</p> Name Type Description Default <code>datamodule</code> <p>The datamodule from which to extract the maximum number of nodes</p> required <code>stages</code> <code>Optional[List[str]]</code> <p>The stages from which to extract the max num nodes. Possible values are [\"train\", \"val\", \"test\", \"predict\"]. If None, all stages are considered.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>max_num_edges</code> <code>int</code> <p>The maximum number of edges across all datasets from the datamodule</p>"},{"location":"api/goli.data.html#goli.data.datamodule.BaseDataModule.get_max_num_nodes_datamodule","title":"<code>get_max_num_nodes_datamodule(stages=None)</code>","text":"<p>Get the maximum number of nodes across all datasets from the datamodule</p> <p>Parameters:</p> Name Type Description Default <code>datamodule</code> <p>The datamodule from which to extract the maximum number of nodes</p> required <code>stages</code> <code>Optional[List[str]]</code> <p>The stages from which to extract the max num nodes. Possible values are [\"train\", \"val\", \"test\", \"predict\"]. If None, all stages are considered.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>max_num_nodes</code> <code>int</code> <p>The maximum number of nodes across all datasets from the datamodule</p>"},{"location":"api/goli.data.html#goli.data.datamodule.BaseDataModule.predict_dataloader","title":"<code>predict_dataloader(**kwargs)</code>","text":"<p>return the dataloader for prediction</p>"},{"location":"api/goli.data.html#goli.data.datamodule.BaseDataModule.test_dataloader","title":"<code>test_dataloader(**kwargs)</code>","text":"<p>return the test dataloader</p>"},{"location":"api/goli.data.html#goli.data.datamodule.BaseDataModule.train_dataloader","title":"<code>train_dataloader(**kwargs)</code>","text":"<p>return the training dataloader</p>"},{"location":"api/goli.data.html#goli.data.datamodule.BaseDataModule.val_dataloader","title":"<code>val_dataloader(**kwargs)</code>","text":"<p>return the validation dataloader</p>"},{"location":"api/goli.data.html#goli.data.datamodule.DatasetProcessingParams","title":"<code>DatasetProcessingParams</code>","text":""},{"location":"api/goli.data.html#goli.data.datamodule.DatasetProcessingParams.__init__","title":"<code>__init__(df=None, df_path=None, smiles_col=None, label_cols=None, weights_col=None, weights_type=None, idx_col=None, sample_size=None, split_val=0.2, split_test=0.2, split_seed=None, splits_path=None, split_names=['train', 'val', 'test'])</code>","text":"<p>object to store the parameters for the dataset processing</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>The dataframe containing the data</p> <code>None</code> <code>df_path</code> <code>Optional[Union[str, os.PathLike]]</code> <p>The path to the dataframe containing the data</p> <code>None</code> <code>smiles_col</code> <code>str</code> <p>The column name of the smiles</p> <code>None</code> <code>label_cols</code> <code>List[str]</code> <p>The column names of the labels</p> <code>None</code> <code>weights_col</code> <code>str</code> <p>The column name of the weights</p> <code>None</code> <code>weights_type</code> <code>str</code> <p>The type of weights</p> <code>None</code> <code>idx_col</code> <code>str</code> <p>The column name of the indices</p> <code>None</code> <code>sample_size</code> <code>Union[int, float, Type[None]]</code> <p>The size of the sample</p> <code>None</code> <code>split_val</code> <code>float</code> <p>The fraction of the data to use for validation</p> <code>0.2</code> <code>split_test</code> <code>float</code> <p>The fraction of the data to use for testing</p> <code>0.2</code> <code>split_seed</code> <code>int</code> <p>The seed to use for the split</p> <code>None</code> <code>splits_path</code> <code>Optional[Union[str, os.PathLike]]</code> <p>The path to the splits</p> <code>None</code>"},{"location":"api/goli.data.html#goli.data.datamodule.FakeDataModule","title":"<code>FakeDataModule</code>","text":"<p>         Bases: <code>MultitaskFromSmilesDataModule</code></p> <p>A fake datamodule that generates artificial data by mimicking the true data coming from the provided dataset. It is useful to test the speed and performance of the model on a dataset without having to featurize it and wait for the workers to load it.</p>"},{"location":"api/goli.data.html#goli.data.datamodule.FakeDataModule.generate_data","title":"<code>generate_data(label_cols, smiles_col)</code>","text":"<p>Returns:</p> Type Description <p>pd.DataFrame</p>"},{"location":"api/goli.data.html#goli.data.datamodule.FakeDataModule.get_first_graph","title":"<code>get_first_graph()</code>","text":"<p>Low memory footprint method to get the first datapoint DGL graph. The first 10 rows of the data are read in case the first one has a featurization error. If all 20 first element, then <code>None</code> is returned, otherwise the first graph to not fail is returned.</p>"},{"location":"api/goli.data.html#goli.data.datamodule.FakeDataModule.prepare_data","title":"<code>prepare_data()</code>","text":"<p>Called only from a single process in distributed settings. Steps:</p> <ul> <li>If each cache is set and exists, reload from cache and return. Otherwise,</li> <li>For each single-task dataset:<ul> <li>Load its dataframe from a path (if provided)</li> <li>Subsample the dataframe</li> <li>Extract the smiles, labels from the dataframe</li> </ul> </li> <li>In the previous step, we were also able to get the unique smiles, which we use to compute the features</li> <li>For each single-task dataframe and associated data (smiles, labels, etc.):<ul> <li>Filter out the data corresponding to molecules which failed featurization.</li> <li>Create a corresponding SingletaskDataset</li> <li>Split the SingletaskDataset according to the task-specific splits for train, val and test</li> </ul> </li> </ul>"},{"location":"api/goli.data.html#goli.data.datamodule.FakeDataModule.setup","title":"<code>setup(stage=None)</code>","text":"<p>Prepare the torch dataset. Called on every GPUs. Setting state here is ok.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>str</code> <p>Either 'fit', 'test', or None.</p> <code>None</code>"},{"location":"api/goli.data.html#goli.data.datamodule.GraphOGBDataModule","title":"<code>GraphOGBDataModule</code>","text":"<p>         Bases: <code>MultitaskFromSmilesDataModule</code></p>"},{"location":"api/goli.data.html#goli.data.datamodule.GraphOGBDataModule.__init__","title":"<code>__init__(task_specific_args, cache_data_path=None, featurization=None, batch_size_training=16, batch_size_inference=16, num_workers=0, pin_memory=True, persistent_workers=False, featurization_n_jobs=-1, featurization_progress=False, featurization_backend='loky', collate_fn=None, prepare_dict_or_graph='pyg:graph', **kwargs)</code>","text":"<p>Load an OGB (Open-graph-benchmark) GraphProp dataset.</p> <p>Parameters:</p> Name Type Description Default <code>task_specific_args</code> <code>Dict[str, Dict[str, Any]]</code> <p>Arguments related to each task, with the task-name being the key, and the specific arguments being the values. The arguments must be a Dict containing the following keys:</p> <ul> <li>\"dataset_name\": Name of the OGB dataset to load. Examples of possible datasets are \"ogbg-molhiv\", \"ogbg-molpcba\", \"ogbg-moltox21\", \"ogbg-molfreesolv\".</li> <li>\"sample_size\": The number of molecules to sample from the dataset. Default=None, meaning that all molecules will be considered.</li> </ul> required <code>cache_data_path</code> <code>Optional[Union[str, os.PathLike]]</code> <p>path where to save or reload the cached data. The path can be remote (S3, GS, etc).</p> <code>None</code> <code>featurization</code> <code>Optional[Union[Dict[str, Any], omegaconf.DictConfig]]</code> <p>args to apply to the SMILES to Graph featurizer.</p> <code>None</code> <code>batch_size_training</code> <code>int</code> <p>batch size for training and val dataset.</p> <code>16</code> <code>batch_size_inference</code> <code>int</code> <p>batch size for test dataset.</p> <code>16</code> <code>num_workers</code> <code>int</code> <p>Number of workers for the dataloader. Use -1 to use all available cores.</p> <code>0</code> <code>pin_memory</code> <code>bool</code> <p>Whether to pin on paginated CPU memory for the dataloader.</p> <code>True</code> <code>featurization_n_jobs</code> <code>int</code> <p>Number of cores to use for the featurization.</p> <code>-1</code> <code>featurization_progress</code> <code>bool</code> <p>whether to show a progress bar during featurization.</p> <code>False</code> <code>featurization_backend</code> <code>str</code> <p>The backend to use for the molecular featurization.</p> <ul> <li>\"multiprocessing\": Found to cause less memory issues.</li> <li>\"loky\": joblib's Default. Found to cause memory leaks.</li> <li>\"threading\": Found to be slow.</li> </ul> <code>'loky'</code> <code>collate_fn</code> <code>Optional[Callable]</code> <p>A custom torch collate function. Default is to <code>goli.data.goli_collate_fn</code></p> <code>None</code> <code>sample_size</code> <ul> <li><code>int</code>: The maximum number of elements to take from the dataset.</li> <li><code>float</code>: Value between 0 and 1 representing the fraction of the dataset to consider</li> <li><code>None</code>: all elements are considered.</li> </ul> required"},{"location":"api/goli.data.html#goli.data.datamodule.GraphOGBDataModule.to_dict","title":"<code>to_dict()</code>","text":"<p>geenrate a dictionary representation of the class</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, Any]</code> <p>dictionary representation of the class</p>"},{"location":"api/goli.data.html#goli.data.datamodule.IPUDataModuleModifier","title":"<code>IPUDataModuleModifier</code>","text":""},{"location":"api/goli.data.html#goli.data.datamodule.IPUDataModuleModifier.__init__","title":"<code>__init__(ipu_inference_opts=None, ipu_training_opts=None, ipu_dataloader_training_opts=None, ipu_dataloader_inference_opts=None, *args, **kwargs)</code>","text":"<p>wrapper functions from the a <code>DataModule</code> to support IPU and IPU options To be used in dual inheritance, for example: <pre><code>IPUDataModule(BaseDataModule, IPUDataModuleModifier):\n    def __init__(self, **kwargs):\n        BaseDataModule.__init__(self, **kwargs)\n        IPUDataModuleModifier.__init__(self, **kwargs)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>ipu_inference_opts</code> <code>Optional[Options]</code> <p>Options for the IPU in inference mode. Ignore if not using IPUs</p> <code>None</code> <code>ipu_training_opts</code> <code>Optional[Options]</code> <p>Options for the IPU in training mode. Ignore if not using IPUs</p> <code>None</code> <code>ipu_dataloader_kwargs_train_val</code> <p>Options for the dataloader for the IPU. Ignore if not using IPUs</p> required <code>ipu_dataloader_kwargs_test</code> <p>Options for the dataloader for the IPU. Ignore if not using IPUs</p> required <code>args</code> <p>Arguments for the <code>DataModule</code></p> <code>()</code> <code>kwargs</code> <p>Keyword arguments for the <code>DataModule</code></p> <code>{}</code>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule","title":"<code>MultitaskFromSmilesDataModule</code>","text":"<p>         Bases: <code>BaseDataModule</code>, <code>IPUDataModuleModifier</code></p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.in_dims","title":"<code>in_dims</code>  <code>property</code>","text":"<p>Return all input dimensions for the set of graphs. Including node/edge features, and raw positional encoding dimensions such eigval, eigvec, rwse and more</p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.num_edge_feats","title":"<code>num_edge_feats</code>  <code>property</code>","text":"<p>Return the number of edge features in the first graph</p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.num_node_feats","title":"<code>num_node_feats</code>  <code>property</code>","text":"<p>Return the number of node features in the first graph</p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.__init__","title":"<code>__init__(task_specific_args, cache_data_path=None, featurization=None, batch_size_training=16, batch_size_inference=16, num_workers=0, pin_memory=True, persistent_workers=False, featurization_n_jobs=-1, featurization_progress=False, featurization_backend='loky', featurization_batch_size=1000, collate_fn=None, prepare_dict_or_graph='pyg:graph', **kwargs)</code>","text":"<p>only for parameters beginning with task_*, we have a dictionary where the key is the task name and the value is specified below.</p> <p>Parameters:</p> Name Type Description Default <code>task_df</code> <p>(value) a dataframe</p> required <code>task_df_path</code> <p>(value) a path to a dataframe to load (CSV file). <code>df</code> takes precedence over <code>df_path</code>.</p> required <code>task_smiles_col</code> <p>(value) Name of the SMILES column. If set to <code>None</code>, it will look for a column with the word \"smile\" (case insensitive) in it. If no such column is found, an error will be raised.</p> required <code>task_label_cols</code> <p>(value) Name of the columns to use as labels, with different options.</p> <ul> <li><code>list</code>: A list of all column names to use</li> <li><code>None</code>: All the columns are used except the SMILES one.</li> <li><code>str</code>: The name of the single column to use</li> <li><code>*str</code>: A string starting by a <code>*</code> means all columns whose name   ends with the specified <code>str</code></li> <li><code>str*</code>: A string ending by a <code>*</code> means all columns whose name   starts with the specified <code>str</code></li> </ul> required <code>task_weights_col</code> <p>(value) Name of the column to use as sample weights. If <code>None</code>, no weights are used. This parameter cannot be used together with <code>weights_type</code>.</p> required <code>task_weights_type</code> <p>(value) The type of weights to use. This parameter cannot be used together with <code>weights_col</code>. It only supports multi-label binary classification.</p> <p>Supported types:</p> <ul> <li><code>None</code>: No weights are used.</li> <li><code>\"sample_balanced\"</code>: A weight is assigned to each sample inversely     proportional to the number of positive value. If there are multiple     labels, the product of the weights is used.</li> <li><code>\"sample_label_balanced\"</code>: Similar to the <code>\"sample_balanced\"</code> weights,     but the weights are applied to each element individually, without     computing the product of the weights for a given sample.</li> </ul> required <code>task_idx_col</code> <p>(value) Name of the columns to use as indices. Unused if set to None.</p> required <code>task_sample_size</code> <p>(value)</p> <ul> <li><code>int</code>: The maximum number of elements to take from the dataset.</li> <li><code>float</code>: Value between 0 and 1 representing the fraction of the dataset to consider</li> <li><code>None</code>: all elements are considered.</li> </ul> required <code>task_split_val</code> <p>(value) Ratio for the validation split.</p> required <code>task_split_test</code> <p>(value) Ratio for the test split.</p> required <code>task_split_seed</code> <p>(value) Seed to use for the random split. More complex splitting strategy should be implemented.</p> required <code>task_splits_path</code> <p>(value) A path a CSV file containing indices for the splits. The file must contains 3 columns \"train\", \"val\" and \"test\". It takes precedence over <code>split_val</code> and <code>split_test</code>.</p> required <code>cache_data_path</code> <code>Optional[Union[str, os.PathLike]]</code> <p>path where to save or reload the cached data. The path can be remote (S3, GS, etc).</p> <code>None</code> <code>featurization</code> <code>Optional[Union[Dict[str, Any], omegaconf.DictConfig]]</code> <p>args to apply to the SMILES to Graph featurizer.</p> <code>None</code> <code>batch_size_training</code> <code>int</code> <p>batch size for training and val dataset.</p> <code>16</code> <code>batch_size_inference</code> <code>int</code> <p>batch size for test dataset.</p> <code>16</code> <code>num_workers</code> <code>int</code> <p>Number of workers for the dataloader. Use -1 to use all available cores.</p> <code>0</code> <code>pin_memory</code> <code>bool</code> <p>Whether to pin on paginated CPU memory for the dataloader.</p> <code>True</code> <code>featurization_n_jobs</code> <code>int</code> <p>Number of cores to use for the featurization.</p> <code>-1</code> <code>featurization_progress</code> <code>bool</code> <p>whether to show a progress bar during featurization.</p> <code>False</code> <code>featurization_backend</code> <code>str</code> <p>The backend to use for the molecular featurization.</p> <ul> <li>\"multiprocessing\": Found to cause less memory issues.</li> <li>\"loky\": joblib's Default. Found to cause memory leaks.</li> <li>\"threading\": Found to be slow.</li> </ul> <code>'loky'</code> <code>featurization_batch_size</code> <code>int</code> <p>Batch size to use for the featurization.</p> <code>1000</code> <code>collate_fn</code> <code>Optional[Callable]</code> <p>A custom torch collate function. Default is to <code>goli.data.goli_collate_fn</code></p> <code>None</code> <code>prepare_dict_or_graph</code> <code>str</code> <p>Whether to preprocess all molecules as Graph dict or PyG graphs. Possible options:</p> <ul> <li>\"pyg:dict\": Process molecules as a <code>dict</code>. It's faster and requires less RAM during   pre-processing. It is slower during training with with <code>num_workers=0</code> since   pyg <code>Data</code> will be created during data-loading, but faster with large   <code>num_workers</code>, and less likely to cause memory issues with the parallelization.</li> <li>\"pyg:graph\": Process molecules as <code>pyg.data.Data</code>.</li> </ul> <code>'pyg:graph'</code>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of elements of the current DataModule, which is the combined size of all single-task datasets given.</p> <p>Returns:</p> Name Type Description <code>num_elements</code> <code>int</code> <p>Number of elements in the current DataModule</p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.__repr__","title":"<code>__repr__()</code>","text":"<p>Controls how the class is printed</p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.get_data_cache_fullname","title":"<code>get_data_cache_fullname(compress=False)</code>","text":"<p>Create a hash for the dataset, and use it to generate a file name</p> <p>Parameters:</p> Name Type Description Default <code>compress</code> <code>bool</code> <p>Whether to compress the data</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>full path to the data cache file</p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.get_data_hash","title":"<code>get_data_hash()</code>","text":"<p>Get a hash specific to a dataset and smiles_transformer. Useful to cache the pre-processed data.</p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.get_dataloader","title":"<code>get_dataloader(dataset, shuffle, stage)</code>","text":"<p>Get the poptorch dataloader for a given dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The dataset from which to load the data</p> required <code>shuffle</code> <code>bool</code> <p>set to <code>True</code> to have the data reshuffled at every epoch.</p> required <code>stage</code> <code>RunningStage</code> <p>Whether in Training, Validating, Testing, Sanity-checking, Predicting, or Tuning phase.</p> required <p>Returns:</p> Type Description <code>Union[DataLoader, DataLoader]</code> <p>The poptorch dataloader to sample from</p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.get_dataloader_kwargs","title":"<code>get_dataloader_kwargs(stage, shuffle, **kwargs)</code>","text":"<p>Get the options for the dataloader depending on the current stage.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>RunningStage</code> <p>Whether in Training, Validating, Testing, Sanity-checking, Predicting, or Tuning phase.</p> required <code>shuffle</code> <code>bool</code> <p>set to <code>True</code> to have the data reshuffled at every epoch.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Arguments to pass to the <code>DataLoader</code> during initialization</p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.get_first_graph","title":"<code>get_first_graph()</code>","text":"<p>Low memory footprint method to get the first datapoint graph. The first 10 rows of the data are read in case the first one has a featurization error. If all 20 first element, then <code>None</code> is returned, otherwise the first graph to not fail is returned.</p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.get_subsets_of_datasets","title":"<code>get_subsets_of_datasets(single_task_datasets, task_train_indices, task_val_indices, task_test_indices)</code>","text":"<p>From a dictionary of datasets and their associated indices, subset the train/val/test sets</p> <p>Parameters:</p> Name Type Description Default <code>single_task_datasets</code> <code>Dict[str, Datasets.SingleTaskDataset]</code> <p>Dictionary of datasets</p> required <code>task_train_indices</code> <code>Dict[str, Iterable]</code> <p>Dictionary of train indices</p> required <code>task_val_indices</code> <code>Dict[str, Iterable]</code> <p>Dictionary of val indices</p> required <code>task_test_indices</code> <code>Dict[str, Iterable]</code> <p>Dictionary of test indices</p> required <p>Returns:</p> Name Type Description <code>train_singletask_datasets</code> <code>Subset</code> <p>Dictionary of train subsets</p> <code>val_singletask_datasets</code> <code>Subset</code> <p>Dictionary of val subsets</p> <code>test_singletask_datasets</code> <code>Subset</code> <p>Dictionary of test subsets</p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.load_data_from_cache","title":"<code>load_data_from_cache(verbose=True, compress=False)</code>","text":"<p>Load the datasets from cache. First create a hash for the dataset, and verify if that hash is available at the path given by <code>self.cache_data_path</code>.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>Whether to print the progress</p> <code>True</code> <code>compress</code> <code>bool</code> <p>Whether to compress the data</p> <code>False</code> <p>Returns:</p> Name Type Description <code>cache_data_exists</code> <code>bool</code> <p>Whether the cache exists (if the hash matches) and the loading succeeded</p>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.prepare_data","title":"<code>prepare_data()</code>","text":"<p>Called only from a single process in distributed settings. Steps:</p> <ul> <li>If each cache is set and exists, reload from cache and return. Otherwise,</li> <li>For each single-task dataset:<ul> <li>Load its dataframe from a path (if provided)</li> <li>Subsample the dataframe</li> <li>Extract the smiles, labels from the dataframe</li> </ul> </li> <li>In the previous step, we were also able to get the unique smiles, which we use to compute the features</li> <li>For each single-task dataframe and associated data (smiles, labels, etc.):<ul> <li>Filter out the data corresponding to molecules which failed featurization.</li> <li>Create a corresponding SingletaskDataset</li> <li>Split the SingletaskDataset according to the task-specific splits for train, val and test</li> </ul> </li> </ul>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.save_data_to_cache","title":"<code>save_data_to_cache(verbose=True, compress=False)</code>","text":"<p>Save the datasets from cache. First create a hash for the dataset, use it to generate a file name. Then save to the path given by <code>self.cache_data_path</code>.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>Whether to print the progress</p> <code>True</code> <code>compress</code> <code>bool</code> <p>Whether to compress the data</p> <code>False</code>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.setup","title":"<code>setup(stage=None, save_smiles_and_ids=False)</code>","text":"<p>Prepare the torch dataset. Called on every GPUs. Setting state here is ok.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>str</code> <p>Either 'fit', 'test', or None.</p> <code>None</code>"},{"location":"api/goli.data.html#goli.data.datamodule.MultitaskFromSmilesDataModule.to_dict","title":"<code>to_dict()</code>","text":"<p>Returns a dictionary representation of the current DataModule</p> <p>Returns:</p> Name Type Description <code>obj_repr</code> <code>Dict[str, Any]</code> <p>Dictionary representation of the current DataModule</p>"},{"location":"api/goli.data.html#goli.data.utils","title":"<code>goli.data.utils</code>","text":""},{"location":"api/goli.data.html#goli.data.utils.download_goli_dataset","title":"<code>download_goli_dataset(name, output_path, extract_zip=True, progress=False)</code>","text":"<p>Download a Goli dataset to a specified location.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the Goli dataset from <code>goli.data.utils.get_goli_datasets()</code>.</p> required <code>output_path</code> <code>str</code> <p>Directory path where to download the dataset to.</p> required <code>extract_zip</code> <code>bool</code> <p>Whether to extract the dataset if it's a zip file.</p> <code>True</code> <code>progress</code> <code>bool</code> <p>Whether to show a progress bar during download.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the downloaded dataset.</p>"},{"location":"api/goli.data.html#goli.data.utils.goli_package_path","title":"<code>goli_package_path(goli_path)</code>","text":"<p>Return the path of a goli file in the package.</p>"},{"location":"api/goli.data.html#goli.data.utils.list_goli_datasets","title":"<code>list_goli_datasets()</code>","text":"<p>List Goli datasets available to download.</p> <p>Returns:</p> Name Type Description <code>set</code> <code>set</code> <p>A set of Goli dataset names.</p>"},{"location":"api/goli.data.html#goli.data.utils.load_micro_zinc","title":"<code>load_micro_zinc()</code>","text":"<p>Return a dataframe of micro ZINC (1000 data points).</p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>pd.DataFrame: A dataframe of micro ZINC.</p>"},{"location":"api/goli.data.html#goli.data.utils.load_tiny_zinc","title":"<code>load_tiny_zinc()</code>","text":"<p>Return a dataframe of tiny ZINC (100 data points).</p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>pd.DataFrame: A dataframe of tiny ZINC.</p>"},{"location":"api/goli.features.html","title":"goli.features","text":""},{"location":"api/goli.features.html#goli.features.featurizer","title":"<code>goli.features.featurizer</code>","text":""},{"location":"api/goli.features.html#goli.features.featurizer.GraphDict","title":"<code>GraphDict</code>","text":"<p>         Bases: <code>dict</code></p>"},{"location":"api/goli.features.html#goli.features.featurizer.GraphDict.__init__","title":"<code>__init__(dic)</code>","text":"<p>Store the parameters required to initialize a <code>pyg.data.Data</code>, but as a dictionary to reduce memory consumption.</p> <p>Possible keys for the dictionary:</p> <ul> <li> <p>adj: A numpy array containing the adjacency matrix</p> </li> <li> <p>ndata: A dictionnary containing different keys and numpy     arrays associated to the node features.</p> </li> <li> <p>edata: A dictionnary containing different keys and numpy     arrays associated to the edge features.</p> </li> <li> <p>dtype: The numpy dtype for the floating data. The arrays     will be converted to <code>torch.Tensor</code> when building the graph.</p> </li> <li> <p>mask_nan:     Deal with molecules that fail a part of the featurization.     NaNs can happen when taking the of a noble gas,     or other properties that are not measured for specific atoms.</p> <ul> <li>\"raise\": Raise an error when there is a nan or inf in the featurization</li> <li>\"warn\": Raise a warning when there is a nan or inf in the featurization</li> <li>\"None\": DEFAULT. Don't do anything</li> <li>\"Floating value\": Replace nans or inf by the specified value</li> </ul> </li> </ul>"},{"location":"api/goli.features.html#goli.features.featurizer.GraphDict.make_pyg_graph","title":"<code>make_pyg_graph(**kwargs)</code>","text":"<p>Convert the current dictionary of parameters, containing an adjacency matrix with node/edge data into a <code>pyg.data.Data</code> of torch Tensors.</p> <p><code>**kwargs</code> can be used to overwrite any parameter from the current dictionary. See <code>GraphDict.__init__</code> for a list of parameters</p>"},{"location":"api/goli.features.html#goli.features.featurizer.get_estimated_bond_length","title":"<code>get_estimated_bond_length(bond, mol)</code>","text":"<p>Estimate the bond length between atoms by looking at the estimated atomic radius that depends both on the atom type and the bond type. The resulting bond-length is then the sum of the radius.</p> <p>Keep in mind that this function only provides an estimate of the bond length and not the true one based on a conformer. The vast majority od estimated bond lengths will have an error below 5% while some bonds can have an error up to 20%. This function is mostly useful when conformer generation fails for some molecules, or for increased computation speed.</p> <p>Parameters:</p> Name Type Description Default <code>bond</code> <code>Chem.rdchem.Bond</code> <p>The bond to measure its lenght</p> required <code>mol</code> <code>dm.Mol</code> <p>The molecule containing the bond (used to get neighbouring atoms)</p> required <p>Returns:</p> Name Type Description <code>bond_length</code> <code>float</code> <p>The bond length in Angstrom, typically a value around 1-2.</p>"},{"location":"api/goli.features.html#goli.features.featurizer.get_mol_atomic_features_float","title":"<code>get_mol_atomic_features_float(mol, property_list, offset_carbon=True, mask_nan='raise')</code>","text":"<p>Get a dictionary of floating-point arrays of atomic properties. To ensure all properties are at a similar scale, some of the properties are divided by a constant.</p> <p>There is also the possibility of offseting by the carbon value using the <code>offset_carbon</code> parameter.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>dm.Mol</code> <p>molecule from which to extract the properties</p> required <code>property_list</code> <code>Union[List[str], List[Callable]]</code> <p>A list of atomic properties to get from the molecule, such as 'atomic-number', 'mass', 'valence', 'degree', 'electronegativity'. Some elements are divided by a factor to avoid feature explosion.</p> <p>Accepted properties are:</p> <ul> <li>\"atomic-number\"</li> <li>\"mass\", \"weight\"</li> <li>\"valence\", \"total-valence\"</li> <li>\"implicit-valence\"</li> <li>\"hybridization\"</li> <li>\"chirality\"</li> <li>\"hybridization\"</li> <li>\"aromatic\"</li> <li>\"ring\", \"in-ring\"</li> <li>\"min-ring\"</li> <li>\"max-ring\"</li> <li>\"num-ring\"</li> <li>\"degree\"</li> <li>\"radical-electron\"</li> <li>\"formal-charge\"</li> <li>\"vdw-radius\"</li> <li>\"covalent-radius\"</li> <li>\"electronegativity\"</li> <li>\"ionization\", \"first-ionization\"</li> <li>\"melting-point\"</li> <li>\"metal\"</li> <li>\"single-bond\"</li> <li>\"aromatic-bond\"</li> <li>\"double-bond\"</li> <li>\"triple-bond\"</li> <li>\"is-carbon\"</li> <li>\"group\"</li> <li>\"period\"</li> </ul> required <code>offset_carbon</code> <code>bool</code> <p>Whether to subract the Carbon property from the desired atomic property. For example, if we want the mass of the Lithium (6.941), the mass of the Carbon (12.0107) will be subracted, resulting in a value of -5.0697</p> <code>True</code> <code>mask_nan</code> <code>Union[str, float, type(None)]</code> <p>Deal with molecules that fail a part of the featurization. NaNs can happen when taking the of a noble gas, or other properties that are not measured for specific atoms.</p> <ul> <li>\"raise\": Raise an error when there is a nan or inf in the featurization</li> <li>\"warn\": Raise a warning when there is a nan or inf in the featurization</li> <li>\"None\": DEFAULT. Don't do anything</li> <li>\"Floating value\": Replace nans or inf by the specified value</li> </ul> <code>'raise'</code> <p>Returns:</p> Name Type Description <code>prop_dict</code> <code>Dict[str, np.ndarray]</code> <p>A dictionnary where the element of <code>property_list</code> are the keys and the values are np.ndarray of shape (N,). N is the number of atoms in <code>mol</code>.</p>"},{"location":"api/goli.features.html#goli.features.featurizer.get_mol_atomic_features_onehot","title":"<code>get_mol_atomic_features_onehot(mol, property_list)</code>","text":"<p>Get the following set of features for any given atom</p> <ul> <li>One-hot representation of the atom</li> <li>One-hot representation of the atom degree</li> <li>One-hot representation of the atom implicit valence</li> <li>One-hot representation of the the atom hybridization</li> <li>Whether the atom is aromatic</li> <li>The atom's formal charge</li> <li>The atom's number of radical electrons</li> </ul> <p>Additionally, the following features can be set, depending on the value of input Parameters</p> <ul> <li>One-hot representation of the number of hydrogen atom in the the current atom neighborhood if <code>explicit_H</code> is false</li> <li>One-hot encoding of the atom chirality, and whether such configuration is even possible</li> </ul> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>dm.Mol</code> <p>molecule from which to extract the properties</p> required <code>property_list</code> <code>List[str]</code> <p>A list of integer atomic properties to get from the molecule. The integer values are converted to a one-hot vector. Callables are not supported by this function.</p> <p>Accepted properties are:</p> <ul> <li>\"atomic-number\"</li> <li>\"degree\"</li> <li>\"valence\", \"total-valence\"</li> <li>\"implicit-valence\"</li> <li>\"hybridization\"</li> <li>\"chirality\"</li> <li>\"phase\"</li> <li>\"type\"</li> <li>\"group\"</li> <li>\"period\"</li> </ul> required <p>Returns:</p> Name Type Description <code>prop_dict</code> <code>Dict[str, np.ndarray]</code> <p>A dictionnary where the element of <code>property_list</code> are the keys and the values are np.ndarray of shape (N, OH). N is the number of atoms in <code>mol</code> and OH the lenght of the one-hot encoding.</p>"},{"location":"api/goli.features.html#goli.features.featurizer.get_mol_conformer_features","title":"<code>get_mol_conformer_features(mol, property_list)</code>","text":"<p>obtain the conformer features of a molecule</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>dm.Mol</code> <p>molecule from which to extract the properties</p> required <code>property_list</code> <code>Union[List[str], List[Callable]]</code> <p>A list of conformer property to get from the molecule Accepted properties are: - \"positions_3d\"</p> required <p>Returns:</p> Name Type Description <code>prop_dict</code> <code>Dict[str, np.ndarray]</code> <p>a dictionary where the element of <code>property_list</code> are the keys</p>"},{"location":"api/goli.features.html#goli.features.featurizer.get_mol_edge_features","title":"<code>get_mol_edge_features(mol, property_list, mask_nan='raise')</code>","text":"<p>Get the following set of features for any given bond See <code>goli.features.nmp</code> for allowed values in one hot encoding</p> <ul> <li>One-hot representation of the bond type. Note that you should not kekulize your     molecules, if you expect this to take aromatic bond into account.</li> <li>Bond stereo type, following CIP classification</li> <li>Whether the bond is conjugated</li> <li>Whether the bond is in a ring</li> </ul> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>dm.Mol</code> <p>rdkit.Chem.Molecule the molecule of interest</p> required <code>property_list</code> <code>List[str]</code> <p>A list of edge properties to return for the given molecule. Accepted properties are:</p> <ul> <li>\"bond-type-onehot\"</li> <li>\"bond-type-float\"</li> <li>\"stereo\"</li> <li>\"in-ring\"</li> <li>\"conjugated\"</li> <li>\"conformer-bond-length\" (might cause problems with complex molecules)</li> <li>\"estimated-bond-length\"</li> </ul> required <p>Returns:</p> Name Type Description <code>prop_dict</code> <code>Dict[str, np.ndarray]</code> <p>A dictionnary where the element of <code>property_list</code> are the keys and the values are np.ndarray of shape (N,). N is the number of atoms in <code>mol</code>.</p>"},{"location":"api/goli.features.html#goli.features.featurizer.get_simple_mol_conformer","title":"<code>get_simple_mol_conformer(mol)</code>","text":"<p>If the molecule has a conformer, then it will return the conformer at idx <code>0</code>. Otherwise, it generates a simple molecule conformer using <code>rdkit.Chem.rdDistGeom.EmbedMolecule</code> and returns it. This is meant to be used in simple functions like <code>GetBondLength</code>, not in functions requiring complex 3D structure.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>dm.Mol</code> <p>Rdkit Molecule</p> required <p>Returns:</p> Name Type Description <code>conf</code> <code>Union[Chem.rdchem.Conformer, None]</code> <p>A conformer of the molecule, or <code>None</code> if it fails</p>"},{"location":"api/goli.features.html#goli.features.featurizer.mol_to_adj_and_features","title":"<code>mol_to_adj_and_features(mol, atom_property_list_onehot=[], atom_property_list_float=[], conformer_property_list=[], edge_property_list=[], add_self_loop=False, explicit_H=False, use_bonds_weights=False, pos_encoding_as_features=None, dtype=np.float16, mask_nan='raise')</code>","text":"<p>Transforms a molecule into an adjacency matrix representing the molecular graph and a set of atom and bond features.</p> <p>It also returns the positional encodings associated to the graph.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[str, dm.Mol]</code> <p>The molecule to be converted</p> required <code>atom_property_list_onehot</code> <code>List[str]</code> <p>List of the properties used to get one-hot encoding of the atom type, such as the atom index represented as a one-hot vector. See function <code>get_mol_atomic_features_onehot</code></p> <code>[]</code> <code>atom_property_list_float</code> <code>List[Union[str, Callable]]</code> <p>List of the properties used to get floating-point encoding of the atom type, such as the atomic mass or electronegativity. See function <code>get_mol_atomic_features_float</code></p> <code>[]</code> <code>conformer_property_list</code> <code>List[str]</code> <p>list of properties used to encode the conformer information, outside of atom properties, currently support \"positions_3d\"</p> <code>[]</code> <code>edge_property_list</code> <code>List[str]</code> <p>List of the properties used to encode the edges, such as the edge type and the stereo type.</p> <code>[]</code> <code>add_self_loop</code> <code>bool</code> <p>Whether to add a value of <code>1</code> on the diagonal of the adjacency matrix.</p> <code>False</code> <code>explicit_H</code> <code>bool</code> <p>Whether to consider the Hydrogens explicitely. If <code>False</code>, the hydrogens are implicit.</p> <code>False</code> <code>use_bonds_weights</code> <code>bool</code> <p>Whether to use the floating-point value of the bonds in the adjacency matrix, such that single bonds are represented by 1, double bonds 2, triple 3, aromatic 1.5</p> <code>False</code> <code>pos_encoding_as_features</code> <code>Dict[str, Any]</code> <p>keyword arguments for function <code>graph_positional_encoder</code> to generate positional encoding for node features.</p> <code>None</code> <code>dtype</code> <code>np.dtype</code> <p>The numpy data type used to build the graph</p> <code>np.float16</code> <code>mask_nan</code> <code>Union[str, float, type(None)]</code> <p>Deal with molecules that fail a part of the featurization. NaNs can happen when taking the of a noble gas, or other properties that are not measured for specific atoms.</p> <ul> <li>\"raise\": Raise an error when there is a nan or inf in the featurization</li> <li>\"warn\": Raise a warning when there is a nan or inf in the featurization</li> <li>\"None\": DEFAULT. Don't do anything</li> <li>\"Floating value\": Replace nans or inf by the specified value</li> </ul> <code>'raise'</code> <p>Returns:</p> Name Type Description <code>adj</code> <code>Union[coo_matrix, Union[np.ndarray, None], Union[np.ndarray, None], Dict[str, np.ndarray], Union[np.ndarray, None], Dict[str, np.ndarray]]</code> <p>Scipy sparse adjacency matrix of the molecule</p> <code>ndata</code> <code>Union[coo_matrix, Union[np.ndarray, None], Union[np.ndarray, None], Dict[str, np.ndarray], Union[np.ndarray, None], Dict[str, np.ndarray]]</code> <p>Concatenated node data of the atoms, based on the properties from <code>atom_property_list_onehot</code> and <code>atom_property_list_float</code>. If no properties are given, it returns <code>None</code></p> <code>edata</code> <code>Union[coo_matrix, Union[np.ndarray, None], Union[np.ndarray, None], Dict[str, np.ndarray], Union[np.ndarray, None], Dict[str, np.ndarray]]</code> <p>Concatenated node edge of the molecule, based on the properties from <code>edge_property_list</code>. If no properties are given, it returns <code>None</code></p> <code>pe_dict</code> <code>Union[coo_matrix, Union[np.ndarray, None], Union[np.ndarray, None], Dict[str, np.ndarray], Union[np.ndarray, None], Dict[str, np.ndarray]]</code> <p>Dictionary of all positional encodings. Current supported keys:</p> <ul> <li> <p>\"pos_enc_feats_sign_flip\":     Node positional encoding that requires augmentation via sign-flip.     For example, eigenvectors of the Laplacian are ambiguous to the     sign and are returned here.</p> </li> <li> <p>\"pos_enc_feats_no_flip\":     Node positional encoding that requires does not use sign-flip.     For example, distance from centroid are returned here.</p> </li> <li> <p>\"rwse\":     Node structural encoding corresponding to the diagonal of the random     walk matrix</p> </li> </ul> <code>conf_dict</code> <code>Union[coo_matrix, Union[np.ndarray, None], Union[np.ndarray, None], Dict[str, np.ndarray], Union[np.ndarray, None], Dict[str, np.ndarray]]</code> <p>contains the 3d positions of a conformer of the molecule or 0s if none is found</p>"},{"location":"api/goli.features.html#goli.features.featurizer.mol_to_graph_dict","title":"<code>mol_to_graph_dict(mol, atom_property_list_onehot=[], atom_property_list_float=[], conformer_property_list=[], edge_property_list=[], add_self_loop=False, explicit_H=False, use_bonds_weights=False, pos_encoding_as_features=None, dtype=np.float16, on_error='ignore', mask_nan='raise', max_num_atoms=None)</code>","text":"<p>Transforms a molecule into an adjacency matrix representing the molecular graph and a set of atom and bond features, and re-organizes them into a dictionary that allows to build a <code>pyg.data.Data</code> object.</p> <p>Compared to <code>mol_to_pyggraph</code>, this function does not build the graph directly, and is thus faster, less memory heavy, and compatible with other frameworks.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>dm.Mol</code> <p>The molecule to be converted</p> required <code>atom_property_list_onehot</code> <code>List[str]</code> <p>List of the properties used to get one-hot encoding of the atom type, such as the atom index represented as a one-hot vector. See function <code>get_mol_atomic_features_onehot</code></p> <code>[]</code> <code>atom_property_list_float</code> <code>List[Union[str, Callable]]</code> <p>List of the properties used to get floating-point encoding of the atom type, such as the atomic mass or electronegativity. See function <code>get_mol_atomic_features_float</code></p> <code>[]</code> <code>conformer_property_list</code> <code>List[str]</code> <p>list of properties used to encode the conformer information, outside of atom properties, currently support \"positions_3d\"</p> <code>[]</code> <code>edge_property_list</code> <code>List[str]</code> <p>List of the properties used to encode the edges, such as the edge type and the stereo type.</p> <code>[]</code> <code>add_self_loop</code> <code>bool</code> <p>Whether to add a value of <code>1</code> on the diagonal of the adjacency matrix.</p> <code>False</code> <code>explicit_H</code> <code>bool</code> <p>Whether to consider the Hydrogens explicitely. If <code>False</code>, the hydrogens are implicit.</p> <code>False</code> <code>use_bonds_weights</code> <code>bool</code> <p>Whether to use the floating-point value of the bonds in the adjacency matrix, such that single bonds are represented by 1, double bonds 2, triple 3, aromatic 1.5</p> <code>False</code> <code>pos_encoding_as_features</code> <code>Dict[str, Any]</code> <p>keyword arguments for function <code>graph_positional_encoder</code> to generate positional encoding for node features.</p> <code>None</code> <code>dtype</code> <code>np.dtype</code> <p>The numpy data type used to build the graph</p> <code>np.float16</code> <code>on_error</code> <code>str</code> <p>What to do when the featurization fails. This can change the behavior of <code>mask_nan</code>.</p> <ul> <li>\"raise\": Raise an error</li> <li>\"warn\": Raise a warning and return a string of the error</li> <li>\"ignore\": Ignore the error and return a string of the error</li> </ul> <code>'ignore'</code> <code>mask_nan</code> <code>Union[str, float, type(None)]</code> <p>Deal with molecules that fail a part of the featurization. NaNs can happen when taking the of a noble gas, or other properties that are not measured for specific atoms.</p> <ul> <li>\"raise\": Raise an error when there is a nan or inf in the featurization</li> <li>\"warn\": Raise a warning when there is a nan or inf in the featurization</li> <li>\"None\": DEFAULT. Don't do anything</li> <li>\"Floating value\": Replace nans or inf by the specified value</li> </ul> <code>'raise'</code> <code>max_num_atoms</code> <code>Optional[int]</code> <p>Maximum number of atoms for a given molecule. If a molecule with more atoms is give, an error is raised, but catpured according to the rules of <code>on_error</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>graph_dict</code> <code>Union[GraphDict, str]</code> <p>A dictionary <code>GraphDict</code> containing the keys required to build a graph, and which can be used to build a PyG graph. If it fails to featurize the molecule, it returns a string with the error.</p> <ul> <li> <p>\"adj\": A sparse int-array containing the adjacency matrix</p> </li> <li> <p>\"ndata\": A dictionnary containing different keys and numpy   arrays associated to the node features.</p> </li> <li> <p>\"edata\": A dictionnary containing different keys and numpy   arrays associated to the edge features.</p> </li> <li> <p>\"dtype\": The numpy dtype for the floating data.</p> </li> </ul>"},{"location":"api/goli.features.html#goli.features.featurizer.mol_to_graph_signature","title":"<code>mol_to_graph_signature(featurizer_args=None)</code>","text":"<p>Get the default arguments of <code>mol_to_graph_dict</code> and update it with a provided dict of arguments in order to get a fulle signature of the featurizer args actually used for the features computation.</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_args</code> <code>Dict[str, Any]</code> <p>A dictionary of featurizer arguments to update</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of featurizer arguments</p>"},{"location":"api/goli.features.html#goli.features.featurizer.mol_to_pyggraph","title":"<code>mol_to_pyggraph(mol, atom_property_list_onehot=[], atom_property_list_float=[], conformer_property_list=[], edge_property_list=[], add_self_loop=False, explicit_H=False, use_bonds_weights=False, pos_encoding_as_features=None, dtype=np.float16, on_error='ignore', mask_nan='raise', max_num_atoms=None)</code>","text":"<p>Transforms a molecule into an adjacency matrix representing the molecular graph and a set of atom and bond features.</p> <p>Then, the adjacency matrix and node/edge features are used to build a <code>pyg.data.Data</code> with pytorch Tensors.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>dm.Mol</code> <p>The molecule to be converted</p> required <code>atom_property_list_onehot</code> <code>List[str]</code> <p>List of the properties used to get one-hot encoding of the atom type, such as the atom index represented as a one-hot vector. See function <code>get_mol_atomic_features_onehot</code></p> <code>[]</code> <code>atom_property_list_float</code> <code>List[Union[str, Callable]]</code> <p>List of the properties used to get floating-point encoding of the atom type, such as the atomic mass or electronegativity. See function <code>get_mol_atomic_features_float</code></p> <code>[]</code> <code>conformer_property_list</code> <code>List[str]</code> <p>list of properties used to encode the conformer information, outside of atom properties, currently support \"positions_3d\"</p> <code>[]</code> <code>edge_property_list</code> <code>List[str]</code> <p>List of the properties used to encode the edges, such as the edge type and the stereo type.</p> <code>[]</code> <code>add_self_loop</code> <code>bool</code> <p>Whether to add a value of <code>1</code> on the diagonal of the adjacency matrix.</p> <code>False</code> <code>explicit_H</code> <code>bool</code> <p>Whether to consider the Hydrogens explicitely. If <code>False</code>, the hydrogens are implicit.</p> <code>False</code> <code>use_bonds_weights</code> <code>bool</code> <p>Whether to use the floating-point value of the bonds in the adjacency matrix, such that single bonds are represented by 1, double bonds 2, triple 3, aromatic 1.5</p> <code>False</code> <code>pos_encoding_as_features</code> <code>Dict[str, Any]</code> <p>keyword arguments for function <code>graph_positional_encoder</code> to generate positional encoding for node features.</p> <code>None</code> <code>dtype</code> <code>np.dtype</code> <p>The numpy data type used to build the graph</p> <code>np.float16</code> <code>on_error</code> <code>str</code> <p>What to do when the featurization fails. This can change the behavior of <code>mask_nan</code>.</p> <ul> <li>\"raise\": Raise an error</li> <li>\"warn\": Raise a warning and return a string of the error</li> <li>\"ignore\": Ignore the error and return a string of the error</li> </ul> <code>'ignore'</code> <code>mask_nan</code> <code>Union[str, float, type(None)]</code> <p>Deal with molecules that fail a part of the featurization. NaNs can happen when taking the of a noble gas, or other properties that are not measured for specific atoms.</p> <ul> <li>\"raise\": Raise an error when there is a nan in the featurization</li> <li>\"warn\": Raise a warning when there is a nan in the featurization</li> <li>\"None\": DEFAULT. Don't do anything</li> <li>\"Floating value\": Replace nans by the specified value</li> </ul> <code>'raise'</code> <code>max_num_atoms</code> <code>Optional[int]</code> <p>Maximum number of atoms for a given molecule. If a molecule with more atoms is give, an error is raised, but catpured according to the rules of <code>on_error</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>graph</code> <code>Union[Data, str]</code> <p>Pyg graph, with <code>graph['feat']</code> corresponding to the concatenated node data from <code>atom_property_list_onehot</code> and <code>atom_property_list_float</code>, <code>graph['edge_feat']</code> corresponding to the concatenated edge data from <code>edge_property_list</code>. There are also additional entries for the positional encodings.</p>"},{"location":"api/goli.features.html#goli.features.featurizer.to_dense_array","title":"<code>to_dense_array(array, dtype=None)</code>","text":"<p>Assign the node data</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>np.ndarray</code> <p>The array to convert to dense</p> required <code>dtype</code> <code>str</code> <p>The dtype of the array</p> <code>None</code> <p>Returns:</p> Type Description <code>np.ndarray</code> <p>The dense array</p>"},{"location":"api/goli.features.html#goli.features.nmp","title":"<code>goli.features.nmp</code>","text":""},{"location":"api/goli.features.html#goli.features.nmp.float_or_none","title":"<code>float_or_none(string)</code>","text":"<p>check if a string can be converted to float, return none if it can't</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <code>str</code> <p>str</p> required <p>Returns:</p> Name Type Description <code>val</code> <code>Union[float, None]</code> <p>float or None</p>"},{"location":"api/goli.features.html#goli.features.positional_encoding","title":"<code>goli.features.positional_encoding</code>","text":""},{"location":"api/goli.features.html#goli.features.positional_encoding.get_all_positional_encoding","title":"<code>get_all_positional_encoding(adj, num_nodes, pos_encoding_as_features=None)</code>","text":"<p>Get features positional encoding.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>Union[np.ndarray, spmatrix]</code> <p>Adjacency matrix of the graph</p> required <code>num_nodes</code> <code>int</code> <p>Number of nodes in the graph</p> required <code>pos_encoding_as_features</code> <code>Optional[Dict]</code> <p>keyword arguments for function <code>graph_positional_encoder</code> to generate positional encoding for node features.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>pe_dict</code> <code>Tuple[ndarray], ndarray]]</code> <p>Dictionary of positional and structural encodings</p>"},{"location":"api/goli.features.html#goli.features.positional_encoding.graph_positional_encoder","title":"<code>graph_positional_encoder(adj, num_nodes, pos_arg)</code>","text":"<p>Get a positional encoding that depends on the parameters.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>Union[np.ndarray, spmatrix]</code> <p>Adjacency matrix of the graph</p> required <code>pos_type</code> <p>The type of positional encoding to use. Supported types are:</p> <ul> <li>laplacian_eigvec</li> <li>laplacian_eigvec_eigval</li> <li>rwse</li> <li>gaussian_kernel</li> </ul> required <p>Returns:</p> Name Type Description <code>pe_dict</code> <code>Dict[str, np.ndarray]</code> <p>Dictionary of positional and structural encodings</p>"},{"location":"api/goli.features.html#goli.features.properties","title":"<code>goli.features.properties</code>","text":""},{"location":"api/goli.features.html#goli.features.properties.get_prop_or_none","title":"<code>get_prop_or_none(prop, n, *args, **kwargs)</code>","text":"<p>return properties. If error, return list of <code>None</code> with lenght <code>n</code>.</p> <p>Parameters:</p> Name Type Description Default <code>prop</code> <code>Callable</code> <p>The property to compute.</p> required <code>n</code> <code>int</code> <p>The number of elements in the property.</p> required <code>*args</code> <code>Union[dm.Mol, str]</code> <p>The arguments to pass to the property.</p> <code>()</code> <code>**kwargs</code> <code>Union[dm.Mol, str]</code> <p>The keyword arguments to pass to the property.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[List[float], List[None]]</code> <p>The property or a list of <code>None</code> with lenght <code>n</code>.</p>"},{"location":"api/goli.features.html#goli.features.properties.get_props_from_mol","title":"<code>get_props_from_mol(mol, properties='autocorr3d')</code>","text":"<p>Function to get a given set of desired properties from a molecule, and output a property list.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[dm.Mol, str]</code> <p>The molecule from which to compute the properties.</p> required <code>properties</code> <code>Union[List[str], str]</code> <p>The list of properties to compute for each molecule. It can be the following:</p> <ul> <li>'descriptors'</li> <li>'autocorr3d'</li> <li>'rdf'</li> <li>'morse'</li> <li>'whim'</li> <li>'all'</li> </ul> <code>'autocorr3d'</code> <p>Returns:</p> Name Type Description <code>props</code> <code>np.ndarray</code> <p>np.array(float) The array of properties for the desired molecule</p> <code>classes_start_idx</code> <code>np.ndarray</code> <p>list(int) The list of index specifying the start of each new class of descriptor or property. For example, if props has 20 elements, the first 5 are rotatable bonds, the next 8 are morse, and the rest are whim, then <code>classes_start_idx = [0, 5, 13]</code>. This will mainly be useful to normalize the features of each class.</p> <code>classes_names</code> <code>np.ndarray</code> <p>list(str) The name of the classes associated to each starting index. Will be usefull to understand what property is the network learning.</p>"},{"location":"api/goli.features.html#goli.features.rw","title":"<code>goli.features.rw</code>","text":""},{"location":"api/goli.features.html#goli.features.rw.compute_rwse","title":"<code>compute_rwse(adj, ksteps, num_nodes)</code>","text":"<p>Compute Random Walk Spectral Embedding (RWSE) for given list of K steps.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>Union[np.ndarray, spmatrix]</code> <p>Adjacency matrix</p> required <code>ksteps</code> <code>int</code> <p>Number of steps for the random walk</p> required <code>num_nodes</code> <code>int</code> <p>Number of nodes in the graph</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>2D array with shape (num_nodes, len(ksteps)) with Random-Walk landing probs</p>"},{"location":"api/goli.features.html#goli.features.rw.get_rw_landing_probs","title":"<code>get_rw_landing_probs(ksteps, edge_index, edge_weight=None, num_nodes=None, space_dim=0.0)</code>","text":"<p>Compute Random Walk landing probabilities for given list of K steps.</p> <p>Parameters:</p> Name Type Description Default <code>ksteps</code> <code>int</code> <p>List of k-steps for which to compute the RW landings</p> required <code>edge_index</code> <code>Tuple[torch.Tensor, torch.Tensor]</code> <p>PyG sparse representation of the graph</p> required <code>edge_weight</code> <code>Optional[torch.Tensor]</code> <p>Edge weights</p> <code>None</code> <code>num_nodes</code> <code>Optional[int]</code> <p>Number of nodes in the graph</p> <code>None</code> <code>space_dim</code> <code>float</code> <p>Estimated dimensionality of the space. Used to correct the random-walk diagonal by a factor <code>k^(space_dim/2)</code>. In euclidean space, this correction means that the height of the gaussian distribution stays almost constant across the number of steps, if <code>space_dim</code> is the dimension of the euclidean space.</p> <code>0.0</code> <p>Returns:</p> Type Description <p>2D Tensor with shape (num_nodes, len(ksteps)) with RW landing probs</p>"},{"location":"api/goli.features.html#goli.features.spectral","title":"<code>goli.features.spectral</code>","text":""},{"location":"api/goli.features.html#goli.features.spectral.compute_laplacian_positional_eigvecs","title":"<code>compute_laplacian_positional_eigvecs(adj, num_pos, disconnected_comp=True, normalization='none')</code>","text":"<p>Compute the Laplacian eigenvalues and eigenvectors of the Laplacian of the graph.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>Union[np.ndarray, spmatrix]</code> <p>Adjacency matrix of the graph</p> required <code>num_pos</code> <code>int</code> <p>Number of Laplacian eigenvectors to compute</p> required <code>disconnected_comp</code> <code>bool</code> <p>Whether to compute the eigenvectors for each connected component</p> <code>True</code> <code>normalization</code> <code>str</code> <p>Normalization to apply to the Laplacian</p> <code>'none'</code> <p>Returns:</p> Name Type Description <code>eigvals_tile</code> <code>np.ndarray</code> <p>Eigenvalues of the Laplacian</p> <code>eigvecs</code> <code>np.ndarray</code> <p>Eigenvectors of the Laplacian</p>"},{"location":"api/goli.features.html#goli.features.spectral.normalize_matrix","title":"<code>normalize_matrix(matrix, degree_vector=None, normalization=None)</code>","text":"<p>Normalize a given matrix using its degree vector</p>"},{"location":"api/goli.features.html#goli.features.spectral.normalize_matrix--parameters","title":"Parameters","text":"<pre><code>matrix: torch.tensor(N, N) or scipy.sparse.spmatrix(N, N)\n    A square matrix representing either an Adjacency matrix or a Laplacian.\n\ndegree_vector: torch.tensor(N) or np.ndarray(N) or None\n    A vector representing the degree of ``matrix``.\n    ``None`` is only accepted if ``normalization==None``\n\nnormalization: str or None, Default='none'\n    Normalization to use on the eig_matrix\n\n    - 'none' or ``None``: no normalization\n\n    - 'sym': Symmetric normalization ``D^-0.5 L D^-0.5``\n\n    - 'inv': Inverse normalization ``D^-1 L``\n</code></pre>"},{"location":"api/goli.features.html#goli.features.spectral.normalize_matrix--returns","title":"Returns","text":"<pre><code>matrix: torch.tensor(N, N) or scipy.sparse.spmatrix(N, N)\n    The normalized matrix\n</code></pre>"},{"location":"api/goli.ipu.html","title":"goli.ipu","text":""},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader","title":"<code>goli.ipu.ipu_dataloader</code>","text":""},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.CombinedBatchingCollator","title":"<code>CombinedBatchingCollator</code>","text":"Collator object that manages the combined batch size defined as <p>combined_batch_size = batch_size * device_iterations                      * replication_factor * gradient_accumulation</p> <p>This is intended to be used in combination with the poptorch.DataLoader</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.CombinedBatchingCollator.__call__","title":"<code>__call__(batch)</code>","text":"<p>padding option to pad each batch to be same size.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Batch</code> <p>The batch of pyg-graphs to be padded</p> required <p>Returns:</p> Name Type Description <code>batch</code> <code>Batch</code> <p>The padded batch</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.CombinedBatchingCollator.__init__","title":"<code>__init__(batch_size, max_num_nodes, max_num_edges, dataset_max_nodes_per_graph, dataset_max_edges_per_graph, collate_fn=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>mini batch size used by the model</p> required <code>max_num_nodes</code> <code>int</code> <p>Maximum number of nodes in the batched padded graph</p> required <code>max_num_edges</code> <code>int</code> <p>Maximum number of edges in the batched padded graph</p> required <code>dataset_max_nodes_per_graph</code> <code>int</code> <p>Maximum number of nodes per graph in the full dataset</p> required <code>dataset_max_edges_per_graph</code> <code>int</code> <p>Maximum number of edges per graph in the full dataset</p> required <code>collate_fn</code> <code>Optional[Callable]</code> <p>Function used to collate (or batch) the single data or graphs together</p> <code>None</code>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.IPUDataloaderOptions","title":"<code>IPUDataloaderOptions</code>  <code>dataclass</code>","text":"<p>This data class stores the arguments necessary to instantiate a model for the Predictor.</p> <p>Parameters:</p> Name Type Description Default <code>model_class</code> <p>pytorch module used to create a model</p> required <code>model_kwargs</code> <p>Key-word arguments used to initialize the model from <code>model_class</code>.</p> required"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.MolPack","title":"<code>MolPack</code>","text":"<p>Class that keeps track of the number of atoms and indices that are added to each pack. Useful when doing packing, or other forms of smart batching. A pack is a batch, but with optimized memory consumption.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.MolPack.__repr__","title":"<code>__repr__()</code>","text":"<p>Print the main attributes of the current class</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.MolPack.add_mol","title":"<code>add_mol(num_nodes, idx)</code>","text":"<p>Add a molecule and it's index to the batch</p> <p>Parameters:</p> Name Type Description Default <code>num_nodes</code> <code>int</code> <p>Number of atoms of the new molecule</p> required <code>idx</code> <code>int</code> <p>Index associated to the molecule</p> required"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.MolPack.expected_atoms","title":"<code>expected_atoms(remaining_mean_num_nodes, batch_size)</code>","text":"<p>Given a desired batch size, and given the remaining mean number of atoms, find the expected number of atoms of the current batch when it is full</p> <p>Parameters:</p> Name Type Description Default <code>remaining_mean_num_nodes</code> <code>float</code> <p>Average number of atoms per molecule left to be sampled and distributed across tasks.</p> required <code>batch_size</code> <code>int</code> <p>Desired batch size</p> required <p>Returns:</p> Name Type Description <code>expected_atoms</code> <code>float</code> <p>The expected number of atoms in this batch if we sample randomly the remaining molecules.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.Pad","title":"<code>Pad</code>","text":"<p>         Bases: <code>BaseTransform</code></p> <p>Data transform that applies padding to enforce consistent tensor shapes.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.Pad.__call__","title":"<code>__call__(batch)</code>","text":"<p>Pad the batch with a fake graphs that has the desired number of nodes and edges.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.Pad.__init__","title":"<code>__init__(max_num_nodes, dataset_max_nodes_per_graph, dataset_max_edges_per_graph, max_num_edges=None, node_value=0, edge_value=0)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>max_num_nodes</code> <code>int</code> <p>The maximum number of nodes for the total padded graph</p> required <code>dataset_max_nodes_per_graph</code> <p>the maximum number of nodes per graph in the dataset</p> required <code>dataset_max_edges_per_graph</code> <p>the maximum number of edges per graph in the dataset</p> required <code>max_num_edges</code> <code>Optional[int]</code> <p>The maximum number of edges for the total padded graph</p> <code>None</code> <code>node_value</code> <code>float</code> <p>Value to add to the node padding</p> <code>0</code> <code>edge_value</code> <code>float</code> <p>Value to add to the edge padding</p> <code>0</code>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.Pad.validate","title":"<code>validate(data)</code>","text":"Validates that the input graph does not exceed the constraints that <ul> <li>the number of nodes must be &lt;= max_num_nodes</li> <li>the number of edges must be &lt;= max_num_edges</li> </ul> <p>Returns:</p> Type Description <p>Tuple containing the number nodes and the number of edges</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.create_ipu_dataloader","title":"<code>create_ipu_dataloader(dataset, ipu_dataloader_options, ipu_options=None, batch_size=1, collate_fn=None, num_workers=0, **kwargs)</code>","text":"<p>Creates a poptorch.DataLoader for graph datasets Applies the mini-batching method of concatenating multiple graphs into a single graph with multiple disconnected subgraphs. See: https://pytorch-geometric.readthedocs.io/en/2.0.2/notes/batching.html</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The torch_geometric.data.Dataset instance from which to load the graph examples for the IPU.</p> required <code>ipu_dataloader_options</code> <code>IPUDataloaderOptions</code> <p>The options to initialize the Dataloader for IPU</p> required <code>ipu_options</code> <code>Optional[Options]</code> <p>The poptorch.Options used by the poptorch.DataLoader. Will use the default options if not provided.</p> <code>None</code> <code>batch_size</code> <code>Optional[int]</code> <p>How many graph examples to load in each batch (default: 1).</p> <code>1</code> <code>collate_fn</code> <p>The function used to collate batches</p> <code>None</code> <code>**kwargs</code> <code>optional</code> <p>Additional arguments of :class:<code>poptorch.DataLoader</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataLoader</code> <p>The dataloader</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.estimate_max_pack_node_size","title":"<code>estimate_max_pack_node_size(num_nodes, batch_size, combined_batch_size)</code>","text":"<p>Estimate the value of <code>max_num_nodes</code>, which represents the maximum number of nodes needed in a batch to fit the data.</p> <p>Parameters:</p> Name Type Description Default <code>num_nodes</code> <code>Iterable[int]</code> <p>Number of nodes for all the graphs in the dataset</p> required <code>batch_size</code> <code>int</code> <p>The regular batch size per IPU</p> required <code>combined_batch_size</code> <code>int</code> <p>batch_size * device_iterations                  * replication_factor * gradient_accumulation</p> required"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.fast_packing","title":"<code>fast_packing(num_nodes, batch_size)</code>","text":"<p>Super fast algorithm for packing graphs such that each batch has roughly the same number of atoms. Not as good as <code>smart_packing</code> but faster and more scalable for-loop complexity of <code>O(batch_size)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_nodes</code> <code>List[int]</code> <p>List of the number of atoms per molecule for the entire global batch. Must be of length <code>batch_size * ipu_batch_size</code>.</p> required <code>batch_size</code> <code>int</code> <p>The batch size per iteration, considering a single device and single forward pass. The global batch size is <code>batch_size * device_iterations * replication_factor * gradient_accumulation</code></p> required <p>Returns:</p> Name Type Description <code>packed_indices</code> <code>List[List[int]]</code> <p>A list of packs, each containing a list of indices, such that if we collect <code>num_nodes</code> from the indices, then each pack has roughly the same total number of atoms.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.get_pack_sizes","title":"<code>get_pack_sizes(packed_indices, num_nodes)</code>","text":"<p>Get the number of atoms of each pack</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.hybrid_packing","title":"<code>hybrid_packing(num_nodes, batch_size)</code>","text":"<p>Uses a combination of the <code>smart_packing</code> <code>O(n^2)</code> on the most important data points, and the <code>fast_packing</code> <code>O(n)</code> on the average-sized data points.</p> <p>Depending on the expected complexity</p> <p>Parameters:</p> Name Type Description Default <code>num_nodes</code> <code>List[int]</code> <p>List of the number of atoms per molecule for the entire global batch. Must be of length <code>batch_size * ipu_batch_size</code>.</p> required <code>batch_size</code> <code>int</code> <p>The batch size per iteration, considering a single device and single forward pass. The global batch size is <code>batch_size * device_iterations * replication_factor * gradient_accumulation</code></p> required <p>Returns:</p> Name Type Description <code>packed_indices</code> <code>List[List[int]]</code> <p>A list of packs, each containing a list of indices, such that if we collect <code>num_nodes</code> from the indices, then each pack has roughly the same total number of atoms.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_dataloader.smart_packing","title":"<code>smart_packing(num_nodes, batch_size)</code>","text":"<p>Simple and fast algorithm for packing graphs such that each batch has roughly the same number of atoms. Has for-loop scalability issues <code>O(num_graphs * ipu_batch_size)</code> = <code>O(num_graphs^2 / batch_size)</code></p> <p>Parameters:</p> Name Type Description Default <code>num_nodes</code> <code>List[int]</code> <p>List of the number of atoms per molecule for the entire global batch. Must be of length <code>batch_size * ipu_batch_size</code>.</p> required <code>batch_size</code> <code>int</code> <p>The batch size per iteration, considering a single device and single forward pass. The global batch size is <code>batch_size * device_iterations * replication_factor * gradient_accumulation</code></p> required <p>Returns:</p> Name Type Description <code>packed_indices</code> <code>List[List[int]]</code> <p>A list of packs, each containing a list of indices, such that if we collect <code>num_nodes</code> from the indices, then each pack has roughly the same total number of atoms.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_losses","title":"<code>goli.ipu.ipu_losses</code>","text":""},{"location":"api/goli.ipu.html#goli.ipu.ipu_losses.BCELossIPU","title":"<code>BCELossIPU</code>","text":"<p>         Bases: <code>BCELoss</code></p> <p>A modified version of the <code>torch.nn.BCELoss</code> that can ignore NaNs by giving them a weight of <code>0</code>. This allows it to work with compilation and IPUs since it doesn't modify the tensor's shape.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_losses.L1LossIPU","title":"<code>L1LossIPU</code>","text":"<p>         Bases: <code>L1Loss</code></p> <p>A modified version of the <code>torch.nn.L1Loss</code> that can ignore NaNs by giving them the same value for both <code>input</code> and <code>target</code>. This allows it to work with compilation and IPUs since it doesn't modify the tensor's shape.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_losses.MSELossIPU","title":"<code>MSELossIPU</code>","text":"<p>         Bases: <code>MSELoss</code></p> <p>A modified version of the <code>torch.nn.MSELoss</code> that can ignore NaNs by giving them the same value for both <code>input</code> and <code>target</code>. This allows it to work with compilation and IPUs since it doesn't modify the tensor's shape.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics","title":"<code>goli.ipu.ipu_metrics</code>","text":""},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.NaNTensor","title":"<code>NaNTensor</code>","text":"<p>         Bases: <code>Tensor</code></p> <p>Class to create and manage a NaN tensor along it's properties</p> <p>The goal of the class is to override the regular tensor such that the basic operations (sum, mean, max, etc) ignore the NaNs in the input. It also supports NaNs in integer tensors (as the lowest integer possible).</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.NaNTensor.get_nans","title":"<code>get_nans: BoolTensor</code>  <code>property</code>","text":"<p>Gets the boolean Tensor containing the location of NaNs. In the case of an integer tensor, this returns where the tensor is equal to its minimal value In the case of a boolean tensor, this returns a Tensor filled with <code>False</code></p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.NaNTensor.__lt__","title":"<code>__lt__(other)</code>","text":"<p>Stupid fix that allows the code to work with <code>r2_score</code>, since it requires the size to be &gt; 2. But since <code>self.size</code> now returns a Tensor instead of a value, we check that all elements are &gt; 2.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.NaNTensor.__torch_function__","title":"<code>__torch_function__(func, types, args=(), kwargs=None)</code>  <code>classmethod</code>","text":"<p>This torch_function implementation wraps subclasses such that methods called on subclasses return a subclass instance instead of a <code>torch.Tensor</code> instance.</p> <p>One corollary to this is that you need coverage for torch.Tensor methods if implementing torch_function for subclasses.</p> <p>Affects the call torch.sum() as to behave the same way as NaNTensor.sum()</p> <p>We recommend always calling <code>super().__torch_function__</code> as the base case when doing the above.</p> <p>While not mandatory, we recommend making <code>__torch_function__</code> a classmethod.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.NaNTensor.argsort","title":"<code>argsort(dim=-1, descending=False)</code>","text":"<p>Return the indices that sort the tensor, while putting all the NaNs to the end of the sorting.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.NaNTensor.max","title":"<code>max(*args, **kwargs)</code>","text":"<p>Returns the max vale of a tensor whitout NaNs</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.NaNTensor.mean","title":"<code>mean(*args, **kwargs)</code>","text":"<p>Overloads the traditional mean to ignore the NaNs</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.NaNTensor.min","title":"<code>min(*args, **kwargs)</code>","text":"<p>Returns the min vale of a tensor whitout NaNs</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.NaNTensor.numel","title":"<code>numel()</code>","text":"<p>Returns the number of non-NaN elements.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.NaNTensor.size","title":"<code>size(dim)</code>","text":"<p>Instead of returning the size, return the number of non-NaN elements in a specific dimension. Useful for the <code>r2_score</code> metric.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.NaNTensor.sum","title":"<code>sum(*args, **kwargs)</code>","text":"<p>Overloads the traditional sum to ignore the NaNs</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.accuracy_ipu","title":"<code>accuracy_ipu(preds, target, average='micro', mdmc_average='global', threshold=0.5, top_k=None, subset_accuracy=False, num_classes=None, multiclass=None, ignore_index=None)</code>","text":"<p>A modified version of the <code>torchmetrics.functional.accuracy</code> that can ignore NaNs by giving them the same value for both <code>preds</code> and <code>target</code>. This allows it to work with compilation and IPUs since it doesn't modify the tensor's shape.</p> <p>Parameters:</p> Name Type Description Default <code>preds</code> <code>Tensor</code> <p>Predictions from model (probabilities, logits or labels)</p> required <code>target</code> <code>Tensor</code> <p>Ground truth labels</p> required <code>average</code> <code>Optional[str]</code> <p>Defines the reduction that is applied. Should be one of the following:</p> <ul> <li><code>'micro'</code> [default]: Calculate the metric globally, across all samples and classes.</li> <li><code>'macro'</code>: Calculate the metric for each class separately, and average the   metrics across classes (with equal weights for each class).</li> <li><code>'weighted'</code>: Calculate the metric for each class separately, and average the   metrics across classes, weighting each class by its support (<code>tp + fn</code>).</li> <li><code>'none'</code> or <code>None</code>: Calculate the metric for each class separately, and return   the metric for every class.</li> <li><code>'samples'</code>: Calculate the metric for each sample, and average the metrics   across samples (with equal weights for each sample).</li> </ul> <p>.. note:: What is considered a sample in the multi-dimensional multi-class case     depends on the value of <code>mdmc_average</code>.</p> <p>.. note:: If <code>'none'</code> and a given class doesn't occur in the <code>preds</code> or <code>target</code>,     the value for the class will be <code>nan</code>.</p> <code>'micro'</code> <code>mdmc_average</code> <code>Optional[str]</code> <p>Defines how averaging is done for multi-dimensional multi-class inputs (on top of the <code>average</code> parameter). Should be one of the following:</p> <ul> <li> <p><code>None</code> [default]: Should be left unchanged if your data is not multi-dimensional multi-class.</p> </li> <li> <p><code>'samplewise'</code>: In this case, the statistics are computed separately for each   sample on the <code>N</code> axis, and then averaged over samples.   The computation for each sample is done by treating the flattened extra axes <code>...</code>   (see :ref:<code>pages/classification:input types</code>) as the <code>N</code> dimension within the sample,   and computing the metric for the sample based on that.</p> </li> <li> <p><code>'global'</code>: In this case the <code>N</code> and <code>...</code> dimensions of the inputs   (see :ref:<code>pages/classification:input types</code>)   are flattened into a new <code>N_X</code> sample axis, i.e. the inputs are treated as if they   were <code>(N_X, C)</code>. From here on the <code>average</code> parameter applies as usual.</p> </li> </ul> <code>'global'</code> <code>num_classes</code> <code>Optional[int]</code> <p>Number of classes. Necessary for <code>'macro'</code>, <code>'weighted'</code> and <code>None</code> average methods.</p> <code>None</code> <code>threshold</code> <code>float</code> <p>Threshold for transforming probability or logit predictions to binary (0,1) predictions, in the case of binary or multi-label inputs. Default value of 0.5 corresponds to input being probabilities.</p> <code>0.5</code> <code>top_k</code> <code>Optional[int]</code> <p>Number of the highest probability or logit score predictions considered finding the correct label, relevant only for (multi-dimensional) multi-class inputs. The default value (<code>None</code>) will be interpreted as 1 for these inputs.</p> <p>Should be left at default (<code>None</code>) for all other types of inputs.</p> <code>None</code> <code>multiclass</code> <code>Optional[bool]</code> <p>Used only in certain special cases, where you want to treat inputs as a different type than what they appear to be. See the parameter's :ref:<code>documentation section &lt;pages/classification:using the multiclass parameter&gt;</code> for a more detailed explanation and examples.</p> <code>None</code> <code>ignore_index</code> <code>Optional[int]</code> <p>Integer specifying a target class to ignore. If given, this class index does not contribute to the returned score, regardless of reduction method. If an index is ignored, and <code>average=None</code> or <code>'none'</code>, the score for the ignored class will be returned as <code>nan</code>.</p> <code>None</code> <code>subset_accuracy</code> <code>bool</code> <p>Whether to compute subset accuracy for multi-label and multi-dimensional multi-class inputs (has no effect for other input types).</p> <ul> <li> <p>For multi-label inputs, if the parameter is set to <code>True</code>, then all labels for   each sample must be correctly predicted for the sample to count as correct. If it   is set to <code>False</code>, then all labels are counted separately - this is equivalent to   flattening inputs beforehand (i.e. <code>preds = preds.flatten()</code> and same for <code>target</code>).</p> </li> <li> <p>For multi-dimensional multi-class inputs, if the parameter is set to <code>True</code>, then all   sub-sample (on the extra axis) must be correct for the sample to be counted as correct.   If it is set to <code>False</code>, then all sub-samples are counter separately - this is equivalent,   in the case of label predictions, to flattening the inputs beforehand (i.e.   <code>preds = preds.flatten()</code> and same for <code>target</code>). Note that the <code>top_k</code> parameter   still applies in both cases, if set.</p> </li> </ul> <code>False</code>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.auroc_ipu","title":"<code>auroc_ipu(preds, target, num_classes=None, pos_label=None, average='macro', max_fpr=None, sample_weights=None)</code>","text":"<p>A modified version of the <code>torchmetrics.functional.auroc</code> that can ignore NaNs by giving them the same value for both <code>preds</code> and <code>target</code>. This allows it to work with compilation and IPUs since it doesn't modify the tensor's shape.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.average_precision_ipu","title":"<code>average_precision_ipu(preds, target, num_classes=None, pos_label=None, average='macro', sample_weights=None)</code>","text":"<p>A modified version of the <code>torchmetrics.functional.average_precision</code> that can ignore NaNs by giving them the same value for both <code>preds</code> and <code>target</code>. This allows it to work with compilation and IPUs since it doesn't modify the tensor's shape.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.f1_score_ipu","title":"<code>f1_score_ipu(preds, target, beta=1.0, average='micro', mdmc_average=None, ignore_index=None, num_classes=None, threshold=0.5, top_k=None, multiclass=None)</code>","text":"<p>A modified version of the <code>torchmetrics.functional.classification.f_beta._fbeta_compute</code> that can ignore NaNs by giving them the same value for both <code>preds</code> and <code>target</code>. Used to calculate the f1_score on IPU with beta parameter equal to 1.0 This allows it to work with compilation and IPUs since it doesn't modify the tensor's shape.</p> <p>Computes f_beta metric from stat scores: true positives, false positives, true negatives, false negatives.</p> <p>Parameters:</p> Name Type Description Default <code>tp</code> <p>True positives</p> required <code>fp</code> <p>False positives</p> required <code>tn</code> <p>True negatives</p> required <code>fn</code> <p>False negatives</p> required <code>beta</code> <code>float</code> <p>The parameter <code>beta</code> (which determines the weight of recall in the combined score)</p> <code>1.0</code> <code>ignore_index</code> <code>Optional[int]</code> <p>Integer specifying a target class to ignore. If given, this class index does not contribute to the returned score, regardless of reduction method</p> <code>None</code> <code>average</code> <code>Optional[str]</code> <p>Defines the reduction that is applied</p> <code>'micro'</code> <code>mdmc_average</code> <code>Optional[str]</code> <p>Defines how averaging is done for multi-dimensional multi-class inputs (on top of the <code>average</code> parameter)</p> <code>None</code>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.fbeta_score_ipu","title":"<code>fbeta_score_ipu(preds, target, beta=1.0, average='micro', mdmc_average=None, ignore_index=None, num_classes=None, threshold=0.5, top_k=None, multiclass=None)</code>","text":"<p>A modified version of the <code>torchmetrics.functional.classification.f_beta._fbeta_compute</code> that can ignore NaNs by giving them the same value for both <code>preds</code> and <code>target</code>. This allows it to work with compilation and IPUs since it doesn't modify the tensor's shape.</p> <p>Parameters:</p> Name Type Description Default <code>preds</code> <code>Tensor</code> <p>Predictions from model (probabilities, logits or labels)</p> required <code>target</code> <code>Tensor</code> <p>Ground truth labels</p> required <code>average</code> <code>Optional[str]</code> <p>Defines the reduction that is applied. Should be one of the following:</p> <ul> <li><code>'micro'</code> [default]: Calculate the metric globally, across all samples and classes.</li> <li><code>'macro'</code>: Calculate the metric for each class separately, and average the   metrics across classes (with equal weights for each class).</li> <li><code>'weighted'</code>: Calculate the metric for each class separately, and average the   metrics across classes, weighting each class by its support (<code>tp + fn</code>).</li> <li><code>'none'</code> or <code>None</code>: Calculate the metric for each class separately, and return   the metric for every class.</li> <li><code>'samples'</code>: Calculate the metric for each sample, and average the metrics   across samples (with equal weights for each sample).</li> </ul> <p>.. note:: What is considered a sample in the multi-dimensional multi-class case     depends on the value of <code>mdmc_average</code>.</p> <p>.. note:: If <code>'none'</code> and a given class doesn't occur in the <code>preds</code> or <code>target</code>,     the value for the class will be <code>nan</code>.</p> <code>'micro'</code> <code>mdmc_average</code> <code>Optional[str]</code> <p>Defines how averaging is done for multi-dimensional multi-class inputs (on top of the <code>average</code> parameter). Should be one of the following:</p> <ul> <li> <p><code>None</code> [default]: Should be left unchanged if your data is not multi-dimensional multi-class.</p> </li> <li> <p><code>'samplewise'</code>: In this case, the statistics are computed separately for each   sample on the <code>N</code> axis, and then averaged over samples.   The computation for each sample is done by treating the flattened extra axes <code>...</code>   (see :ref:<code>pages/classification:input types</code>) as the <code>N</code> dimension within the sample,   and computing the metric for the sample based on that.</p> </li> <li> <p><code>'global'</code>: In this case the <code>N</code> and <code>...</code> dimensions of the inputs   (see :ref:<code>pages/classification:input types</code>)   are flattened into a new <code>N_X</code> sample axis, i.e. the inputs are treated as if they   were <code>(N_X, C)</code>. From here on the <code>average</code> parameter applies as usual.</p> </li> </ul> <code>None</code> <code>num_classes</code> <code>Optional[int]</code> <p>Number of classes. Necessary for <code>'macro'</code>, <code>'weighted'</code> and <code>None</code> average methods.</p> <code>None</code> <code>threshold</code> <code>float</code> <p>Threshold for transforming probability or logit predictions to binary (0,1) predictions, in the case of binary or multi-label inputs. Default value of 0.5 corresponds to input being probabilities.</p> <code>0.5</code> <code>top_k</code> <code>Optional[int]</code> <p>Number of the highest probability or logit score predictions considered finding the correct label, relevant only for (multi-dimensional) multi-class inputs. The default value (<code>None</code>) will be interpreted as 1 for these inputs.</p> <p>Should be left at default (<code>None</code>) for all other types of inputs.</p> <code>None</code> <code>multiclass</code> <code>Optional[bool]</code> <p>Used only in certain special cases, where you want to treat inputs as a different type than what they appear to be. See the parameter's :ref:<code>documentation section &lt;pages/classification:using the multiclass parameter&gt;</code> for a more detailed explanation and examples.</p> <code>None</code> <code>ignore_index</code> <code>Optional[int]</code> <p>Integer specifying a target class to ignore. If given, this class index does not contribute to the returned score, regardless of reduction method. If an index is ignored, and <code>average=None</code> or <code>'none'</code>, the score for the ignored class will be returned as <code>nan</code>.</p> <code>None</code> <code>subset_accuracy</code> <p>Whether to compute subset accuracy for multi-label and multi-dimensional multi-class inputs (has no effect for other input types).</p> <ul> <li> <p>For multi-label inputs, if the parameter is set to <code>True</code>, then all labels for   each sample must be correctly predicted for the sample to count as correct. If it   is set to <code>False</code>, then all labels are counted separately - this is equivalent to   flattening inputs beforehand (i.e. <code>preds = preds.flatten()</code> and same for <code>target</code>).</p> </li> <li> <p>For multi-dimensional multi-class inputs, if the parameter is set to <code>True</code>, then all   sub-sample (on the extra axis) must be correct for the sample to be counted as correct.   If it is set to <code>False</code>, then all sub-samples are counter separately - this is equivalent,   in the case of label predictions, to flattening the inputs beforehand (i.e.   <code>preds = preds.flatten()</code> and same for <code>target</code>). Note that the <code>top_k</code> parameter   still applies in both cases, if set.</p> </li> </ul> required"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.get_confusion_matrix","title":"<code>get_confusion_matrix(preds, target, average='micro', mdmc_average='global', threshold=0.5, top_k=None, subset_accuracy=False, num_classes=None, multiclass=None, ignore_index=None)</code>","text":"<p>Calculates the confusion matrix according to the specified average method.</p> <p>Parameters:</p> Name Type Description Default <code>preds</code> <code>Tensor</code> <p>Predictions from model (probabilities, logits or labels)</p> required <code>target</code> <code>Tensor</code> <p>Ground truth labels</p> required <code>average</code> <code>Optional[str]</code> <p>Defines the reduction that is applied. Should be one of the following:</p> <ul> <li><code>'micro'</code> [default]: Calculate the metric globally, across all samples and classes.</li> <li><code>'macro'</code>: Calculate the metric for each class separately, and average the   metrics across classes (with equal weights for each class).</li> <li><code>'weighted'</code>: Calculate the metric for each class separately, and average the   metrics across classes, weighting each class by its support (<code>tp + fn</code>).</li> <li><code>'none'</code> or <code>None</code>: Calculate the metric for each class separately, and return   the metric for every class.</li> <li><code>'samples'</code>: Calculate the metric for each sample, and average the metrics   across samples (with equal weights for each sample).</li> </ul> <p>.. note:: What is considered a sample in the multi-dimensional multi-class case     depends on the value of <code>mdmc_average</code>.</p> <p>.. note:: If <code>'none'</code> and a given class doesn't occur in the <code>preds</code> or <code>target</code>,     the value for the class will be <code>nan</code>.</p> <code>'micro'</code> <code>mdmc_average</code> <code>Optional[str]</code> <p>Defines how averaging is done for multi-dimensional multi-class inputs (on top of the <code>average</code> parameter). Should be one of the following:</p> <ul> <li> <p><code>None</code> [default]: Should be left unchanged if your data is not multi-dimensional multi-class.</p> </li> <li> <p><code>'samplewise'</code>: In this case, the statistics are computed separately for each   sample on the <code>N</code> axis, and then averaged over samples.   The computation for each sample is done by treating the flattened extra axes <code>...</code>   (see :ref:<code>pages/classification:input types</code>) as the <code>N</code> dimension within the sample,   and computing the metric for the sample based on that.</p> </li> <li> <p><code>'global'</code>: In this case the <code>N</code> and <code>...</code> dimensions of the inputs   (see :ref:<code>pages/classification:input types</code>)   are flattened into a new <code>N_X</code> sample axis, i.e. the inputs are treated as if they   were <code>(N_X, C)</code>. From here on the <code>average</code> parameter applies as usual.</p> </li> </ul> <code>'global'</code> <code>num_classes</code> <code>Optional[int]</code> <p>Number of classes. Necessary for <code>'macro'</code>, <code>'weighted'</code> and <code>None</code> average methods.</p> <code>None</code> <code>threshold</code> <code>float</code> <p>Threshold for transforming probability or logit predictions to binary (0,1) predictions, in the case of binary or multi-label inputs. Default value of 0.5 corresponds to input being probabilities.</p> <code>0.5</code> <code>top_k</code> <code>Optional[int]</code> <p>Number of the highest probability or logit score predictions considered finding the correct label, relevant only for (multi-dimensional) multi-class inputs. The default value (<code>None</code>) will be interpreted as 1 for these inputs.</p> <p>Should be left at default (<code>None</code>) for all other types of inputs.</p> <code>None</code> <code>multiclass</code> <code>Optional[bool]</code> <p>Used only in certain special cases, where you want to treat inputs as a different type than what they appear to be. See the parameter's :ref:<code>documentation section &lt;pages/classification:using the multiclass parameter&gt;</code> for a more detailed explanation and examples.</p> <code>None</code> <code>ignore_index</code> <code>Optional[int]</code> <p>Integer specifying a target class to ignore. If given, this class index does not contribute to the returned score, regardless of reduction method. If an index is ignored, and <code>average=None</code></p> <code>None</code>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.mean_absolute_error_ipu","title":"<code>mean_absolute_error_ipu(preds, target)</code>","text":"<p>Computes mean absolute error.</p> <p>Handles NaNs without reshaping tensors in order to work on IPU.</p> <p>Parameters:</p> Name Type Description Default <code>preds</code> <code>Tensor</code> <p>estimated labels</p> required <code>target</code> <code>Tensor</code> <p>ground truth labels</p> required Return <p>Tensor with MAE</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.mean_squared_error_ipu","title":"<code>mean_squared_error_ipu(preds, target, squared)</code>","text":"<p>Computes mean squared error.</p> <p>Handles NaNs without reshaping tensors in order to work on IPU.</p> <p>Parameters:</p> Name Type Description Default <code>preds</code> <code>Tensor</code> <p>estimated labels</p> required <code>target</code> <code>Tensor</code> <p>ground truth labels</p> required <code>squared</code> <code>bool</code> <p>returns RMSE value if set to False</p> required Return <p>Tensor with MSE</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.pearson_ipu","title":"<code>pearson_ipu(preds, target)</code>","text":"<p>Computes pearson correlation coefficient.</p> <p>Handles NaNs in the target without reshaping tensors in order to work on IPU.</p> <p>Parameters:</p> Name Type Description Default <code>preds</code> <p>estimated scores</p> required <code>target</code> <p>ground truth scores</p> required"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.precision_ipu","title":"<code>precision_ipu(preds, target, average='micro', mdmc_average=None, ignore_index=None, num_classes=None, threshold=0.5, top_k=None, multiclass=None)</code>","text":"<p>A modified version of the <code>torchmetrics.functional.precision</code> that can ignore NaNs by giving them the same value for both <code>preds</code> and <code>target</code>. This allows it to work with compilation and IPUs since it doesn't modify the tensor's shape.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.r2_score_ipu","title":"<code>r2_score_ipu(preds, target, *args, **kwargs)</code>","text":"<p>Computes r2 score also known as <code>R2 Score_Coefficient Determination</code>_:</p> <p>.. math:: R^2 = 1 - \frac{SS_{res}}{SS_{tot}}</p> <p>where :math:<code>SS_{res}=\\sum_i (y_i - f(x_i))^2</code> is the sum of residual squares, and :math:<code>SS_{tot}=\\sum_i (y_i - \bar{y})^2</code> is total sum of squares. Can also calculate adjusted r2 score given by</p> <p>.. math:: R^2_{adj} = 1 - \frac{(1-R^2)(n-1)}{n-k-1}</p> <p>where the parameter :math:<code>k</code> (the number of independent regressors) should be provided as the <code>adjusted</code> argument. Handles NaNs without reshaping tensors in order to work on IPU.</p> <p>Parameters:</p> Name Type Description Default <code>preds</code> <p>estimated labels</p> required <code>target</code> <p>ground truth labels</p> required <code>adjusted</code> <p>number of independent regressors for calculating adjusted r2 score.</p> required <code>multioutput</code> <p>Defines aggregation in the case of multiple output scores. Can be one of the following strings:</p> <ul> <li><code>'raw_values'</code> returns full set of scores</li> <li><code>'uniform_average'</code> scores are uniformly averaged</li> <li><code>'variance_weighted'</code> scores are weighted by their individual variances</li> </ul> required"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.recall_ipu","title":"<code>recall_ipu(preds, target, average='micro', mdmc_average=None, ignore_index=None, num_classes=None, threshold=0.5, top_k=None, multiclass=None)</code>","text":"<p>A modified version of the <code>torchmetrics.functional.recall</code> that can ignore NaNs by giving them the same value for both <code>preds</code> and <code>target</code>. This allows it to work with compilation and IPUs since it doesn't modify the tensor's shape.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_metrics.spearman_ipu","title":"<code>spearman_ipu(preds, target)</code>","text":"<p>Computes spearman rank correlation coefficient.</p> <p>Handles NaNs in the target without reshaping tensors in order to work on IPU.</p> <p>Parameters:</p> Name Type Description Default <code>preds</code> <p>estimated scores</p> required <code>target</code> <p>ground truth scores</p> required"},{"location":"api/goli.ipu.html#goli.ipu.ipu_simple_lightning","title":"<code>goli.ipu.ipu_simple_lightning</code>","text":""},{"location":"api/goli.ipu.html#goli.ipu.ipu_utils","title":"<code>goli.ipu.ipu_utils</code>","text":""},{"location":"api/goli.ipu.html#goli.ipu.ipu_utils.import_poptorch","title":"<code>import_poptorch(raise_error=True)</code>","text":"<p>Import poptorch and returns it. It is wrapped in a function to avoid breaking the code for non-IPU devices which did not install poptorch.</p> <p>Parameters:</p> Name Type Description Default <code>raise_error</code> <p>Whether to raise an error if poptorch is unavailable. If <code>False</code>, return <code>None</code></p> <code>True</code> <p>Returns:</p> Type Description <code>Optional[ModuleType]</code> <p>The poptorch module</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_utils.is_running_on_ipu","title":"<code>is_running_on_ipu()</code>","text":"<p>Returns whether the current module is running on ipu. Needs to be used in the <code>forward</code> or <code>backward</code> pass.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_utils.load_ipu_options","title":"<code>load_ipu_options(ipu_file, seed=None, model_name=None, gradient_accumulation=None, precision=None, ipu_inference_overrides=None)</code>","text":"<p>Load the IPU options from the config file.</p> <p>Parameters:</p> Name Type Description Default <code>ipu_file</code> <code>str</code> <p>file path containing the IPU configurations. Example of options are:</p> <p>load the options from a config file. See <code>Options.loadFromFile</code></p> required <code>seed</code> <code>Optional[int]</code> <p>random seed for the IPU</p> <code>None</code> <code>model_name</code> <code>Optional[str]</code> <p>Name of the model, to be used for ipu profiling</p> <code>None</code> <code>ipu_inference_overrides</code> <code>Optional[str]</code> <p>optional file path containing IPU configuration overrides for inference. If this file is provided, options in this file override those in <code>ipu_file</code> for inference.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>training_opts</code> <code>Options</code> <p>IPU options for the training set.</p> <code>inference_opts</code> <code>Options</code> <p>IPU options for inference. It differs from the <code>training_opts</code> by enforcing <code>gradientAccumulation</code> to 1</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_utils.load_ipu_options--see-the-tutorial-for-ipu-options-here","title":"? see the tutorial for IPU options here","text":""},{"location":"api/goli.ipu.html#goli.ipu.ipu_utils.load_ipu_options--httpsgithubcomgraphcoretutorialstreesdk-release-26tutorialspytorchefficient_data_loading","title":"https://github.com/graphcore/tutorials/tree/sdk-release-2.6/tutorials/pytorch/efficient_data_loading","text":""},{"location":"api/goli.ipu.html#goli.ipu.ipu_utils.load_ipu_options--see-the-full-documentation-for-ipu-options-here","title":"? see the full documentation for ipu options here","text":""},{"location":"api/goli.ipu.html#goli.ipu.ipu_utils.load_ipu_options--httpsdocsgraphcoreaiprojectspoptorch-user-guideenlatestreferencehtmlhighlightoptionspoptorchoptions","title":"https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/reference.html?highlight=options#poptorch.Options","text":"<p>minibatch size: The number of samples processed by one simple fwd/bwd pass. = # of samples in a minibatch</p> <p>device iterations: A device iteration corresponds to one iteration of the training loop executed on the IPU, starting with data-loading and ending with a weight update. In this simple case, when we set n deviceIterations, the host will prepare n mini-batches in an infeed queue so the IPU can perform efficiently n iterations. = # of minibatches to be processed at a time = # of training / backward pass in this call</p> <p>gradient accumulation factor: After each backward pass the gradients are accumulated together for K mini-batches. set K in the argument = # of minibatches to accumulate gradients from</p> <p>replication factor: Replication describes the process of running multiple instances of the same model simultaneously on different IPUs to achieve data parallelism. If the model requires N IPUs and the replication factor is M, N x M IPUs will be necessary. = # of times the model is copied to speed up computation, each replica of the model is sent a different subset of the dataset</p> <p>global batch size: In a single device iteration, many mini-batches may be processed and the resulting gradients accumulated. We call this total number of samples processed for one optimiser step the global batch size. = total number of samples processed for one optimiser step = (minibatch size x Gradient accumulation factor) x Number of replicas</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_wrapper","title":"<code>goli.ipu.ipu_wrapper</code>","text":""},{"location":"api/goli.ipu.html#goli.ipu.ipu_wrapper.PredictorModuleIPU","title":"<code>PredictorModuleIPU</code>","text":"<p>         Bases: <code>PredictorModule</code></p> <p>This class wraps around the <code>PredictorModule</code> to make it work with IPU and the <code>IPUPluginGoli</code>.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_wrapper.PredictorModuleIPU.convert_from_fp16","title":"<code>convert_from_fp16(data)</code>","text":"<p>Converts tensors from FP16 to FP32. Useful to convert the IPU program output data</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_wrapper.PredictorModuleIPU.get_num_graphs","title":"<code>get_num_graphs(data)</code>","text":"<p>IPU specific method to compute the number of graphs in a Batch, that considers gradient accumulation, multiple IPUs and multiple device iterations. Essential to estimate throughput in graphs/s.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_wrapper.PyGArgsParser","title":"<code>PyGArgsParser</code>","text":"<p>         Bases: <code>poptorch.ICustomArgParser</code></p> <p>This class is responsible for converting a PyG Batch from and to a tensor of tuples. This allows PyG Batch to be used as inputs to IPU programs. Copied from poppyg repo, in the future import from the repo directly.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_wrapper.PyGArgsParser.reconstruct","title":"<code>reconstruct(original_structure, tensor_iterator)</code>","text":"<p>Create a new instance with the same class type as the original_structure. This new instance will be initialized with tensors from the provided iterator and uses the same sorted keys from the yieldTensors() implementation.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_wrapper.PyGArgsParser.sortedTensorKeys","title":"<code>sortedTensorKeys(struct)</code>  <code>staticmethod</code>","text":"<p>Find all the keys that map to a tensor value in struct. The keys are returned in sorted order.</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_wrapper.PyGArgsParser.yieldTensors","title":"<code>yieldTensors(struct)</code>","text":"<p>yield every torch.Tensor in struct in sorted order</p>"},{"location":"api/goli.ipu.html#goli.ipu.ipu_wrapper.remove_pad_loss","title":"<code>remove_pad_loss(preds, targets)</code>","text":"<p>helper function to remove the fake graph loss always reduce the last loss since it is the fake graph</p>"},{"location":"api/goli.ipu.html#goli.ipu.to_dense_batch","title":"<code>goli.ipu.to_dense_batch</code>","text":""},{"location":"api/goli.ipu.html#goli.ipu.to_dense_batch.to_dense_batch","title":"<code>to_dense_batch(x, batch=None, fill_value=0.0, max_num_nodes_per_graph=None, batch_size=None, drop_nodes_last_graph=False)</code>","text":"<p>Given a sparse batch of node features :math:<code>\\mathbf{X} \\in \\mathbb{R}^{(N_1 + \\ldots + N_B) \\times F}</code> (with :math:<code>N_i</code> indicating the number of nodes in graph :math:<code>i</code>), creates a dense node feature tensor :math:<code>\\mathbf{X} \\in \\mathbb{R}^{B \\times N_{\\max} \\times F}</code> (with :math:<code>N_{\\max} = \\max_i^B N_i</code>). In addition, a mask of shape :math:<code>\\mathbf{M} \\in \\{ 0, 1 \\}^{B \\times N_{\\max}}</code> is returned, holding information about the existence of fake-nodes in the dense representation.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Node feature matrix :math:<code>\\mathbf{X} \\in \\mathbb{R}^{(N_1 + \\ldots + N_B) \\times F}</code>.</p> required <code>batch</code> <code>Optional[Tensor]</code> <p>Batch vector :math:<code>\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N</code>, which assigns each node to a specific example. Must be ordered. (default: :obj:<code>None</code>)</p> <code>None</code> <code>fill_value</code> <code>float</code> <p>The value for invalid entries in the resulting dense output tensor. (default: :obj:<code>0</code>)</p> <code>0.0</code> <code>max_num_nodes_per_graph</code> <code>Optional[int]</code> <p>The size of the output node dimension. (default: :obj:<code>None</code>)</p> <code>None</code> <code>batch_size</code> <code>Optional[int]</code> <p>The batch size. (default: :obj:<code>None</code>)</p> <code>None</code> <code>drop_nodes_last_graph</code> <p>Whether to drop the nodes of the last graphs that exceed the <code>max_num_nodes_per_graph</code>. Useful when the last graph is a padding.</p> <code>False</code> <p>:rtype: (:class:<code>Tensor</code>, :class:<code>BoolTensor</code>)</p>"},{"location":"api/goli.ipu.html#goli.ipu.to_dense_batch.to_sparse_batch","title":"<code>to_sparse_batch(x, mask_idx)</code>","text":"<p>Reverse function of <code>to_dense_batch</code></p>"},{"location":"api/goli.trainer.html","title":"goli.trainer","text":""},{"location":"api/goli.trainer.html#goli.trainer.metrics","title":"<code>goli.trainer.metrics</code>","text":""},{"location":"api/goli.trainer.html#goli.trainer.metrics.MetricWrapper","title":"<code>MetricWrapper</code>","text":"<p>Allows to initialize a metric from a name or Callable, and initialize the <code>Thresholder</code> in case the metric requires a threshold.</p>"},{"location":"api/goli.trainer.html#goli.trainer.metrics.MetricWrapper.__call__","title":"<code>__call__(preds, target)</code>","text":"<p>Compute the metric with the method <code>self.compute</code></p>"},{"location":"api/goli.trainer.html#goli.trainer.metrics.MetricWrapper.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Serialize the class for pickling.</p>"},{"location":"api/goli.trainer.html#goli.trainer.metrics.MetricWrapper.__init__","title":"<code>__init__(metric, threshold_kwargs=None, target_nan_mask=None, multitask_handling=None, **kwargs)</code>","text":"<p>Parameters     metric:         The metric to use. See <code>METRICS_DICT</code></p> <pre><code>threshold_kwargs:\n    If `None`, no threshold is applied.\n    Otherwise, we use the class `Thresholder` is initialized with the\n    provided argument, and called before the `compute`\n\ntarget_nan_mask:\n\n    - None: Do not change behaviour if there are NaNs\n\n    - int, float: Value used to replace NaNs. For example, if `target_nan_mask==0`, then\n      all NaNs will be replaced by zeros\n\n    - 'ignore': The NaN values will be removed from the tensor before computing the metrics.\n      Must be coupled with the `multitask_handling='flatten'` or `multitask_handling='mean-per-label'`.\n\nmultitask_handling:\n    - None: Do not process the tensor before passing it to the metric.\n      Cannot use the option `multitask_handling=None` when `target_nan_mask=ignore`.\n      Use either 'flatten' or 'mean-per-label'.\n\n    - 'flatten': Flatten the tensor to produce the equivalent of a single task\n\n    - 'mean-per-label': Loop all the labels columns, process them as a single task,\n        and average the results over each task\n      *This option might slowdown the computation if there are too many labels*\n\nkwargs:\n    Other arguments to call with the metric\n</code></pre>"},{"location":"api/goli.trainer.html#goli.trainer.metrics.MetricWrapper.__repr__","title":"<code>__repr__()</code>","text":"<p>Control how the class is printed</p>"},{"location":"api/goli.trainer.html#goli.trainer.metrics.MetricWrapper.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Reload the class from pickling.</p>"},{"location":"api/goli.trainer.html#goli.trainer.metrics.MetricWrapper.compute","title":"<code>compute(preds, target)</code>","text":"<p>Compute the metric, apply the thresholder if provided, and manage the NaNs</p>"},{"location":"api/goli.trainer.html#goli.trainer.metrics.Thresholder","title":"<code>Thresholder</code>","text":""},{"location":"api/goli.trainer.html#goli.trainer.metrics.Thresholder.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Serialize the class for pickling.</p>"},{"location":"api/goli.trainer.html#goli.trainer.metrics.Thresholder.__repr__","title":"<code>__repr__()</code>","text":"<p>Control how the class is printed</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor_options","title":"<code>goli.trainer.predictor_options</code>","text":"<p>Data classes to group together related arguments for the creation of a Predictor Module.</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor_options.EvalOptions","title":"<code>EvalOptions</code>  <code>dataclass</code>","text":"<p>This data class stores the arguments necessary to instantiate a model for the Predictor.</p> <p>Parameters:</p> Name Type Description Default <code>loss_fun</code> <code>Union[str, Callable]</code> <p>Loss function used during training. Acceptable strings are 'mse', 'bce', 'mae', 'cosine'. Otherwise, a callable object must be provided, with a method <code>loss_fun._get_name()</code>.</p> required <code>metrics</code> <code>Dict[str, Callable]</code> <p>A dictionnary of metrics to compute on the prediction, other than the loss function. These metrics will be logged into TensorBoard.</p> <code>None</code> <code>metrics_on_progress_bar</code> <code>List[str]</code> <p>The metrics names from <code>metrics</code> to display also on the progress bar of the training</p> <code>field(default_factory=List[str])</code> <code>metrics_on_training_set</code> <code>Optional[List[str]]</code> <p>The metrics names from <code>metrics</code> to be computed on the training set for each iteration. If <code>None</code>, all the metrics are computed. Using less metrics can significantly improve performance, depending on the number of readouts.</p> <code>None</code>"},{"location":"api/goli.trainer.html#goli.trainer.predictor_options.EvalOptions.parse_loss_fun","title":"<code>parse_loss_fun(loss_fun)</code>  <code>staticmethod</code>","text":"<p>Parse the loss function from a string</p> <p>Parameters:</p> Name Type Description Default <code>loss_fun</code> <code>Union[str, Callable]</code> <p>A callable corresponding to the loss function or a string specifying the loss function from <code>LOSS_DICT</code>. Accepted strings are: \"mse\", \"bce\", \"l1\", \"mae\", \"cosine\".</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable</code> <p>Function or callable to compute the loss, takes <code>preds</code> and <code>targets</code> as inputs.</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor_options.FlagOptions","title":"<code>FlagOptions</code>  <code>dataclass</code>","text":"<p>This data class stores the arguments necessary to instantiate a model for the Predictor.</p> <p>Parameters:</p> Name Type Description Default <code>flag_kwargs</code> <code>Dict[str, Any]</code> <p>Keyword arguments used for FLAG, and adversarial data augmentation for graph networks. See: https://arxiv.org/abs/2010.09891</p> <ul> <li> <p>n_steps: An integer that specifies the number of ascent steps when running FLAG during training.     Default value of 0 trains GNNs without FLAG, and any value greater than 0 will use FLAG with that     many iterations.</p> </li> <li> <p>alpha: A float that specifies the ascent step size when running FLAG. Default=0.01</p> </li> </ul> <code>None</code>"},{"location":"api/goli.trainer.html#goli.trainer.predictor_options.ModelOptions","title":"<code>ModelOptions</code>  <code>dataclass</code>","text":"<p>This data class stores the arguments necessary to instantiate a model for the Predictor.</p> <p>Parameters:</p> Name Type Description Default <code>model_class</code> <code>Type[nn.Module]</code> <p>pytorch module used to create a model</p> required <code>model_kwargs</code> <code>Dict[str, Any]</code> <p>Key-word arguments used to initialize the model from <code>model_class</code>.</p> required"},{"location":"api/goli.trainer.html#goli.trainer.predictor_options.OptimOptions","title":"<code>OptimOptions</code>  <code>dataclass</code>","text":"<p>This data class stores the arguments necessary to configure the optimizer for the Predictor.</p> <p>Parameters:</p> Name Type Description Default <code>optim_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Dictionnary used to initialize the optimizer, with possible keys below.</p> <ul> <li>lr <code>float</code>: Learning rate (Default=<code>1e-3</code>)</li> <li>weight_decay <code>float</code>: Weight decay used to regularize the optimizer (Default=<code>0.</code>)</li> </ul> <code>None</code> <code>torch_scheduler_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Dictionnary for the scheduling of learning rate, with possible keys below.</p> <ul> <li>type <code>str</code>: Type of the learning rate to use from pytorch. Examples are     <code>'ReduceLROnPlateau'</code> (default), <code>'CosineAnnealingWarmRestarts'</code>, <code>'StepLR'</code>, etc.</li> <li>**kwargs: Any other argument for the learning rate scheduler</li> </ul> <code>None</code> <code>scheduler_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Dictionnary for the scheduling of the learning rate modification used by pytorch-lightning</p> <ul> <li>monitor <code>str</code>: metric to track (Default=<code>\"loss/val\"</code>)</li> <li>interval <code>str</code>: Whether to look at iterations or epochs (Default=<code>\"epoch\"</code>)</li> <li>strict <code>bool</code>: if set to True will enforce that value specified in monitor is available     while trying to call scheduler.step(), and stop training if not found. If False will     only give a warning and continue training (without calling the scheduler). (Default=<code>True</code>)</li> <li>frequency <code>int</code>: TODO: NOT REALLY SURE HOW IT WORKS! (Default=<code>1</code>)</li> </ul> <code>None</code> <code>scheduler_class</code> <code>Optional[Union[str, Type]]</code> <p>The class to use for the scheduler, or the str representing the scheduler.</p> <code>None</code>"},{"location":"api/goli.trainer.html#goli.trainer.predictor_summaries","title":"<code>goli.trainer.predictor_summaries</code>","text":"<p>Classes to store information about resulting evaluation metrics when using a Predictor Module.</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor_summaries.Summary","title":"<code>Summary</code>","text":"<p>         Bases: <code>SummaryInterface</code></p> <p>A container to be used by the Predictor Module that stores the results for the given metrics on the predictions and targets provided.</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor_summaries.Summary.Results","title":"<code>Results</code>","text":""},{"location":"api/goli.trainer.html#goli.trainer.predictor_summaries.Summary.Results.__init__","title":"<code>__init__(targets=None, predictions=None, loss=None, metrics=None, monitored_metric=None, n_epochs=None)</code>","text":"<p>This inner class is used as a container for storing the results of the summary.</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor_summaries.Summary.get_metrics_logs","title":"<code>get_metrics_logs()</code>","text":"<p>Get the data about metrics to log.</p> <p>Note: This function requires that self.update_predictor_state() be called before it.</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor_summaries.Summary.is_best_epoch","title":"<code>is_best_epoch(step_name, loss, metrics)</code>","text":"<p>TODO (Gabriela): Check for bugs related to monitor_name</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor_summaries.Summary.set_results","title":"<code>set_results(metrics)</code>","text":"<p>This function requires that self.update_predictor_state() be called before it.</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor_summaries.SummaryInterface","title":"<code>SummaryInterface</code>","text":"<p>         Bases: <code>object</code></p> <p>An interface to define the functions implemented by summary classes that implement SummaryInterface.</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor","title":"<code>goli.trainer.predictor</code>","text":""},{"location":"api/goli.trainer.html#goli.trainer.predictor.PredictorModule","title":"<code>PredictorModule</code>","text":"<p>         Bases: <code>pl.LightningModule</code></p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor.PredictorModule.__init__","title":"<code>__init__(model_class, model_kwargs, loss_fun, random_seed=42, optim_kwargs=None, torch_scheduler_kwargs=None, scheduler_kwargs=None, target_nan_mask=None, multitask_handling=None, metrics=None, metrics_on_progress_bar=[], metrics_on_training_set=None, flag_kwargs=None)</code>","text":"<p>The Lightning module responsible for handling the predictions, losses, metrics, optimization, etc. It works in a multi-task setting, with different losses and metrics per class</p> <p>Parameters:</p> Name Type Description Default <code>model_class</code> <code>Type[nn.Module]</code> <p>The torch Module containing the main forward function</p> required <code>model_kwargs</code> <code>Dict[str, Any]</code> <p>The arguments to initialize the model from <code>model_class</code></p> required <code>loss_fun</code> <code>Dict[str, Union[str, Callable]]</code> <p>A <code>dict[str, fun]</code>, where <code>str</code> is the task name and <code>fun</code> the loss function</p> required <code>random_seed</code> <code>int</code> <p>The seed for random initialization</p> <code>42</code> <code>optim_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>The optimization arguments. See class <code>OptimOptions</code></p> <code>None</code> <code>torch_scheduler_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>The torch scheduler arguments. See class <code>OptimOptions</code></p> <code>None</code> <code>scheduler_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>The lightning scheduler arguments. See class <code>OptimOptions</code></p> <code>None</code> <code>target_nan_mask</code> <code>Optional[Union[str, int]]</code> <p>How to handle the NaNs. See <code>MetricsWrapper</code> for options</p> <code>None</code> <code>metrics</code> <code>Dict[str, Callable]</code> <p>A <code>dict[str, fun]</code>, where <code>str</code> is the task name and <code>fun</code> the metric function</p> <code>None</code> <code>metrics_on_progress_bar</code> <code>Dict[str, List[str]]</code> <p>A <code>dict[str, list[str2]</code>, where <code>str</code> is the task name and <code>str2</code> the metrics to include on the progress bar</p> <code>[]</code> <code>metrics_on_training_set</code> <code>Optional[Dict[str, List[str]]]</code> <p>A <code>dict[str, list[str2]</code>, where <code>str</code> is the task name and <code>str2</code> the metrics to include on the training set</p> <code>None</code> <code>flag_kwargs</code> <code>Dict[str, Any]</code> <p>Arguments related to using the FLAG adversarial augmentation</p> <code>None</code>"},{"location":"api/goli.trainer.html#goli.trainer.predictor.PredictorModule.__repr__","title":"<code>__repr__()</code>","text":"<p>Controls how the class is printed</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor.PredictorModule.compute_loss","title":"<code>compute_loss(preds, targets, weights, loss_fun, target_nan_mask=None, multitask_handling=None)</code>  <code>staticmethod</code>","text":"<p>Compute the loss using the specified loss function, and dealing with the nans in the <code>targets</code>.</p> <p>Parameters:</p> Name Type Description Default <code>preds</code> <code>Dict[str, Tensor]</code> <p>Predicted values</p> required <code>targets</code> <code>Dict[str, Tensor]</code> <p>Target values</p> required <code>weights</code> <code>Optional[Tensor]</code> <p>No longer supported, will raise an error.</p> required <code>target_nan_mask</code> <code>Optional[Union[str, int]]</code> <ul> <li> <p>None: Do not change behaviour if there are NaNs</p> </li> <li> <p>int, float: Value used to replace NaNs. For example, if <code>target_nan_mask==0</code>, then   all NaNs will be replaced by zeros</p> </li> <li> <p>'ignore': The NaN values will be removed from the tensor before computing the metrics.   Must be coupled with the <code>multitask_handling='flatten'</code> or <code>multitask_handling='mean-per-label'</code>.</p> </li> </ul> <code>None</code> <code>multitask_handling</code> <code>Optional[str]</code> <ul> <li> <p>None: Do not process the tensor before passing it to the metric.   Cannot use the option <code>multitask_handling=None</code> when <code>target_nan_mask=ignore</code>.   Use either 'flatten' or 'mean-per-label'.</p> </li> <li> <p>'flatten': Flatten the tensor to produce the equivalent of a single task</p> </li> <li> <p>'mean-per-label': Loop all the labels columns, process them as a single task,     and average the results over each task   This option might slowdown the computation if there are too many labels</p> </li> </ul> <code>None</code> <code>loss_fun</code> <code>Dict[str, Callable]</code> <p>Loss function to use</p> required <p>Returns:</p> Name Type Description <code>Tensor</code> <code>Tuple[Tensor, Dict[str, Tensor]]</code> <p>weighted_loss: Resulting weighted loss all_task_losses: Loss per task</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor.PredictorModule.flag_step","title":"<code>flag_step(batch, step_name, to_cpu)</code>","text":"<p>Perform adversarial data agumentation during one training step using FLAG. Paper: https://arxiv.org/abs/2010.09891 Github: https://github.com/devnkong/FLAG</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor.PredictorModule.forward","title":"<code>forward(inputs)</code>","text":"<p>Returns the result of <code>self.model.forward(*inputs)</code> on the inputs. If the output of <code>out = self.model.forward</code> is a dictionary with a <code>\"preds\"</code> key, it is returned directly. Otherwise, a new dictionary is created and returns <code>{\"preds\": out}</code>.</p> <p>Returns:</p> Type Description <code>Dict[str, Union[Tensor, Dict[str, Tensor], Dict[str, Dict[str, Tensor]]]]</code> <p>A dict with a key <code>\"preds\"</code> representing the prediction of the network.</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor.PredictorModule.get_num_graphs","title":"<code>get_num_graphs(data)</code>","text":"<p>Method to compute number of graphs in a Batch. Essential to estimate throughput in graphs/s.</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor.PredictorModule.list_pretrained_models","title":"<code>list_pretrained_models()</code>  <code>staticmethod</code>","text":"<p>List available pretrained models.</p>"},{"location":"api/goli.trainer.html#goli.trainer.predictor.PredictorModule.load_pretrained_models","title":"<code>load_pretrained_models(name)</code>  <code>staticmethod</code>","text":"<p>Load a pretrained model from its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the model to load. List available from <code>goli.trainer.PredictorModule.list_pretrained_models()</code>.</p> required"},{"location":"api/goli.trainer.html#goli.trainer.predictor.PredictorModule.training_epoch_end","title":"<code>training_epoch_end(outputs)</code>","text":"<p>Nothing happens at the end of the training epoch. It serves no purpose to do a general step for the training, but it can explode the RAM when using a large dataset.</p>"},{"location":"api/goli.utils.html","title":"goli.utils","text":""},{"location":"api/goli.utils.html#goli.utils.arg_checker","title":"<code>goli.utils.arg_checker</code>","text":"<p>Argument checker module</p>"},{"location":"api/goli.utils.html#goli.utils.arg_checker.check_arg_iterator","title":"<code>check_arg_iterator(arg, enforce_type=None, enforce_subtype=None, cast_subtype=True)</code>","text":"<p>Verify if the type is an iterator. If it is <code>None</code>, convert to an empty list/tuple. If it is not a list/tuple/str, try to convert to an iterator. If it is a str or cannot be converted to an iterator, then put the <code>arg</code> inside an iterator. Possibly enforce the iterator type to <code>list</code> or <code>tuple</code>, if <code>enfoce_type</code> is not None. Possibly enforce the subtype to any given type if <code>enforce_subtype</code> is not None, and decide whether to cast the subtype or to throw an error.</p> <p>Parameters:</p> Name Type Description Default <code>arg</code> <code>any type</code> <p>The input to verify/convert to an iterator (list or tuple). If None, an empty iterator is returned.</p> required <code>enforce_type</code> <code>str or type</code> <p>The type to enforce the iterator. The valid choices are : <code>None</code>, <code>list</code>, <code>tuple</code>, <code>'none'</code>, <code>'list'</code>, <code>'tuple'</code>. If <code>None</code>, then the iterator type is not enforced.</p> <code>None</code> <code>enforce_subtype</code> <code>type, np.dtype or str representing basic type</code> <p>Verify if all the elements inside the iterator are the desired type. If <code>None</code>, then the sub-type is not enforced. Accepted strings are ['none', 'str', 'list', 'tuple', 'dict', 'int', 'float', 'complex', 'bool', 'callable']</p> <code>None</code> <code>cast_subtype</code> <code>bool</code> <p>If True, then the type specified by <code>enforce_subtype</code> is used to cast the elements inside the iterator. If False, then an error is thrown if the types do not match.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>output</code> <code>iterator</code> <p>An iterator based on the input of the desired type (list or tuple) and the desired subtypes.</p>"},{"location":"api/goli.utils.html#goli.utils.arg_checker.check_columns_choice","title":"<code>check_columns_choice(dataframe, columns_choice, extra_accepted_cols=None, enforce_type='list')</code>","text":"<p>Verify if the choice of column <code>columns_choice</code> is inside the dataframe or the extra_accepted_cols. Otherwise, errors are thrown by the sub-functions.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <p>(pd.DataFrame) The dataframe on which to verify if the column choice is valid. columns_choice: str, iterator(str) The columns chosen from the dataframe</p> required <code>extra_accepted_cols</code> <p>str, iterator(str) A list</p> <code>None</code> <code>enforce_type</code> <p>str or type The type to enforce the iterator. The valid choices are : <code>None</code>, <code>list</code>, <code>tuple</code>, <code>'none'</code>, <code>'list'</code>, <code>'tuple'</code>. If <code>None</code>, then the iterator type is not enforced.</p> <code>'list'</code> <p>Returns:</p> Name Type Description <code>output</code> <p>iterator A str iterator based on the input of the desired type (list or tuple)</p>"},{"location":"api/goli.utils.html#goli.utils.arg_checker.check_list1_in_list2","title":"<code>check_list1_in_list2(list1, list2, throw_error=True)</code>","text":"<p>Verify if the list1 (iterator) is included in list2 (iterator). If not, raise an error.</p> <p>Parameters:</p> Name Type Description Default <code>list1,</code> <code>list2</code> <p>list, tuple or object A list or tuple containing the elements to verify the inclusion. If an object is provided other than a list or tuple, then it is considered as a list of a single element.</p> required <code>throw_error</code> <p>bool Whether to throw an error if list1 is not in list2</p> <code>True</code> <p>Returns:</p> Name Type Description <code>list1_in_list2</code> <p>bool A boolean representing the inclusion of list1 in list2. It is returned if throw_error is set to false</p>"},{"location":"api/goli.utils.html#goli.utils.decorators","title":"<code>goli.utils.decorators</code>","text":""},{"location":"api/goli.utils.html#goli.utils.decorators.classproperty","title":"<code>classproperty</code>","text":"<p>         Bases: <code>property</code></p> <p>Decorator used to declare a class property, defined for the class without needing to instanciate an object.</p> <p>Example</p> <pre><code>    @classproperty\n    def my_class_property(cls):\n        return 5\n</code></pre>"},{"location":"api/goli.utils.html#goli.utils.dict_tensor","title":"<code>goli.utils.dict_tensor</code>","text":""},{"location":"api/goli.utils.html#goli.utils.dict_tensor.DictTensor","title":"<code>DictTensor</code>","text":"<p>         Bases: <code>dict</code></p> <p>A class that combines the functionality of <code>dict</code> and <code>torch.Tensor</code>. Specifically, it is a dict of Tensor, but it has all the methods and attributes of a Tensor. When a given method or attribute is called, it will be called on each element of the dict, and a new dict is returned.</p> <p>All methods from <code>torch.Tensor</code> and other functions are expected to work on <code>DictTensor</code></p> with the following rules <ul> <li>The function receives one <code>DictTensor</code>: The function will be applied on   all values of the dictionary. Examples are <code>torch.sum</code> or <code>torch.abs</code>.</li> <li>The function receives two <code>DictTensor</code>: The function will be applied on   each pair of Tensor with matching keys. If the keys don't match, an error   will be thrown. Example are operators such as <code>dict_tensor1 + dict_tensor2</code>   or <code>dict_tensor1 == dict_tensor2</code>.</li> </ul> <p>The output of the functions that act on the <code>torch.Tensor</code> level is a <code>dict[Any]</code>. If the output is a <code>dict[torch.Tensor]</code>, it is converted automatically to <code>DictTensor</code>.</p> <p>If a given method is available in both <code>dict</code> and <code>torch.Tensor</code>, then the one from <code>Tensor</code> is not available. Exceptions to the above rules are the <code>__dict__</code> and all comparison methods:</p> <ul> <li><code>__dict__</code>: Not available for this class.</li> <li><code>__lt__</code> or <code>&lt;</code>: Supports two-way comparison between <code>DictTensor</code> and number, <code>torch.Tensor</code> or <code>DictTensor</code>.</li> <li><code>__le__</code> or <code>&lt;=</code>: Supports two-way comparison between <code>DictTensor</code> and number, <code>torch.Tensor</code> or <code>DictTensor</code>.</li> <li><code>__eq__</code> or <code>==</code>: Supports two-way comparison between <code>DictTensor</code> and number, <code>torch.Tensor</code> or <code>DictTensor</code>.</li> <li><code>__ne__</code> or <code>!=</code>: Supports two-way comparison between <code>DictTensor</code> and number, <code>torch.Tensor</code> or <code>DictTensor</code>.</li> <li><code>__gt__</code> or <code>&gt;</code>: Supports two-way comparison between <code>DictTensor</code> and number, <code>torch.Tensor</code> or <code>DictTensor</code>.</li> <li><code>__ge__</code> or <code>&gt;=</code>: Supports two-way comparison between <code>DictTensor</code> and number, <code>torch.Tensor</code> or <code>DictTensor</code>.</li> </ul> <p>The only major function from <code>torch.Tensor</code> that doesn't work (to my knowledge) is the indexing. Indexing has to be done by manually looping the dictionary.</p> Example <pre><code># Summing a float to a DictTensor\ndict_ten = DictTensor({\n        \"a\": torch.zeros(5),\n        \"b\": torch.zeros(2, 3),\n        \"c\": torch.zeros(1, 2),\n    })\ndict_ten + 2\n&gt;&gt;\n{'a': tensor([2., 2., 2., 2., 2.]),\n'b': tensor([[2., 2., 2.],\n        [2., 2., 2.]]),\n'c': tensor([[2., 2.]])}\n\n# Summing a DictTensor to a DictTensor\ndict_ten = DictTensor({\n        \"a\": torch.zeros(5),\n        \"b\": torch.zeros(2, 3) + 0.1,\n        \"c\": torch.zeros(1, 2) + 0.5,\n    })\ndict_ten2 = DictTensor({\n        \"a\": torch.zeros(5) + 0.2,\n        \"b\": torch.zeros(2, 3) + 0.3,\n        \"c\": torch.zeros(1, 2) + 0.4,\n    })\ndict_ten + dict_ten2\n&gt;&gt;\n{'a': tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000]),\n'b': tensor([[0.4000, 0.4000, 0.4000],\n        [0.4000, 0.4000, 0.4000]]),\n'c': tensor([[0.9000, 0.9000]])}\n\n\n# Summing a accross the first axis\ndict_ten = DictTensor({\n        \"a\": torch.zeros(5) + 0.1,\n        \"b\": torch.zeros(2, 3) + 0.2,\n        \"c\": torch.zeros(1, 2) + 0.5,\n    })\ndict_ten.sum(axis=0)\n&gt;&gt;\n{'a': tensor(0.5000),\n'b': tensor([0.4000, 0.4000, 0.4000]),\n'c': tensor([0.5000, 0.5000])}\n\n# Getting the shape of each tensor\ndict_ten = DictTensor({\n        \"a\": torch.zeros(5) + 0.1,\n        \"b\": torch.zeros(2, 3) + 0.2,\n        \"c\": torch.zeros(1, 2) + 0.5,\n    })\ndict_ten.shape\n&gt;&gt;\n{'a': torch.Size([5]), 'b': torch.Size([2, 3]), 'c': torch.Size([1, 2])}\n</code></pre>"},{"location":"api/goli.utils.html#goli.utils.dict_tensor.DictTensor.__init__","title":"<code>__init__(dic)</code>","text":"<p>Take a dictionary of <code>torch.Tensors</code>, and transform it into a <code>DictTensor</code>. Register all the required methods from <code>torch.Tensors</code>, but modify them to work on dictionary instead.</p>"},{"location":"api/goli.utils.html#goli.utils.dict_tensor.DictTensor.apply","title":"<code>apply(func, *args, **kwargs)</code>","text":"<p>Apply a function on every Tensor \"value\" of the current dictionary</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>function to be called on each Tensor</p> required <code>*args,</code> <code>**kwargs</code> <p>Additional parameters to the function. Note that the Tensor should be the first input to the function.</p> required <p>Returns:</p> Type Description <code>Union[DictTensor, Dict[Any]]</code> <p><code>DictTensor</code> if the output of the function is a <code>torch.Tensor</code>,</p> <code>Union[DictTensor, Dict[Any]]</code> <p>or <code>dict[X]</code> if the output of the function is of type<code>X</code>.</p>"},{"location":"api/goli.utils.html#goli.utils.fs","title":"<code>goli.utils.fs</code>","text":""},{"location":"api/goli.utils.html#goli.utils.fs.copy","title":"<code>copy(source, destination, chunk_size=None, force=False, progress=False, leave_progress=True)</code>","text":"<p>Copy one file to another location across different filesystem (local, S3, GCS, etc).</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Union[str, os.PathLike, io.IOBase, fsspec.core.OpenFile]</code> <p>path or file-like object to copy from.</p> required <code>destination</code> <code>Union[str, os.PathLike, io.IOBase, fsspec.core.OpenFile]</code> <p>path or file-like object to copy to.</p> required <code>chunk_size</code> <code>int</code> <p>the chunk size to use. If progress is enabled the chunk size is <code>None</code>, it is set to 2048.</p> <code>None</code> <code>force</code> <code>bool</code> <p>whether to overwrite the destination file it it exists.</p> <code>False</code> <code>progress</code> <code>bool</code> <p>whether to display a progress bar.</p> <code>False</code> <code>leave_progress</code> <code>bool</code> <p>whether to hide the progress bar once the copy is done.</p> <code>True</code>"},{"location":"api/goli.utils.html#goli.utils.fs.exists","title":"<code>exists(path)</code>","text":"<p>Check whether a file exists.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, os.PathLike, fsspec.core.OpenFile, io.IOBase]</code> <p>a path supported by <code>fsspec</code> such as local, s3, gcs, etc.</p> required"},{"location":"api/goli.utils.html#goli.utils.fs.exists_and_not_empty","title":"<code>exists_and_not_empty(path)</code>","text":"<p>Check whether a directory exists and is not empty.</p>"},{"location":"api/goli.utils.html#goli.utils.fs.get_basename","title":"<code>get_basename(path)</code>","text":"<p>Get the basename of a file or a folder.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, os.PathLike]</code> <p>a path supported by <code>fsspec</code> such as local, s3, gcs, etc.</p> required"},{"location":"api/goli.utils.html#goli.utils.fs.get_cache_dir","title":"<code>get_cache_dir(suffix=None, create=True)</code>","text":"<p>Get a local cache directory. You can append a suffix folder to it and optionnaly create the folder if it doesn't exist.</p>"},{"location":"api/goli.utils.html#goli.utils.fs.get_extension","title":"<code>get_extension(path)</code>","text":"<p>Get the extension of a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, os.PathLike]</code> <p>a path supported by <code>fsspec</code> such as local, s3, gcs, etc.</p> required"},{"location":"api/goli.utils.html#goli.utils.fs.get_mapper","title":"<code>get_mapper(path)</code>","text":"<p>Get the fsspec mapper.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, os.PathLike]</code> <p>a path supported by <code>fsspec</code> such as local, s3, gcs, etc.</p> required"},{"location":"api/goli.utils.html#goli.utils.fs.get_size","title":"<code>get_size(file)</code>","text":"<p>Get the size of a file given its path. Return None if the size can't be retrieved.</p>"},{"location":"api/goli.utils.html#goli.utils.fs.join","title":"<code>join(*paths)</code>","text":"<p>Join paths together. The first element determine the filesystem to use (and so the separator.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <p>a list of paths supported by <code>fsspec</code> such as local, s3, gcs, etc.</p> <code>()</code>"},{"location":"api/goli.utils.html#goli.utils.fs.mkdir","title":"<code>mkdir(path, exist_ok=True)</code>","text":"<p>Create directory including potential parents.</p>"},{"location":"api/goli.utils.html#goli.utils.fs.rm","title":"<code>rm(path, recursive=False, maxdepth=None)</code>","text":"<p>Delete a file or a directory with all nested files.</p>"},{"location":"api/goli.utils.html#goli.utils.hashing","title":"<code>goli.utils.hashing</code>","text":""},{"location":"api/goli.utils.html#goli.utils.hashing.get_md5_hash","title":"<code>get_md5_hash(object)</code>","text":"<p>MD5 hash of any object. The object is converted to a YAML string before being hashed. This allows for nested dictionaries/lists and for hashing of classes and their attributes.</p>"},{"location":"api/goli.utils.html#goli.utils.moving_average_tracker","title":"<code>goli.utils.moving_average_tracker</code>","text":""},{"location":"api/goli.utils.html#goli.utils.mup","title":"<code>goli.utils.mup</code>","text":""},{"location":"api/goli.utils.html#goli.utils.mup.apply_infshapes","title":"<code>apply_infshapes(model, infshapes)</code>","text":"<p>Modified from the regular <code>mup.apply_infshapes</code> by explicitly adding <code>base_dim</code> to the <code>MuReadoutGoli</code>. This allows the code to work on IPUs.</p>"},{"location":"api/goli.utils.html#goli.utils.mup.set_base_shapes","title":"<code>set_base_shapes(model, base, rescale_params=True, delta=None, savefile=None, do_assert=True)</code>","text":"<p>Sets the <code>p.infshape</code> attribute for each parameter <code>p</code> of <code>model</code>.</p> <p>Code taken from the <code>mup</code> package from Microsoft https://github.com/microsoft/mup. No change except in the <code>apply_inf_shapes</code>, using the one from Goli instead of <code>mup</code></p> Inputs <p>model: nn.Module instance base: The base model.     Can be nn.Module, a dict of shapes, a str, or None.     If None, then defaults to <code>model</code>     If str, then treated as filename for yaml encoding of a dict of base shapes. rescale_params:     assuming the model is initialized using the default pytorch init (or     He initialization etc that scale the same way with fanin): If True     (default), rescales parameters to have the correct (\u03bcP) variances. do_assert:</p> Output <p>same object as <code>model</code>, after setting the <code>infshape</code> attribute of each parameter.</p>"},{"location":"api/goli.utils.html#goli.utils.read_file","title":"<code>goli.utils.read_file</code>","text":"<p>Utiles for data parsing</p>"},{"location":"api/goli.utils.html#goli.utils.read_file.file_opener","title":"<code>file_opener(filename, mode='r')</code>","text":"<p>File reader stream</p>"},{"location":"api/goli.utils.html#goli.utils.read_file.parse_sdf_to_dataframe","title":"<code>parse_sdf_to_dataframe(sdf_path, as_cxsmiles=True, skiprows=None)</code>","text":"<p>Allows to read an SDF file containing molecular informations, convert it to a pandas DataFrame and convert the molecules to SMILES. It also lists a warning of all the molecules that couldn't be read.</p>"},{"location":"api/goli.utils.html#goli.utils.read_file.parse_sdf_to_dataframe--arguments","title":"Arguments","text":"<pre><code>sdf_path: str\n    The full path and name of the sdf file to read\nas_cxsmiles: bool, optional\n    Whether to use the CXSMILES notation, which preserves atomic coordinates,\n    stereocenters, and much more.\n    See `https://dl.chemaxon.com/marvin-archive/latest/help/formats/cxsmiles-doc.html`\n    (Default = True)\nskiprows: int, list\n    The rows to skip from dataset. The enumerate index starts from 1 insted of 0.\n    (Default = None)\n</code></pre>"},{"location":"api/goli.utils.html#goli.utils.read_file.read_file","title":"<code>read_file(filepath, as_ext=None, **kwargs)</code>","text":"<p>Allow to read different file format and parse them into a MolecularDataFrame. Supported formats are: * csv (.csv, .smile, .smiles, .tsv) * txt (.txt) * xls (.xls, .xlsx, .xlsm, .xls*) * sdf (.sdf) * pkl (.pkl)</p>"},{"location":"api/goli.utils.html#goli.utils.read_file.read_file--arguments","title":"Arguments","text":"<pre><code>filepath: str\n    The full path and name of the file to read.\n    It also supports the s3 url path.\nas_ext: str, Optional\n    The file extension used to read the file. If None, the extension is deduced\n    from the extension of the file. Otherwise, no matter the file extension,\n    the file will be read according to the specified ``as_ext``.\n    (Default=None)\n**kwargs: All the optional parameters required for the desired file reader.\n</code></pre> <p>TODO: unit test to make sure it works well with all extensions</p>"},{"location":"api/goli.utils.html#goli.utils.read_file.read_file--returns","title":"Returns","text":"<pre><code>df: pandas.DataFrame\n    The ``pandas.DataFrame`` containing the parsed data\n</code></pre>"},{"location":"api/goli.utils.html#goli.utils.safe_run","title":"<code>goli.utils.safe_run</code>","text":""},{"location":"api/goli.utils.html#goli.utils.safe_run.SafeRun","title":"<code>SafeRun</code>","text":""},{"location":"api/goli.utils.html#goli.utils.safe_run.SafeRun.__enter__","title":"<code>__enter__()</code>","text":"<p>Print that the with-statement started, if <code>self.verbose &gt;= 2</code></p>"},{"location":"api/goli.utils.html#goli.utils.safe_run.SafeRun.__exit__","title":"<code>__exit__(type, value, traceback)</code>","text":"<p>Handle the error. Raise it if <code>self.raise_error==True</code>, otherwise ignore it and print it if <code>self.verbose &gt;= 1</code>. Also print that the with-statement is completed if <code>self.verbose &gt;= 2</code>.</p>"},{"location":"api/goli.utils.html#goli.utils.safe_run.SafeRun.__init__","title":"<code>__init__(name, raise_error=True, verbose=2)</code>","text":"<p>Run some code with error handling and some printing, using the with statment.</p> Example <p>In the example below, the <code>2+None</code>, an error will be caught and printed. <pre><code>with SafeRun(name=\"Addition that fails\", raise_error=False):\n    2 + None\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the code, used for printing</p> required <code>raise_error</code> <code>bool</code> <p>Whether to raise an error, or to catch it and print instead</p> <code>True</code> <code>verbose</code> <code>int</code> <p>The level of verbosity 0: Do not print anything 1: Print only the traced stack when an error is caught and <code>raise_error</code> is False 2: Print headers and footers at the start and exit of the with statement.</p> <code>2</code>"},{"location":"api/goli.utils.html#goli.utils.spaces","title":"<code>goli.utils.spaces</code>","text":""},{"location":"api/goli.utils.html#goli.utils.tensor","title":"<code>goli.utils.tensor</code>","text":""},{"location":"api/goli.utils.html#goli.utils.tensor.ModuleListConcat","title":"<code>ModuleListConcat</code>","text":"<p>         Bases: <code>torch.nn.ModuleList</code></p> <p>A list of neural modules similar to <code>torch.nn.ModuleList</code>, but where the modules are applied on the same input and concatenated together, instead of being applied sequentially.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>The dimension for the concatenation</p> <code>-1</code>"},{"location":"api/goli.utils.html#goli.utils.tensor.ModuleListConcat.forward","title":"<code>forward(*args, **kwargs)</code>","text":"<p>Apply all layers on the <code>args</code> and <code>kwargs</code>, and concatenate their output alongside the dimension <code>self.dim</code>.</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.ModuleWrap","title":"<code>ModuleWrap</code>","text":"<p>         Bases: <code>torch.nn.Module</code></p> <p>Wrap a function into a <code>torch.nn.Module</code>, with possible <code>*args</code> and <code>**kwargs</code></p> <p>Parameters:</p> Name Type Description Default <code>func</code> <p>function to wrap into a module</p> required"},{"location":"api/goli.utils.html#goli.utils.tensor.ModuleWrap.forward","title":"<code>forward(*args, **kwargs)</code>","text":"<p>Calls the function <code>self.func</code> with the arguments <code>self.func(*self.args, *args, **self.kwargs, **kwargs)</code></p>"},{"location":"api/goli.utils.html#goli.utils.tensor.arg_in_func","title":"<code>arg_in_func(fn, arg)</code>","text":"<p>Check if a function takes the given argument.</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.arg_in_func--parameters","title":"Parameters","text":"func <p>The function to check the argument.</p> str <p>The name of the argument.</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.arg_in_func--returns","title":"Returns","text":"<pre><code>res: bool\n    True if the function contains the argument, otherwise False.\n</code></pre>"},{"location":"api/goli.utils.html#goli.utils.tensor.is_device_cuda","title":"<code>is_device_cuda(device, ignore_errors=False)</code>","text":"<p>Check wheter the given device is a cuda device.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>str, torch.device object to check for cuda</p> required <code>ignore_errors</code> <code>bool</code> <p>bool Whether to ignore the error if the device is not recognized. Otherwise, <code>False</code> is returned in case of errors.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>is_cuda</code> <code>bool</code> <p>bool</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.is_dtype_numpy_array","title":"<code>is_dtype_numpy_array(dtype)</code>","text":"<p>Verify if the dtype is a numpy dtype</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>Union[np.dtype, torch.dtype]</code> <p>dtype The dtype of a value. E.g. np.int32, str, torch.float</p> required <p>Returns:</p> Type Description <code>bool</code> <p>A boolean saying if the dtype is a numpy dtype</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.is_dtype_torch_tensor","title":"<code>is_dtype_torch_tensor(dtype)</code>","text":"<p>Verify if the dtype is a torch dtype</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>Union[np.dtype, torch.dtype]</code> <p>dtype The dtype of a value. E.g. np.int32, str, torch.float</p> required <p>Returns:</p> Type Description <code>bool</code> <p>A boolean saying if the dtype is a torch dtype</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.nan_mad","title":"<code>nan_mad(input, normal=True, **kwargs)</code>","text":"<p>Return the median absolute deviation of all elements, while ignoring the NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Tensor</code> <p>The input tensor.</p> required <code>normal</code> <code>bool</code> <p>whether to multiply the result by 1.4826 to mimic the standard deviation for normal distributions.</p> <code>True</code> <code>dim</code> <code>int or tuple(int</code> <p>The dimension or dimensions to reduce.</p> required <code>keepdim</code> <code>bool</code> <p>whether the output tensor has dim retained or not.</p> required <code>dtype</code> <code>torch.dtype</code> <p>The desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None.</p> required <p>Returns:</p> Name Type Description <code>output</code> <code>Tensor</code> <p>The resulting median absolute deviation of the tensor</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.nan_mean","title":"<code>nan_mean(input, *args, **kwargs)</code>","text":"<p>Return the mean of all elements, while ignoring the NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Tensor</code> <p>The input tensor.</p> required <code>dim</code> <code>int or tuple(int</code> <p>The dimension or dimensions to reduce.</p> required <code>keepdim</code> <code>bool</code> <p>whether the output tensor has dim retained or not.</p> required <code>dtype</code> <code>torch.dtype</code> <p>The desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None.</p> required <p>Returns:</p> Name Type Description <code>output</code> <code>Tensor</code> <p>The resulting mean of the tensor</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.nan_median","title":"<code>nan_median(input, **kwargs)</code>","text":"<p>Return the median of all elements, while ignoring the NaNs. Contrarily to <code>torch.nanmedian</code>, this function supports a list of dimensions, or <code>dim=None</code>, and does not return the index of the median</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Tensor</code> <p>The input tensor.</p> required <code>dim</code> <code>int or tuple(int</code> <p>The dimension or dimensions to reduce.</p> required <code>keepdim</code> <code>bool</code> <p>whether the output tensor has dim retained or not.</p> required <code>dtype</code> <code>torch.dtype</code> <p>The desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None.</p> required <p>Returns:</p> Name Type Description <code>output</code> <code>Tensor</code> <p>The resulting median of the tensor. Contrarily to <code>torch.median</code>, it does not return the index of the median</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.nan_std","title":"<code>nan_std(input, unbiased=True, **kwargs)</code>","text":"<p>Return the standard deviation of all elements, while ignoring the NaNs. If unbiased is True, Bessel\u2019s correction will be used. Otherwise, the sample deviation is calculated, without any correction.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Tensor</code> <p>The input tensor.</p> required <code>unbiased</code> <code>bool</code> <p>whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1).</p> <code>True</code> <code>dim</code> <code>int or tuple(int</code> <p>The dimension or dimensions to reduce.</p> required <code>keepdim</code> <code>bool</code> <p>whether the output tensor has dim retained or not.</p> required <code>dtype</code> <code>torch.dtype</code> <p>The desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None.</p> required <p>Returns:</p> Name Type Description <code>output</code> <code>Tensor</code> <p>The resulting standard deviation of the tensor</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.nan_var","title":"<code>nan_var(input, unbiased=True, **kwargs)</code>","text":"<p>Return the variace of all elements, while ignoring the NaNs. If unbiased is True, Bessel\u2019s correction will be used. Otherwise, the sample deviation is calculated, without any correction.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Tensor</code> <p>The input tensor.</p> required <code>unbiased</code> <code>bool</code> <p>whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1).</p> <code>True</code> <code>dim</code> <code>int or tuple(int</code> <p>The dimension or dimensions to reduce.</p> required <code>keepdim</code> <code>bool</code> <p>whether the output tensor has dim retained or not.</p> required <code>dtype</code> <code>torch.dtype</code> <p>The desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None.</p> required <p>Returns:</p> Name Type Description <code>output</code> <code>Tensor</code> <p>The resulting variance of the tensor</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.one_of_k_encoding","title":"<code>one_of_k_encoding(val, classes)</code>","text":"<p>Converts a single value to a one-hot vector.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <code>Any</code> <p>int class to be converted into a one hot vector (integers from 0 to num_classes).</p> required <code>num_classes</code> <p>iterator a list or 1D array of allowed choices for val to take</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>A list of length len(num_classes) + 1</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.parse_valid_args","title":"<code>parse_valid_args(param_dict, fn)</code>","text":"<p>Check if a function takes the given argument.</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.parse_valid_args--parameters","title":"Parameters","text":"func <p>The function to check the argument.</p> dict <p>Dictionary of the argument.</p>"},{"location":"api/goli.utils.html#goli.utils.tensor.parse_valid_args--returns","title":"Returns","text":"<pre><code>param_dict: dict\n    Valid paramter dictionary for the given fucntions.\n</code></pre>"},{"location":"api/goli.visualization.html","title":"goli.visualization","text":""},{"location":"api/goli.visualization.html#goli.visualization.vis_utils","title":"<code>goli.visualization.vis_utils</code>","text":""},{"location":"api/goli.nn/architectures.html","title":"goli.nn.architectures","text":""},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures","title":"<code>goli.nn.architectures.global_architectures</code>","text":""},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FeedForwardGraph","title":"<code>FeedForwardGraph</code>","text":"<p>         Bases: <code>FeedForwardNN</code></p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FeedForwardGraph.__init__","title":"<code>__init__(in_dim, out_dim, hidden_dims, layer_type, depth=None, activation='relu', last_activation='none', dropout=0.0, last_dropout=0.0, normalization='none', first_normalization='none', last_normalization='none', residual_type='none', residual_skip_steps=1, in_dim_edges=0, hidden_dims_edges=[], pooling=['sum'], name='GNN', layer_kwargs=None, virtual_node='none', use_virtual_edges=False, last_layer_is_readout=False)</code>","text":"<p>A flexible neural network architecture, with variable hidden dimensions, support for multiple layer types, and support for different residual connections.</p> <p>This class is meant to work with different graph neural networks layers. Any layer must inherit from <code>goli.nn.base_graph_layer.BaseGraphStructure</code> or <code>goli.nn.base_graph_layer.BaseGraphLayer</code>.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input feature dimensions of the layer</p> required <code>out_dim</code> <code>int</code> <p>Output feature dimensions of the layer</p> required <code>hidden_dims</code> <code>Union[List[int], int]</code> <p>List of dimensions in the hidden layers. Be careful, the \"simple\" residual type only supports hidden dimensions of the same value.</p> required <code>layer_type</code> <code>Union[str, nn.Module]</code> <p>Type of layer to use. Can be a string or nn.Module.</p> required <code>depth</code> <code>Optional[int]</code> <p>If <code>hidden_dims</code> is an integer, <code>depth</code> is 1 + the number of hidden layers to use. If <code>hidden_dims</code> is a <code>list</code>, <code>depth</code> must be <code>None</code>.</p> <code>None</code> <code>activation</code> <code>Union[str, Callable]</code> <p>activation function to use in the hidden layers.</p> <code>'relu'</code> <code>last_activation</code> <code>Union[str, Callable]</code> <p>activation function to use in the last layer.</p> <code>'none'</code> <code>dropout</code> <code>float</code> <p>The ratio of units to dropout. Must be between 0 and 1</p> <code>0.0</code> <code>last_dropout</code> <code>float</code> <p>The ratio of units to dropout for the last layer. Must be between 0 and 1</p> <code>0.0</code> <code>normalization</code> <code>Union[str, Callable]</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'none'</code> <code>first_normalization</code> <code>Union[str, Callable]</code> <p>Whether to use batch normalization before the first layer</p> <code>'none'</code> <code>last_normalization</code> <code>Union[str, Callable]</code> <p>Whether to use batch normalization in the last layer</p> <code>'none'</code> <code>residual_type</code> <code>str</code> <ul> <li>\"none\": No residual connection</li> <li>\"simple\": Residual connection similar to the ResNet architecture.   See class <code>ResidualConnectionSimple</code></li> <li>\"weighted\": Residual connection similar to the Resnet architecture,   but with weights applied before the summation. See class <code>ResidualConnectionWeighted</code></li> <li>\"concat\": Residual connection where the residual is concatenated instead   of being added.</li> <li>\"densenet\": Residual connection where the residual of all previous layers   are concatenated. This leads to a strong increase in the number of parameters   if there are multiple hidden layers.</li> </ul> <code>'none'</code> <code>residual_skip_steps</code> <code>int</code> <p>The number of steps to skip between each residual connection. If <code>1</code>, all the layers are connected. If <code>2</code>, half of the layers are connected.</p> <code>1</code> <code>in_dim_edges</code> <code>int</code> <p>Input edge-feature dimensions of the network. Keep at 0 if not using edge features, or if the layer doesn't support edges.</p> <code>0</code> <code>hidden_dims_edges</code> <code>List[int]</code> <p>Hidden dimensions for the edges. Most models don't support it, so it should only be used for those that do, i.e. <code>GatedGCNLayer</code></p> <code>[]</code> <code>pooling</code> <code>Union[List[str], List[Callable]]</code> <p>The pooling types to use. Multiple pooling can be used, and their results will be concatenated. For node feature predictions, use <code>[\"none\"]</code>. For graph feature predictions see <code>self.parse_pooling_layer</code>. The list must either contain Callables, or the string below</p> <ul> <li>\"none\": No pooling is applied</li> <li>\"sum\": <code>SumPooling</code></li> <li>\"mean\": <code>MeanPooling</code></li> <li>\"max\": <code>MaxPooling</code></li> <li>\"min\": <code>MinPooling</code></li> <li>\"std\": <code>StdPooling</code></li> <li>\"s2s\": <code>Set2Set</code></li> </ul> <code>['sum']</code> <code>name</code> <code>str</code> <p>Name attributed to the current network, for display and printing purposes.</p> <code>'GNN'</code> <code>layer_type</code> <code>Union[str, nn.Module]</code> <p>The type of layers to use in the network. A class that inherits from <code>goli.nn.base_graph_layer.BaseGraphStructure</code>, or one of the following strings</p> <ul> <li>\"pyg:gin\": GINConvPyg</li> <li>\"pyg:gine\": GINEConvPyg</li> <li>\"pyg:gated-gcn\": GatedGCNPyg</li> <li>\"pyg:pna-msgpass\": PNAMessagePassingPyg</li> </ul> required <code>layer_kwargs</code> <code>Optional[Dict]</code> <p>The arguments to be used in the initialization of the layer provided by <code>layer_type</code></p> <code>None</code> <code>virtual_node</code> <code>str</code> <p>A string associated to the type of virtual node to use, either <code>None</code>, \"none\", \"mean\", \"sum\", \"max\", \"logsum\". See <code>goli.nn.pooling_pyg.VirtualNode</code>.</p> <p>The virtual node will not use any residual connection if <code>residual_type</code> is \"none\". Otherwise, it will use a simple ResNet like residual connection.</p> <code>'none'</code> <code>use_virtual_edges</code> <code>bool</code> <p>A bool flag used to select if the virtual node should use the edges or not</p> <code>False</code> <code>last_layer_is_readout</code> <code>bool</code> <p>Whether the last layer should be treated as a readout layer. Allows to use the <code>mup.MuReadout</code> from the muTransfer method https://github.com/microsoft/mup</p> <code>False</code>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FeedForwardGraph.__repr__","title":"<code>__repr__()</code>","text":"<p>Controls how the class is printed</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FeedForwardGraph.forward","title":"<code>forward(g)</code>","text":"<p>Apply the full graph neural network on the input graph and node features.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Batch</code> <p>pyg Batch graph on which the convolution is done with the keys:</p> <ul> <li> <p><code>\"feat\"</code>: torch.Tensor[..., N, Din]   Node feature tensor, before convolution.   <code>N</code> is the number of nodes, <code>Din</code> is the input features</p> </li> <li> <p><code>\"edge_feat\"</code> (torch.Tensor[..., N, Ein]):   Edge feature tensor, before convolution.   <code>N</code> is the number of nodes, <code>Ein</code> is the input edge features</p> </li> </ul> required <p>Returns:</p> Type Description <code>torch.Tensor</code> <p><code>torch.Tensor[..., M, Dout]</code> or <code>torch.Tensor[..., N, Dout]</code>: Node or graph feature tensor, after the network. <code>N</code> is the number of nodes, <code>M</code> is the number of graphs, <code>Dout</code> is the output dimension <code>self.out_dim</code> If the <code>self.pooling</code> is [<code>None</code>], then it returns node features and the output dimension is <code>N</code>, otherwise it returns graph features and the output dimension is <code>M</code></p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FeedForwardGraph.get_init_kwargs","title":"<code>get_init_kwargs()</code>","text":"<p>Get a dictionary that can be used to instanciate a new object with identical parameters.</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FeedForwardGraph.make_mup_base_kwargs","title":"<code>make_mup_base_kwargs(divide_factor=2.0, factor_in_dim=False)</code>","text":"<p>Create a 'base' model to be used by the <code>mup</code> or <code>muTransfer</code> scaling of the model. The base model is usually identical to the regular model, but with the layers width divided by a given factor (2 by default)</p> Parameter <p>divide_factor: Factor by which to divide the width. factor_in_dim: Whether to factor the input dimension for the nodes</p> <p>Returns:</p> Name Type Description <code>kwargs</code> <code>Dict[str, Any]</code> <p>Dictionary of parameters to be used to instanciate the base model divided by the factor</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FeedForwardNN","title":"<code>FeedForwardNN</code>","text":"<p>         Bases: <code>nn.Module</code>, <code>MupMixin</code></p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FeedForwardNN.__init__","title":"<code>__init__(in_dim, out_dim, hidden_dims, depth=None, activation='relu', last_activation='none', dropout=0.0, last_dropout=0.0, normalization='none', first_normalization='none', last_normalization='none', residual_type='none', residual_skip_steps=1, name='LNN', layer_type='fc', layer_kwargs=None, last_layer_is_readout=False)</code>","text":"<p>A flexible neural network architecture, with variable hidden dimensions, support for multiple layer types, and support for different residual connections.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input feature dimensions of the layer</p> required <code>out_dim</code> <code>int</code> <p>Output feature dimensions of the layer</p> required <code>hidden_dims</code> <code>Union[List[int], int]</code> <p>Either an integer specifying all the hidden dimensions, or a list of dimensions in the hidden layers. Be careful, the \"simple\" residual type only supports hidden dimensions of the same value.</p> required <code>depth</code> <code>Optional[int]</code> <p>If <code>hidden_dims</code> is an integer, <code>depth</code> is 1 + the number of hidden layers to use. If <code>hidden_dims</code> is a list, then <code>depth</code> must be <code>None</code> or equal to <code>len(hidden_dims) + 1</code></p> <code>None</code> <code>activation</code> <code>Union[str, Callable]</code> <p>activation function to use in the hidden layers.</p> <code>'relu'</code> <code>last_activation</code> <code>Union[str, Callable]</code> <p>activation function to use in the last layer.</p> <code>'none'</code> <code>dropout</code> <code>float</code> <p>The ratio of units to dropout. Must be between 0 and 1</p> <code>0.0</code> <code>last_dropout</code> <code>float</code> <p>The ratio of units to dropout for the last_layer. Must be between 0 and 1</p> <code>0.0</code> <code>normalization</code> <code>Union[str, Callable]</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'none'</code> <code>first_normalization</code> <code>Union[str, Callable]</code> <p>Whether to use batch normalization before the first layer</p> <code>'none'</code> <code>last_normalization</code> <code>Union[str, Callable]</code> <p>Whether to use batch normalization in the last layer</p> <code>'none'</code> <code>residual_type</code> <code>str</code> <ul> <li>\"none\": No residual connection</li> <li>\"simple\": Residual connection similar to the ResNet architecture.   See class <code>ResidualConnectionSimple</code></li> <li>\"weighted\": Residual connection similar to the Resnet architecture,   but with weights applied before the summation. See class <code>ResidualConnectionWeighted</code></li> <li>\"concat\": Residual connection where the residual is concatenated instead   of being added.</li> <li>\"densenet\": Residual connection where the residual of all previous layers   are concatenated. This leads to a strong increase in the number of parameters   if there are multiple hidden layers.</li> </ul> <code>'none'</code> <code>residual_skip_steps</code> <code>int</code> <p>The number of steps to skip between each residual connection. If <code>1</code>, all the layers are connected. If <code>2</code>, half of the layers are connected.</p> <code>1</code> <code>name</code> <code>str</code> <p>Name attributed to the current network, for display and printing purposes.</p> <code>'LNN'</code> <code>layer_type</code> <code>Union[str, nn.Module]</code> <p>The type of layers to use in the network. Either \"fc\" as the <code>FCLayer</code>, or a class representing the <code>nn.Module</code> to use.</p> <code>'fc'</code> <code>layer_kwargs</code> <code>Optional[Dict]</code> <p>The arguments to be used in the initialization of the layer provided by <code>layer_type</code></p> <code>None</code> <code>last_layer_is_readout</code> <code>bool</code> <p>Whether the last layer should be treated as a readout layer. Allows to use the <code>mup.MuReadout</code> from the muTransfer method https://github.com/microsoft/mup</p> <code>False</code>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FeedForwardNN.__repr__","title":"<code>__repr__()</code>","text":"<p>Controls how the class is printed</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FeedForwardNN.forward","title":"<code>forward(h)</code>","text":"<p>Apply the neural network on the input features.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>torch.Tensor</code> <p><code>torch.Tensor[..., Din]</code>: Input feature tensor, before the network. <code>Din</code> is the number of input features</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code> <p><code>torch.Tensor[..., Dout]</code>: Output feature tensor, after the network. <code>Dout</code> is the number of output features</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FeedForwardNN.get_init_kwargs","title":"<code>get_init_kwargs()</code>","text":"<p>Get a dictionary that can be used to instanciate a new object with identical parameters.</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FeedForwardNN.make_mup_base_kwargs","title":"<code>make_mup_base_kwargs(divide_factor=2.0, factor_in_dim=False)</code>","text":"<p>Create a 'base' model to be used by the <code>mup</code> or <code>muTransfer</code> scaling of the model. The base model is usually identical to the regular model, but with the layers width divided by a given factor (2 by default)</p> Parameter <p>divide_factor: Factor by which to divide the width. factor_in_dim: Whether to factor the input dimension</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphMultiTaskNetwork","title":"<code>FullGraphMultiTaskNetwork</code>","text":"<p>         Bases: <code>FullGraphNetwork</code></p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphMultiTaskNetwork.out_dim","title":"<code>out_dim: Dict[str, int]</code>  <code>property</code>","text":"<p>Returns the output dimension of the network for each task</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphMultiTaskNetwork.__init__","title":"<code>__init__(task_heads_kwargs, gnn_kwargs, pre_nn_kwargs=None, pe_encoders_kwargs=None, pre_nn_edges_kwargs=None, post_nn_kwargs=None, accelerator_kwargs=None, num_inference_to_average=1, last_layer_is_readout=True, name='Multitask_GNN')</code>","text":"<p>Class that allows to implement a full multi-task graph neural network architecture, including the pre-processing MLP, post-processing MLP and the task-specific heads.</p> <p>In this model, the tasks share a full network as a \"trunk\", and additionally have task-specific MLPs. Each molecular graph is associated with a variety of tasks, so the network outputs the task-specific preedictions for a graph.</p> <p>Parameters:</p> Name Type Description Default <code>task_heads_kwargs</code> <code>Dict[str, Any]</code> <p>This argument is a list of dictionaries containing the arguments for task heads. Each argument is used to initialize a task-specific MLP.</p> required <code>gnn_kwargs</code> <code>Dict[str, Any]</code> <p>key-word arguments to use for the initialization of the pre-processing GNN network using the class <code>FeedForwardGraph</code>. It must respect the following criteria:</p> <ul> <li>gnn_kwargs[\"in_dim\"] must be equal to pre_nn_kwargs[\"out_dim\"]</li> <li>gnn_kwargs[\"out_dim\"] must be equal to post_nn_kwargs[\"in_dim\"]</li> </ul> required <code>pre_nn_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>key-word arguments to use for the initialization of the pre-processing MLP network of the node features before the GNN, using the class <code>FeedForwardNN</code>. If <code>None</code>, there won't be a pre-processing MLP.</p> <code>None</code> <code>pre_nn_edges_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>key-word arguments to use for the initialization of the pre-processing MLP network of the edge features before the GNN, using the class <code>FeedForwardNN</code>. If <code>None</code>, there won't be a pre-processing MLP.</p> <code>None</code> <code>post_nn_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>key-word arguments to use for the initialization of the post-processing MLP network after the GNN, using the class <code>FeedForwardNN</code>. If <code>None</code>, there won't be a post-processing MLP.</p> <code>None</code> <code>accelerator_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>key-word arguments specific to the accelerator being used, e.g. pipeline split points</p> <code>None</code> <code>num_inference_to_average</code> <code>int</code> <p>Number of inferences to average at val/test time. This is used to avoid the noise introduced by positional encodings with sign-flips. In case no such encoding is given, this parameter is ignored. NOTE: The inference time will be slowed-down proportionaly to this parameter.</p> <code>1</code> <code>last_layer_is_readout</code> <code>bool</code> <p>Whether the last layer should be treated as a readout layer. Allows to use the <code>mup.MuReadout</code> from the muTransfer method https://github.com/microsoft/mup</p> <code>True</code> <code>name</code> <code>str</code> <p>Name attributed to the current network, for display and printing purposes.</p> <code>'Multitask_GNN'</code>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphMultiTaskNetwork.__repr__","title":"<code>__repr__()</code>","text":"<p>Print the network architecture</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphMultiTaskNetwork.forward","title":"<code>forward(g)</code>","text":"<p>forward pass of the network</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Batch</code> <p>Batch of pyg molecular graphs</p> required"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphMultiTaskNetwork.make_mup_base_kwargs","title":"<code>make_mup_base_kwargs(divide_factor=2.0)</code>","text":"<p>Create a 'base' model to be used by the <code>mup</code> or <code>muTransfer</code> scaling of the model. The base model is usually identical to the regular model, but with the layers width divided by a given factor (2 by default)</p> Parameter <p>divide_factor: Factor by which to divide the width.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of arguments to be used to initialize the base model.</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphMultiTaskNetwork.set_max_num_nodes_edges_per_graph","title":"<code>set_max_num_nodes_edges_per_graph(max_nodes, max_edges)</code>","text":"<p>Set the maximum number of nodes and edges for all gnn layers</p> <p>Parameters:</p> Name Type Description Default <code>max_nodes</code> <code>Optional[int]</code> <p>Maximum number of nodes in the dataset. This will be useful for certain architecture, but ignored by others.</p> required <code>max_edges</code> <code>Optional[int]</code> <p>Maximum number of edges in the dataset. This will be useful for certain architecture, but ignored by others.</p> required"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork","title":"<code>FullGraphNetwork</code>","text":"<p>         Bases: <code>nn.Module</code>, <code>MupMixin</code></p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork.concat_last_layers","title":"<code>concat_last_layers: Optional[Iterable[int]]</code>  <code>property</code> <code>writable</code>","text":"<p>Property to control the output of the <code>self.forward</code>. If set to a list of integer, the <code>forward</code> function will concatenate the output of different layers.</p> <p>If set to <code>None</code>, the output of the last layer is returned.</p> <p>NOTE: The indexes are inverted. 0 is the last layer, 1 is the second last, etc.</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork.dtype","title":"<code>dtype: torch.dtype</code>  <code>property</code>","text":"<p>Get the dtype of the current network, based on the weights of linear layers within the GNN</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork.in_dim","title":"<code>in_dim: int</code>  <code>property</code>","text":"<p>Returns the input dimension of the network</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork.in_dim_edges","title":"<code>in_dim_edges: int</code>  <code>property</code>","text":"<p>Returns the input edge dimension of the network</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork.out_dim","title":"<code>out_dim: int</code>  <code>property</code>","text":"<p>Returns the output dimension of the network</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork.__init__","title":"<code>__init__(gnn_kwargs, pre_nn_kwargs=None, pre_nn_edges_kwargs=None, pe_encoders_kwargs=None, post_nn_kwargs=None, accelerator_kwargs=None, num_inference_to_average=1, last_layer_is_readout=False, name='FullGNN')</code>","text":"<p>Class that allows to implement a full graph neural network architecture, including the pre-processing MLP and the post processing MLP.</p> <p>Parameters:</p> Name Type Description Default <code>gnn_kwargs</code> <code>Dict[str, Any]</code> <p>key-word arguments to use for the initialization of the pre-processing GNN network using the class <code>FeedForwardGraph</code>. It must respect the following criteria:</p> <ul> <li>gnn_kwargs[\"in_dim\"] must be equal to pre_nn_kwargs[\"out_dim\"]</li> <li>gnn_kwargs[\"out_dim\"] must be equal to post_nn_kwargs[\"in_dim\"]</li> </ul> required <code>pe_encoders_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>key-word arguments to use for the initialization of all positional encoding encoders. See the class <code>EncoderManager</code> for more details.</p> <code>None</code> <code>pre_nn_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>key-word arguments to use for the initialization of the pre-processing MLP network of the node features before the GNN, using the class <code>FeedForwardNN</code>. If <code>None</code>, there won't be a pre-processing MLP.</p> <code>None</code> <code>pre_nn_edges_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>key-word arguments to use for the initialization of the pre-processing MLP network of the edge features before the GNN, using the class <code>FeedForwardNN</code>. If <code>None</code>, there won't be a pre-processing MLP.</p> <code>None</code> <code>post_nn_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>key-word arguments to use for the initialization of the post-processing MLP network after the GNN, using the class <code>FeedForwardNN</code>. If <code>None</code>, there won't be a post-processing MLP.</p> <code>None</code> <code>accelerator_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>key-word arguments specific to the accelerator being used, e.g. pipeline split points</p> <code>None</code> <code>num_inference_to_average</code> <code>int</code> <p>Number of inferences to average at val/test time. This is used to avoid the noise introduced by positional encodings with sign-flips. In case no such encoding is given, this parameter is ignored. NOTE: The inference time will be slowed-down proportionaly to this parameter.</p> <code>1</code> <code>last_layer_is_readout</code> <code>bool</code> <p>Whether the last layer should be treated as a readout layer. Allows to use the <code>mup.MuReadout</code> from the muTransfer method https://github.com/microsoft/mup</p> <code>False</code> <code>name</code> <code>str</code> <p>Name attributed to the current network, for display and printing purposes.</p> <code>'FullGNN'</code>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork.__repr__","title":"<code>__repr__()</code>","text":"<p>Controls how the class is printed</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork.drop_post_nn_layers","title":"<code>drop_post_nn_layers(num_layers_to_drop)</code>","text":"<p>Remove the last layers of the model. Useful for Transfer Learning.</p> <p>Parameters:</p> Name Type Description Default <code>num_layers_to_drop</code> <code>int</code> <p>The number of layers to drop from the <code>self.post_nn</code> network.</p> required"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork.extend_post_nn_layers","title":"<code>extend_post_nn_layers(layers)</code>","text":"<p>Add layers at the end of the model. Useful for Transfer Learning.</p> <p>Parameters:</p> Name Type Description Default <code>layers</code> <code>nn.ModuleList</code> <p>A ModuleList of all the layers to extend</p> required"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork.forward","title":"<code>forward(g)</code>","text":"<p>Apply the pre-processing neural network, the graph neural network, and the post-processing neural network on the graph features.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Batch</code> <p>pyg Batch graph on which the convolution is done. Must contain the following elements:</p> <ul> <li> <p>Node key <code>\"feat\"</code>: <code>torch.Tensor[..., N, Din]</code>.   Input node feature tensor, before the network.   <code>N</code> is the number of nodes, <code>Din</code> is the input features dimension <code>self.pre_nn.in_dim</code></p> </li> <li> <p>Edge key <code>\"edge_feat\"</code>: <code>torch.Tensor[..., N, Ein]</code> Optional.   The edge features to use. It will be ignored if the   model doesn't supporte edge features or if   <code>self.in_dim_edges==0</code>.</p> </li> <li> <p>Other keys related to positional encodings <code>\"pos_enc_feats_sign_flip\"</code>,   <code>\"pos_enc_feats_no_flip\"</code>.</p> </li> </ul> required <p>Returns:</p> Type Description <code>Tensor</code> <p><code>torch.Tensor[..., M, Dout]</code> or <code>torch.Tensor[..., N, Dout]</code>: Node or graph feature tensor, after the network. <code>N</code> is the number of nodes, <code>M</code> is the number of graphs, <code>Dout</code> is the output dimension <code>self.post_nn.out_dim</code> If the <code>self.gnn.pooling</code> is [<code>None</code>], then it returns node features and the output dimension is <code>N</code>, otherwise it returns graph features and the output dimension is <code>M</code></p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork.make_mup_base_kwargs","title":"<code>make_mup_base_kwargs(divide_factor=2.0)</code>","text":"<p>Create a 'base' model to be used by the <code>mup</code> or <code>muTransfer</code> scaling of the model. The base model is usually identical to the regular model, but with the layers width divided by a given factor (2 by default)</p> Parameter <p>divide_factor: Factor by which to divide the width.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the kwargs to create the base model.</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.FullGraphNetwork.set_max_num_nodes_edges_per_graph","title":"<code>set_max_num_nodes_edges_per_graph(max_nodes, max_edges)</code>","text":"<p>Set the maximum number of nodes and edges for all gnn layers and encoder layers</p> <p>Parameters:</p> Name Type Description Default <code>max_nodes</code> <code>Optional[int]</code> <p>Maximum number of nodes in the dataset. This will be useful for certain architecture, but ignored by others.</p> required <code>max_edges</code> <code>Optional[int]</code> <p>Maximum number of edges in the dataset. This will be useful for certain architecture, but ignored by others.</p> required"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.TaskHeads","title":"<code>TaskHeads</code>","text":"<p>         Bases: <code>nn.Module</code>, <code>MupMixin</code></p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.TaskHeads.out_dim","title":"<code>out_dim: Dict[str, int]</code>  <code>property</code>","text":"<p>Returns the output dimension of each task head</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.TaskHeads.__init__","title":"<code>__init__(in_dim, task_heads_kwargs, last_layer_is_readout=True)</code>","text":"<p>Class that groups all multi-task output heads together to provide the task-specific outputs.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input feature dimensions of the layer</p> required <code>task_heads_kwargs</code> <code>Dict[str, Any]</code> <p>This argument is a list of dictionaries corresponding to the arguments for a FeedForwardNN. Each dict of arguments is used to initialize a task-specific MLP.</p> required <code>last_layer_is_readout</code> <code>bool</code> <p>Whether the last layer should be treated as a readout layer. Allows to use the <code>mup.MuReadout</code> from the muTransfer method https://github.com/microsoft/mup</p> <code>True</code>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.TaskHeads.__repr__","title":"<code>__repr__()</code>","text":"<p>Returns a string representation of the task heads</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.TaskHeads.forward","title":"<code>forward(h)</code>","text":"<p>forward function of the task head</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>torch.Tensor</code> <p>input tensor</p> required <p>Returns:</p> Name Type Description <code>task_head_outputs</code> <code>Dict[str, torch.Tensor]</code> <p>Return a dictionary: Dict[task_name, Tensor]</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.global_architectures.TaskHeads.make_mup_base_kwargs","title":"<code>make_mup_base_kwargs(divide_factor=2.0, factor_in_dim=False)</code>","text":"<p>Create a 'base' model to be used by the <code>mup</code> or <code>muTransfer</code> scaling of the model. The base model is usually identical to the regular model, but with the layers width divided by a given factor (2 by default)</p> Parameter <p>divide_factor: Factor by which to divide the width. factor_in_dim: Whether to factor the input dimension</p> <p>Returns:</p> Name Type Description <code>kwargs</code> <code>Dict[str, Any]</code> <p>Dictionary of arguments to be used to initialize the base model</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.pyg_architectures","title":"<code>goli.nn.architectures.pyg_architectures</code>","text":""},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.pyg_architectures.FeedForwardPyg","title":"<code>FeedForwardPyg</code>","text":"<p>         Bases: <code>FeedForwardGraph</code></p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.encoder_manager","title":"<code>goli.nn.architectures.encoder_manager</code>","text":""},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.encoder_manager.EncoderManager","title":"<code>EncoderManager</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.encoder_manager.EncoderManager.in_dims","title":"<code>in_dims: Iterable[int]</code>  <code>property</code>","text":"<p>Returns the input dimensions for all pe-encoders</p> <p>Returns:</p> Name Type Description <code>in_dims</code> <code>Iterable[int]</code> <p>the input dimensions for all pe-encoders</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.encoder_manager.EncoderManager.input_keys","title":"<code>input_keys: Iterable[str]</code>  <code>property</code>","text":"<p>Returns the input keys for all pe-encoders</p> <p>Returns:</p> Name Type Description <code>input_keys</code> <code>Iterable[str]</code> <p>the input keys for all pe-encoders</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.encoder_manager.EncoderManager.out_dim","title":"<code>out_dim: int</code>  <code>property</code>","text":"<p>Returns the output dimension of the pooled embedding from all the pe encoders</p> <p>Returns:</p> Name Type Description <code>out_dim</code> <code>int</code> <p>the output dimension of the pooled embedding from all the pe encoders</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.encoder_manager.EncoderManager.__init__","title":"<code>__init__(pe_encoders_kwargs=None, max_num_nodes_per_graph=None, name='encoder_manager')</code>","text":"<p>Class that allows to runs multiple encoders in parallel and concatenate / pool their outputs.</p> <p>Parameters:</p> Name Type Description Default <code>pe_encoders_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>key-word arguments to use for the initialization of all positional encoding encoders can use the class PE_ENCODERS_DICT: \"la_encoder\"(tested) , \"mlp_encoder\" (not tested), \"signnet_encoder\" (not tested)</p> <code>None</code> <code>name</code> <code>str</code> <p>Name attributed to the current network, for display and printing purposes.</p> <code>'encoder_manager'</code>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.encoder_manager.EncoderManager.forward","title":"<code>forward(g)</code>","text":"<p>forward pass of the pe encoders and pooling</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Batch</code> <p>ptg Batch on which the convolution is done. Must contain the following elements:</p> <ul> <li> <p>Node key <code>\"feat\"</code>: <code>torch.Tensor[..., N, Din]</code>.   Input node feature tensor, before the network.   <code>N</code> is the number of nodes, <code>Din</code> is the input features dimension <code>self.pre_nn.in_dim</code></p> </li> <li> <p>Edge key <code>\"edge_feat\"</code>: <code>torch.Tensor[..., N, Ein]</code> Optional.   The edge features to use. It will be ignored if the   model doesn't supporte edge features or if   <code>self.in_dim_edges==0</code>.</p> </li> <li> <p>Other keys related to positional encodings <code>\"pos_enc_feats_sign_flip\"</code>,   <code>\"pos_enc_feats_no_flip\"</code>.</p> </li> </ul> required <p>Returns:</p> Name Type Description <code>g</code> <code>Batch</code> <p>pyg Batch with the positional encodings added to the graph</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.encoder_manager.EncoderManager.forward_positional_encoding","title":"<code>forward_positional_encoding(g)</code>","text":"<p>Forward pass for the positional encodings (PE), with each PE having it's own encoder defined in <code>self.pe_encoders</code>. All the positional encodings with the same keys are pooled together using <code>self.pe_pooling</code>.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Batch</code> <p>pyg Batch containing the node positional encodings</p> required <p>Returns:</p> Name Type Description <code>pe_node_pooled</code> <code>Dict[str, Tensor]</code> <p>The positional / structural encodings go through</p> <code>Dict[str, Tensor]</code> <p>encoders, then are pooled together according to their keys.</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.encoder_manager.EncoderManager.forward_simple_pooling","title":"<code>forward_simple_pooling(h, pooling, dim)</code>","text":"<p>Apply sum, mean, or max pooling on a Tensor.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>Tensor</code> <p>the Tensor to pool</p> required <code>pooling</code> <code>str</code> <p>string specifiying the pooling method</p> required <code>dim</code> <code>int</code> <p>the dimension to pool over</p> required <p>Returns:</p> Name Type Description <code>pooled</code> <code>Tensor</code> <p>the pooled Tensor</p>"},{"location":"api/goli.nn/architectures.html#goli.nn.architectures.encoder_manager.EncoderManager.make_mup_base_kwargs","title":"<code>make_mup_base_kwargs(divide_factor=2.0)</code>","text":"<p>Create a 'base' model to be used by the <code>mup</code> or <code>muTransfer</code> scaling of the model. The base model is usually identical to the regular model, but with the layers width divided by a given factor (2 by default)</p> Parameter <p>divide_factor: Factor by which to divide the width.</p> <p>Returns:</p> Name Type Description <code>pe_kw</code> <code>Dict[str, Any]</code> <p>the model kwargs where the dimensions are divided by the factor</p>"},{"location":"api/goli.nn/encoders.html","title":"goli.nn.encoders","text":""},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.base_encoder","title":"<code>goli.nn.encoders.base_encoder</code>","text":""},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.base_encoder.BaseEncoder","title":"<code>BaseEncoder</code>","text":"<p>         Bases: <code>torch.nn.Module</code>, <code>MupMixin</code></p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.base_encoder.BaseEncoder.__init__","title":"<code>__init__(input_keys, output_keys, in_dim, out_dim, num_layers, activation='relu', first_normalization=None, use_input_keys_prefix=True)</code>","text":"<p>Base class for all positional and structural encoders. Initialize the encoder with the following arguments:</p> <p>Parameters:</p> Name Type Description Default <code>input_keys</code> <code>List[str]</code> <p>The keys from the graph to use as input</p> required <code>output_keys</code> <code>List[str]</code> <p>The keys to return as output encodings</p> required <code>in_dim</code> <code>int</code> <p>The input dimension for the encoder</p> required <code>out_dim</code> <code>int</code> <p>The output dimension of the encodings</p> required <code>num_layers</code> <code>int</code> <p>The number of layers of the encoder</p> required <code>activation</code> <code>Union[str, Callable]</code> <p>The activation function to use</p> <code>'relu'</code> <code>first_normalization</code> <p>The normalization to use before the first layer</p> <code>None</code> <code>use_input_keys_prefix</code> <code>bool</code> <p>Whether to use the <code>key_prefix</code> argument in the <code>forward</code> method.</p> <code>True</code>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.base_encoder.BaseEncoder.forward","title":"<code>forward(graph, key_prefix=None)</code>  <code>abstractmethod</code>","text":"<p>Forward pass of the encoder on a graph. This is a method to be implemented by the child class.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Batch</code> <p>The input pyg Batch</p> required"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.base_encoder.BaseEncoder.make_mup_base_kwargs","title":"<code>make_mup_base_kwargs(divide_factor=2.0, factor_in_dim=False)</code>","text":"<p>Create a 'base' model to be used by the <code>mup</code> or <code>muTransfer</code> scaling of the model. The base model is usually identical to the regular model, but with the layers width divided by a given factor (2 by default)</p> <p>Parameters:</p> Name Type Description Default <code>divide_factor</code> <code>float</code> <p>Factor by which to divide the width.</p> <code>2.0</code> <code>factor_in_dim</code> <code>bool</code> <p>Whether to factor the input dimension</p> <code>False</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary with the base model arguments</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.base_encoder.BaseEncoder.parse_input_keys","title":"<code>parse_input_keys(input_keys)</code>  <code>abstractmethod</code>","text":"<p>Parse the <code>input_keys</code> argument. This is a method to be implemented by the child class.</p> <p>Parameters:</p> Name Type Description Default <code>input_keys</code> <code>List[str]</code> <p>The input keys to parse</p> required"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.base_encoder.BaseEncoder.parse_input_keys_with_prefix","title":"<code>parse_input_keys_with_prefix(key_prefix)</code>","text":"<p>Parse the <code>input_keys</code> argument, given a certain prefix. If the prefix is <code>None</code>, it is ignored</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.base_encoder.BaseEncoder.parse_output_keys","title":"<code>parse_output_keys(output_keys)</code>  <code>abstractmethod</code>","text":"<p>Parse the <code>output_keys</code> argument.  This is a method to be implemented by the child class.</p> <p>Parameters:</p> Name Type Description Default <code>output_keys</code> <code>List[str]</code> <p>The output keys to parse</p> required"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.gaussian_kernel_pos_encoder","title":"<code>goli.nn.encoders.gaussian_kernel_pos_encoder</code>","text":""},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.gaussian_kernel_pos_encoder.GaussianKernelPosEncoder","title":"<code>GaussianKernelPosEncoder</code>","text":"<p>         Bases: <code>BaseEncoder</code></p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.gaussian_kernel_pos_encoder.GaussianKernelPosEncoder.__init__","title":"<code>__init__(input_keys, output_keys, in_dim, out_dim, embed_dim, num_layers, max_num_nodes_per_graph=None, activation='gelu', first_normalization='none', use_input_keys_prefix=True, num_heads=1)</code>","text":"<p>Configurable gaussian kernel-based Positional Encoding node and edge encoder. Useful for encoding 3D conformation positions.</p> <p>Parameters:</p> Name Type Description Default <code>input_keys</code> <code>List[str]</code> <p>The keys from the pyg graph to use as input</p> required <code>output_keys</code> <code>List[str]</code> <p>The keys to return corresponding to the output encodings</p> required <code>in_dim</code> <code>int</code> <p>The input dimension for the encoder</p> required <code>out_dim</code> <code>int</code> <p>The output dimension of the encodings</p> required <code>embed_dim</code> <code>int</code> <p>The dimension of the embedding</p> required <code>num_layers</code> <code>int</code> <p>The number of layers of the encoder</p> required <code>max_num_nodes_per_graph</code> <code>Optional[int]</code> <p>The maximum number of nodes per graph</p> <code>None</code> <code>activation</code> <code>Union[str, Callable]</code> <p>The activation function to use</p> <code>'gelu'</code> <code>first_normalization</code> <p>The normalization to use before the first layer</p> <code>'none'</code> <code>use_input_keys_prefix</code> <code>bool</code> <p>Whether to use the <code>key_prefix</code> argument in the <code>forward</code> method.</p> <code>True</code> <code>num_heads</code> <code>int</code> <p>The number of heads to use for the multi-head attention</p> <code>1</code>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.gaussian_kernel_pos_encoder.GaussianKernelPosEncoder.forward","title":"<code>forward(batch, key_prefix=None)</code>","text":"<p>forward function of the GaussianKernelPosEncoder class</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Batch</code> <p>The batch of pyg graphs</p> required <code>key_prefix</code> <code>Optional[str]</code> <p>The prefix to use for the input keys</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of the output encodings with keys specified by <code>output_keys</code></p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.gaussian_kernel_pos_encoder.GaussianKernelPosEncoder.make_mup_base_kwargs","title":"<code>make_mup_base_kwargs(divide_factor=2.0, factor_in_dim=False)</code>","text":"<p>Create a 'base' model to be used by the <code>mup</code> or <code>muTransfer</code> scaling of the model. The base model is usually identical to the regular model, but with the layers width divided by a given factor (2 by default)</p> Parameter <p>divide_factor: Factor by which to divide the width. factor_in_dim: Whether to factor the input dimension</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary of the base model kwargs</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.gaussian_kernel_pos_encoder.GaussianKernelPosEncoder.parse_input_keys","title":"<code>parse_input_keys(input_keys)</code>","text":"<p>Parse the <code>input_keys</code>.</p> <p>Parameters:</p> Name Type Description Default <code>input_keys</code> <code>List[str]</code> <p>The input keys to parse</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>The parsed input keys</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.gaussian_kernel_pos_encoder.GaussianKernelPosEncoder.parse_output_keys","title":"<code>parse_output_keys(output_keys)</code>","text":"<p>Parse the <code>output_keys</code>.</p> <p>Parameters:</p> Name Type Description Default <code>output_keys</code> <code>List[str]</code> <p>The output keys to parse</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>The parsed output keys</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.laplace_pos_encoder","title":"<code>goli.nn.encoders.laplace_pos_encoder</code>","text":""},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.laplace_pos_encoder.LapPENodeEncoder","title":"<code>LapPENodeEncoder</code>","text":"<p>         Bases: <code>BaseEncoder</code></p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.laplace_pos_encoder.LapPENodeEncoder.__init__","title":"<code>__init__(input_keys, output_keys, in_dim, hidden_dim, out_dim, num_layers, activation='relu', model_type='DeepSet', num_layers_post=1, dropout=0.0, first_normalization=None, use_input_keys_prefix=True, **model_kwargs)</code>","text":"<p>Laplace Positional Embedding node encoder. LapPE of size dim_pe will get appended to each node feature vector.</p> <p>Parameters:</p> Name Type Description Default <code>input_keys</code> <code>List[str]</code> <p>List of input keys to use from the data object.</p> required <code>output_keys</code> <code>List[str]</code> <p>List of output keys to add to the data object.</p> required <code>in_dim</code> <p>Size of Laplace PE embedding. Only used by the MLP model</p> required <code>hidden_dim</code> <code>int</code> <p>Size of hidden layer</p> required <code>out_dim</code> <code>int</code> <p>Size of final node embedding</p> required <code>num_layers</code> <code>int</code> <p>Number of layers in the MLP</p> required <code>activation</code> <code>Optional[Union[str, Callable]]</code> <p>Activation function to use.</p> <code>'relu'</code> <code>model_type</code> <code>str</code> <p>'Transformer' or 'DeepSet' or 'MLP'</p> <code>'DeepSet'</code> <code>num_layers_post</code> <p>Number of layers to apply after pooling</p> <code>1</code> <code>dropout</code> <p>Dropout rate</p> <code>0.0</code> <code>first_normalization</code> <p>Normalization to apply to the first layer.</p> <code>None</code>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.laplace_pos_encoder.LapPENodeEncoder.forward","title":"<code>forward(batch, key_prefix=None)</code>","text":"<p>Forward pass of the encoder.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Batch</code> <p>pyg Batches of graphs</p> required <code>key_prefix</code> <code>Optional[str]</code> <p>Prefix to use for the input and output keys.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, torch.Tensor]</code> <p>output dictionary with keys as specified in <code>output_keys</code> and their output embeddings.</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.laplace_pos_encoder.LapPENodeEncoder.make_mup_base_kwargs","title":"<code>make_mup_base_kwargs(divide_factor=2.0, factor_in_dim=False)</code>","text":"<p>Create a 'base' model to be used by the <code>mup</code> or <code>muTransfer</code> scaling of the model. The base model is usually identical to the regular model, but with the layers width divided by a given factor (2 by default)</p> Parameter <p>divide_factor: Factor by which to divide the width. factor_in_dim: Whether to factor the input dimension</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary of kwargs to be used to create the base model.</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.laplace_pos_encoder.LapPENodeEncoder.parse_input_keys","title":"<code>parse_input_keys(input_keys)</code>","text":"<p>Parse the input keys and make sure they are supported for this encoder</p> <p>Parameters:</p> Name Type Description Default <code>input_keys</code> <code>List[str]</code> <p>List of input keys to use from the data object.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of parsed input keys</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.laplace_pos_encoder.LapPENodeEncoder.parse_output_keys","title":"<code>parse_output_keys(output_keys)</code>","text":"<p>parse the output keys</p> <p>Parameters:</p> Name Type Description Default <code>output_keys</code> <code>List[str]</code> <p>List of output keys to add to the data object.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of parsed output keys</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.mlp_encoder","title":"<code>goli.nn.encoders.mlp_encoder</code>","text":""},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.mlp_encoder.MLPEncoder","title":"<code>MLPEncoder</code>","text":"<p>         Bases: <code>BaseEncoder</code></p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.mlp_encoder.MLPEncoder.__init__","title":"<code>__init__(input_keys, output_keys, in_dim, hidden_dim, out_dim, num_layers, activation='relu', dropout=0.0, normalization='none', first_normalization='none', use_input_keys_prefix=True)</code>","text":"<p>Configurable kernel-based Positional Encoding node encoder.</p> <p>Parameters:</p> Name Type Description Default <code>input_keys</code> <code>List[str]</code> <p>List of input keys to use from pyg batch graph</p> required <code>output_keys</code> <code>str</code> <p>List of output keys to add to the pyg batch graph</p> required <code>in_dim</code> <p>input dimension of the mlp encoder</p> required <code>hidden_dim</code> <p>hidden dimension of the mlp encoder</p> required <code>out_dim</code> <p>output dimension of the mlp encoder</p> required <code>num_layers</code> <p>number of layers of the mlp encoder</p> required <code>activation</code> <p>activation function to use</p> <code>'relu'</code> <code>dropout</code> <p>dropout to use</p> <code>0.0</code> <code>normalization</code> <p>normalization to use</p> <code>'none'</code> <code>first_normalization</code> <p>normalization to use before the first layer</p> <code>'none'</code> <code>use_input_keys_prefix</code> <code>bool</code> <p>Whether to use the <code>key_prefix</code> argument</p> <code>True</code>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.mlp_encoder.MLPEncoder.forward","title":"<code>forward(batch, key_prefix=None)</code>","text":"<p>forward function of the mlp encoder</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Batch</code> <p>pyg batch graph</p> required <code>key_prefix</code> <code>Optional[str]</code> <p>Prefix to use for the input keys</p> <code>None</code> <p>Returns:</p> Name Type Description <code>output</code> <code>Dict[str, torch.Tensor]</code> <p>Dictionary of output embeddings with keys specified by input_keys</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.mlp_encoder.MLPEncoder.make_mup_base_kwargs","title":"<code>make_mup_base_kwargs(divide_factor=2.0, factor_in_dim=False)</code>","text":"<p>Create a 'base' model to be used by the <code>mup</code> or <code>muTransfer</code> scaling of the model. The base model is usually identical to the regular model, but with the layers width divided by a given factor (2 by default)</p> Parameter <p>divide_factor: Factor by which to divide the width. factor_in_dim: Whether to factor the input dimension</p> <p>Returns:</p> Name Type Description <code>base_kwargs</code> <code>Dict[str, Any]</code> <p>Dictionary of kwargs to use for the base model</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.mlp_encoder.MLPEncoder.parse_input_keys","title":"<code>parse_input_keys(input_keys)</code>","text":"<p>Parse the <code>input_keys</code>.</p> <p>Parameters:</p> Name Type Description Default <code>input_keys</code> <code>List[str]</code> <p>List of input keys to use from pyg batch graph</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>parsed input_keys</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.mlp_encoder.MLPEncoder.parse_output_keys","title":"<code>parse_output_keys(output_keys)</code>","text":"<p>Parse the <code>output_keys</code>.</p> <p>Parameters:</p> Name Type Description Default <code>output_keys</code> <code>List[str]</code> <p>List of output keys to add to the pyg batch graph</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>parsed output_keys</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.signnet_pos_encoder","title":"<code>goli.nn.encoders.signnet_pos_encoder</code>","text":"<p>SignNet https://arxiv.org/abs/2202.13013 based on https://github.com/cptq/SignNet-BasisNet</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.signnet_pos_encoder.GINDeepSigns","title":"<code>GINDeepSigns</code>","text":"<p>         Bases: <code>nn.Module</code></p> <p>Sign invariant neural network with MLP aggregation. f(v1, ..., vk) = rho(enc(v1) + enc(-v1), ..., enc(vk) + enc(-vk))</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.signnet_pos_encoder.MaskedGINDeepSigns","title":"<code>MaskedGINDeepSigns</code>","text":"<p>         Bases: <code>nn.Module</code></p> <p>Sign invariant neural network with sum pooling and DeepSet. f(v1, ..., vk) = rho(enc(v1) + enc(-v1), ..., enc(vk) + enc(-vk))</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.signnet_pos_encoder.SignNetNodeEncoder","title":"<code>SignNetNodeEncoder</code>","text":"<p>         Bases: <code>BaseEncoder</code></p> <p>SignNet Positional Embedding node encoder. https://arxiv.org/abs/2202.13013 https://github.com/cptq/SignNet-BasisNet</p> <p>Uses precomputated Laplacian eigen-decomposition, but instead of eigen-vector sign flipping + DeepSet/Transformer, computes the PE as: SignNetPE(v_1, ... , v_k) = \\rho ( [\\phi(v_i) + \\rhi(-v_i)]^k_i=1 ) where \\phi is GIN network applied to k first non-trivial eigenvectors, and \\rho is an MLP if k is a constant, but if all eigenvectors are used then \\rho is DeepSet with sum-pooling.</p> <p>SignNetPE of size dim_pe will get appended to each node feature vector.</p> <p>Parameters:</p> Name Type Description Default <code>dim_emb</code> <p>Size of final node embedding</p> required"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.signnet_pos_encoder.SignNetNodeEncoder.make_mup_base_kwargs","title":"<code>make_mup_base_kwargs(divide_factor=2.0, factor_in_dim=False)</code>","text":"<p>Create a 'base' model to be used by the <code>mup</code> or <code>muTransfer</code> scaling of the model. The base model is usually identical to the regular model, but with the layers width divided by a given factor (2 by default)</p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.signnet_pos_encoder.SignNetNodeEncoder.make_mup_base_kwargs--todo-update-this-it-is-broken","title":"TODO: Update this. It is broken","text":"<p>Parameters:</p> Name Type Description Default <code>divide_factor</code> <code>float</code> <p>Factor by which to divide the width.</p> <code>2.0</code> <code>factor_in_dim</code> <code>bool</code> <p>Whether to factor the input dimension</p> <code>False</code>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.signnet_pos_encoder.SimpleGIN","title":"<code>SimpleGIN</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"api/goli.nn/encoders.html#goli.nn.encoders.signnet_pos_encoder.SimpleGIN.__init__","title":"<code>__init__(in_dim, hidden_dim, out_dim, num_layers, normalization='none', dropout=0.5, activation='relu')</code>","text":"<p>not supported yet</p>"},{"location":"api/goli.nn/goli.nn.html","title":"goli.nn","text":""},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer","title":"<code>goli.nn.base_graph_layer</code>","text":""},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.BaseGraphModule","title":"<code>BaseGraphModule</code>","text":"<p>         Bases: <code>BaseGraphStructure</code>, <code>nn.Module</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.BaseGraphModule.__init__","title":"<code>__init__(in_dim, out_dim, activation='relu', dropout=0.0, normalization='none', layer_idx=None, layer_depth=None, droppath_rate=0.0)</code>","text":"<p>Abstract class used to standardize the implementation of Pyg layers in the current library. It will allow a network to seemlesly swap between different GNN layers by better understanding the expected inputs and outputs.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input feature dimensions of the layer</p> required <code>out_dim</code> <code>int</code> <p>Output feature dimensions of the layer</p> required <code>activation</code> <code>Union[str, Callable]</code> <p>activation function to use in the layer</p> <code>'relu'</code> <code>dropout</code> <code>float</code> <p>The ratio of units to dropout. Must be between 0 and 1</p> <code>0.0</code> <code>normalization</code> <code>Union[str, Callable]</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'none'</code> <code>layer_idx</code> <code>Optional[int]</code> <p>The index of the current layer</p> <code>None</code> <code>layer_depth</code> <code>Optional[int]</code> <p>The total depth (number of layers) associated to this specific layer</p> <code>None</code> <code>droppath_rate</code> <code>float</code> <p>stochastic depth drop rate, between 0 and 1, see https://arxiv.org/abs/1603.09382</p> <code>0.0</code>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.BaseGraphStructure","title":"<code>BaseGraphStructure</code>","text":""},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.BaseGraphStructure.layer_inputs_edges","title":"<code>layer_inputs_edges: bool</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Abstract method. Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_input_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether the layer uses input edges in the forward pass</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.BaseGraphStructure.layer_outputs_edges","title":"<code>layer_outputs_edges: bool</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Abstract method. Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_output_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether the layer outputs edges in the forward pass</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.BaseGraphStructure.max_num_edges_per_graph","title":"<code>max_num_edges_per_graph: Optional[int]</code>  <code>property</code> <code>writable</code>","text":"<p>Get the maximum number of nodes per graph. Useful for reshaping a compiled model (IPU)</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.BaseGraphStructure.max_num_nodes_per_graph","title":"<code>max_num_nodes_per_graph: Optional[int]</code>  <code>property</code> <code>writable</code>","text":"<p>Get the maximum number of nodes per graph. Useful for reshaping a compiled model (IPU)</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.BaseGraphStructure.out_dim_factor","title":"<code>out_dim_factor: int</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Abstract method. Get the factor by which the output dimension is multiplied for the next layer.</p> <p>For standard layers, this will return <code>1</code>.</p> <p>But for others, such as <code>GatLayer</code>, the output is the concatenation of the outputs from each head, so the out_dim gets multiplied by the number of heads, and this function should return the number of heads.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The factor that multiplies the output dimensions</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.BaseGraphStructure.__init__","title":"<code>__init__(in_dim, out_dim, activation='relu', dropout=0.0, normalization='none', layer_idx=None, layer_depth=None, droppath_rate=0.0)</code>","text":"<p>Abstract class used to standardize the implementation of Pyg layers in the current library. It will allow a network to seemlesly swap between different GNN layers by better understanding the expected inputs and outputs.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input feature dimensions of the layer</p> required <code>out_dim</code> <code>int</code> <p>Output feature dimensions of the layer</p> required <code>activation</code> <code>Union[str, Callable]</code> <p>activation function to use in the layer</p> <code>'relu'</code> <code>dropout</code> <code>float</code> <p>The ratio of units to dropout. Must be between 0 and 1</p> <code>0.0</code> <code>normalization</code> <code>Union[str, Callable]</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'none'</code> <code>layer_idx</code> <code>Optional[int]</code> <p>The index of the current layer</p> <code>None</code> <code>layer_depth</code> <code>Optional[int]</code> <p>The total depth (number of layers) associated to this specific layer</p> <code>None</code> <code>droppath_rate</code> <code>float</code> <p>stochastic depth drop rate, between 0 and 1, see https://arxiv.org/abs/1603.09382</p> <code>0.0</code>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.BaseGraphStructure.__repr__","title":"<code>__repr__()</code>","text":"<p>Controls how the class is printed</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.BaseGraphStructure.apply_norm_activation_dropout","title":"<code>apply_norm_activation_dropout(feat, normalization=True, activation=True, dropout=True, droppath=True, batch_idx=None, batch_size=None)</code>","text":"<p>Apply the different normalization and the dropout to the output layer.</p> <p>Parameters:</p> Name Type Description Default <code>feat</code> <code>Tensor</code> <p>Feature tensor, to be normalized</p> required <code>normalization</code> <code>bool</code> <p>Whether to apply the normalization</p> <code>True</code> <code>activation</code> <code>bool</code> <p>Whether to apply the activation layer</p> <code>True</code> <code>dropout</code> <code>bool</code> <p>Whether to apply the dropout layer</p> <code>True</code> <code>droppath</code> <code>bool</code> <p>Whether to apply the DropPath layer</p> <code>True</code> <p>Returns:</p> Name Type Description <code>feat</code> <p>Normalized and dropped-out features</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.BaseGraphStructure.layer_supports_edges","title":"<code>layer_supports_edges()</code>","text":"<p>Abstract method. Return a boolean specifying if the layer type supports output edges edges or not.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether the layer supports the use of edges</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_graph_layer.check_intpus_allow_int","title":"<code>check_intpus_allow_int(obj, edge_index, size)</code>","text":"<p>Overwrite the check_input to allow for int32 and int16 TODO: Remove when PyG and pytorch supports int32.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers","title":"<code>goli.nn.base_layers</code>","text":""},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.DropPath","title":"<code>DropPath</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.DropPath.__init__","title":"<code>__init__(drop_rate)</code>","text":"<p>DropPath class for stochastic depth Deep Networks with Stochastic Depth Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra and Kilian Weinberger https://arxiv.org/abs/1603.09382</p> <p>Parameters:</p> Name Type Description Default <code>drop_rate</code> <code>float</code> <p>Drop out probability</p> required"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.DropPath.forward","title":"<code>forward(input, batch_idx, batch_size=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>input</code> <code>Tensor</code> <p><code>torch.Tensor[total_num_nodes, hidden]</code></p> required <code>batch</code> <p>batch attribute of the batch object, batch.batch</p> required <code>batch_size</code> <code>Optional[int]</code> <p>The batch size. Must be provided when working on IPU</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: <code>torch.Tensor[total_num_nodes, hidde]</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.DropPath.get_stochastic_drop_rate","title":"<code>get_stochastic_drop_rate(drop_rate, layer_idx=None, layer_depth=None)</code>  <code>staticmethod</code>","text":"<p>Get the stochastic drop rate from the nominal drop rate, the layer index, and the layer depth.</p> <p><code>return drop_rate * (layer_idx / (layer_depth - 1))</code></p> <p>Parameters:</p> Name Type Description Default <code>drop_rate</code> <code>float</code> <p>Drop out nominal probability</p> required <code>layer_idx</code> <code>Optional[int]</code> <p>The index of the current layer</p> <code>None</code> <code>layer_depth</code> <code>Optional[int]</code> <p>The total depth (number of layers) associated to this specific layer</p> <code>None</code>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.FCLayer","title":"<code>FCLayer</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.FCLayer.in_channels","title":"<code>in_channels: int</code>  <code>property</code>","text":"<p>Get the input channel size. For compatibility with PyG.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.FCLayer.out_channels","title":"<code>out_channels: int</code>  <code>property</code>","text":"<p>Get the output channel size. For compatibility with PyG.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.FCLayer.__init__","title":"<code>__init__(in_dim, out_dim, activation='relu', dropout=0.0, normalization='none', bias=True, init_fn=None, is_readout_layer=False, droppath_rate=0.0)</code>","text":"<p>A simple fully connected and customizable layer. This layer is centered around a <code>torch.nn.Linear</code> module. The order in which transformations are applied is:</p> <ul> <li>Dense Layer</li> <li>Activation</li> <li>Dropout (if applicable)</li> <li>Batch Normalization (if applicable)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input dimension of the layer (the <code>torch.nn.Linear</code>)</p> required <code>out_dim</code> <code>int</code> <p>Output dimension of the layer.</p> required <code>dropout</code> <code>float</code> <p>The ratio of units to dropout. No dropout by default.</p> <code>0.0</code> <code>activation</code> <code>Union[str, Callable]</code> <p>Activation function to use.</p> <code>'relu'</code> <code>normalization</code> <code>Union[str, Callable]</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'none'</code> <code>bias</code> <code>bool</code> <p>Whether to enable bias in for the linear layer.</p> <code>True</code> <code>init_fn</code> <code>Optional[Callable]</code> <p>Initialization function to use for the weight of the layer. Default is \\(\\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\)\\) with \\(\\(k=\\frac{1}{ \\text{in_dim}}\\)\\)</p> <code>None</code> <code>is_readout_layer</code> <code>bool</code> <p>Whether the layer should be treated as a readout layer by replacing of <code>torch.nn.Linear</code> by <code>mup.MuReadout</code> from the muTransfer method https://github.com/microsoft/mup</p> <code>False</code> <code>droppath_rate</code> <code>float</code> <p>stochastic depth drop rate, between 0 and 1, see https://arxiv.org/abs/1603.09382</p> <code>0.0</code> <p>Attributes:</p> Name Type Description <code>dropout</code> <code>int</code> <p>The ratio of units to dropout.</p> <code>normalization</code> <code>None or Callable</code> <p>Normalization layer</p> <code>linear</code> <code>`torch.nn.Linear`</code> <p>The linear layer</p> <code>activation</code> <code>`torch.nn.Module`</code> <p>The activation layer</p> <code>init_fn</code> <code>Callable</code> <p>Initialization function used for the weight of the layer</p> <code>in_dim</code> <code>int</code> <p>Input dimension of the linear layer</p> <code>out_dim</code> <code>int</code> <p>Output dimension of the linear layer</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.FCLayer.forward","title":"<code>forward(h)</code>","text":"<p>Apply the FC layer on the input features.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>torch.Tensor</code> <p><code>torch.Tensor[..., Din]</code>: Input feature tensor, before the FC. <code>Din</code> is the number of input features</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code> <p><code>torch.Tensor[..., Dout]</code>: Output feature tensor, after the FC. <code>Dout</code> is the number of output features</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.FCLayer.reset_parameters","title":"<code>reset_parameters(init_fn=None)</code>","text":"<p>Reset the parameters of the linear layer using the <code>init_fn</code>.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.GRU","title":"<code>GRU</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.GRU.__init__","title":"<code>__init__(in_dim, hidden_dim)</code>","text":"<p>Wrapper class for the GRU used by the GNN framework, nn.GRU is used for the Gated Recurrent Unit itself</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input dimension of the GRU layer</p> required <code>hidden_dim</code> <code>int</code> <p>Hidden dimension of the GRU layer.</p> required"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.GRU.forward","title":"<code>forward(x, y)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>x</code> <p><code>torch.Tensor[B, N, Din]</code> where Din &lt;= in_dim (difference is padded)</p> required <code>y</code> <p><code>torch.Tensor[B, N, Dh]</code> where Dh &lt;= hidden_dim (difference is padded)</p> required <p>Returns:</p> Type Description <p>torch.Tensor: <code>torch.Tensor[B, N, Dh]</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.MLP","title":"<code>MLP</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.MLP.__init__","title":"<code>__init__(in_dim, hidden_dims, out_dim, depth, activation='relu', last_activation='none', dropout=0.0, last_dropout=0.0, normalization='none', last_normalization='none', first_normalization='none', last_layer_is_readout=False, droppath_rate=0.0, constant_droppath_rate=True)</code>","text":"<p>Simple multi-layer perceptron, built of a series of FCLayers</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input dimension of the MLP</p> required <code>hidden_dims</code> <code>Union[Iterable[int], int]</code> <p>Either an integer specifying all the hidden dimensions, or a list of dimensions in the hidden layers.</p> required <code>out_dim</code> <code>int</code> <p>Output dimension of the MLP.</p> required <code>depth</code> <code>int</code> <p>If <code>hidden_dims</code> is an integer, <code>depth</code> is 1 + the number of hidden layers to use. If <code>hidden_dims</code> is a list, then <code>depth</code> must be <code>None</code> or equal to <code>len(hidden_dims) + 1</code></p> required <code>activation</code> <code>Union[str, Callable]</code> <p>Activation function to use in all the layers except the last. if <code>layers==1</code>, this parameter is ignored</p> <code>'relu'</code> <code>last_activation</code> <code>Union[str, Callable]</code> <p>Activation function to use in the last layer.</p> <code>'none'</code> <code>dropout</code> <code>float</code> <p>The ratio of units to dropout. Must be between 0 and 1</p> <code>0.0</code> <code>normalization</code> <code>Union[Type[None], str, Callable]</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization in the hidden layers.</li> <li><code>Callable</code>: Any callable function</li> </ul> <p>if <code>layers==1</code>, this parameter is ignored</p> <code>'none'</code> <code>last_normalization</code> <code>Union[Type[None], str, Callable]</code> <p>Norrmalization to use after the last layer. Same options as <code>normalization</code>.</p> <code>'none'</code> <code>first_normalization</code> <code>Union[Type[None], str, Callable]</code> <p>Norrmalization to use in before the first layer. Same options as <code>normalization</code>.</p> <code>'none'</code> <code>last_dropout</code> <code>float</code> <p>The ratio of units to dropout at the last layer.</p> <code>0.0</code> <code>last_layer_is_readout</code> <code>bool</code> <p>Whether the last layer should be treated as a readout layer. Allows to use the <code>mup.MuReadout</code> from the muTransfer method https://github.com/microsoft/mup</p> <code>False</code> <code>droppath_rate</code> <code>float</code> <p>stochastic depth drop rate, between 0 and 1. See https://arxiv.org/abs/1603.09382</p> <code>0.0</code> <code>constant_droppath_rate</code> <code>bool</code> <p>If <code>True</code>, drop rates will remain constant accross layers. Otherwise, drop rates will vary stochastically. See <code>DropPath.get_stochastic_drop_rate</code></p> <code>True</code>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.MLP.__repr__","title":"<code>__repr__()</code>","text":"<p>Controls how the class is printed</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.MLP.forward","title":"<code>forward(h)</code>","text":"<p>Apply the MLP on the input features.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>torch.Tensor</code> <p><code>torch.Tensor[..., Din]</code>: Input feature tensor, before the MLP. <code>Din</code> is the number of input features</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code> <p><code>torch.Tensor[..., Dout]</code>: Output feature tensor, after the MLP. <code>Dout</code> is the number of output features</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.MuReadoutGoli","title":"<code>MuReadoutGoli</code>","text":"<p>         Bases: <code>MuReadout</code></p> <p>PopTorch-compatible replacement for <code>mup.MuReadout</code></p> <p>Not quite a drop-in replacement for <code>mup.MuReadout</code> - you need to specify <code>base_width</code>.</p> <p>Set <code>base_width</code> to width of base model passed to <code>mup.set_base_shapes</code> to get same results on IPU and CPU. Should still \"work\" with any other value, but won't give the same results as CPU</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.MultiheadAttentionMup","title":"<code>MultiheadAttentionMup</code>","text":"<p>         Bases: <code>nn.MultiheadAttention</code></p> <p>Modifying the MultiheadAttention to work with the muTransfer paradigm. The layers are initialized using the mup package. The <code>_scaled_dot_product_attention</code> normalizes the attention matrix with <code>1/d</code> instead of <code>1/sqrt(d)</code> The biased self-attention option is added to have 3D attention bias.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.TransformerEncoderLayerMup","title":"<code>TransformerEncoderLayerMup</code>","text":"<p>         Bases: <code>nn.TransformerEncoderLayer</code></p> <p>Modified version of <code>torch.nn.TransformerEncoderLayer</code> that uses :math:<code>1/n</code>-scaled attention for compatibility with muP (as opposed to the original :math:<code>1/\\sqrt{n}</code> scaling factor) Arguments are the same as <code>torch.nn.TransformerEncoderLayer</code>.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.get_activation","title":"<code>get_activation(activation)</code>","text":"<p>returns the activation function represented by the input string</p> <p>Parameters:</p> Name Type Description Default <code>activation</code> <code>Union[type(None), str, Callable]</code> <p>Callable, <code>None</code>, or string with value: \"none\", \"ReLU\", \"Sigmoid\", \"Tanh\", \"ELU\", \"SELU\", \"GLU\", \"GELU\", \"LeakyReLU\", \"Softplus\"</p> required <p>Returns:</p> Type Description <code>Optional[Callable]</code> <p>Callable or None: The activation function</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.get_activation_str","title":"<code>get_activation_str(activation)</code>","text":"<p>returns the string related to the activation function</p> <p>Parameters:</p> Name Type Description Default <code>activation</code> <code>Union[type(None), str, Callable]</code> <p>Callable, <code>None</code>, or string with value: \"none\", \"ReLU\", \"Sigmoid\", \"Tanh\", \"ELU\", \"SELU\", \"GLU\", \"LeakyReLU\", \"Softplus\"</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the activation function</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.base_layers.get_norm","title":"<code>get_norm(normalization, dim=None)</code>","text":"<p>returns the normalization function represented by the input string</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>Union[Type[None], str, Callable]</code> <p>Callable, <code>None</code>, or string with value: \"none\", \"batch_norm\", \"layer_norm\"</p> required <code>dim</code> <code>Optional[int]</code> <p>Dimension where to apply the norm. Mandatory for 'batch_norm' and 'layer_norm'</p> <code>None</code> <p>Returns:</p> Type Description <p>Callable or None: The normalization function</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections","title":"<code>goli.nn.residual_connections</code>","text":"<p>Different types of residual connections, including None, Simple (ResNet-like), Concat and DenseNet</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionBase","title":"<code>ResidualConnectionBase</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionBase.__init__","title":"<code>__init__(skip_steps=1)</code>","text":"<p>Abstract class for the residual connections. Using this class, we implement different types of residual connections, such as the ResNet, weighted-ResNet, skip-concat and DensNet.</p> <p>The following methods must be implemented in a children class</p> <ul> <li><code>h_dim_increase_type()</code></li> <li><code>has_weights()</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>skip_steps</code> <code>int</code> <p>int The number of steps to skip between the residual connections. If <code>1</code>, all the layers are connected. If <code>2</code>, half of the layers are connected.</p> <code>1</code>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionBase.__repr__","title":"<code>__repr__()</code>","text":"<p>Controls how the class is printed</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionBase.get_true_out_dims","title":"<code>get_true_out_dims(out_dims)</code>","text":"<p>find the true output dimensions</p> <p>Parameters:</p> Name Type Description Default <code>out_dims</code> <code>List</code> <p>List</p> required <p>Returns:</p> Name Type Description <code>true_out_dims</code> <code>List</code> <p>List</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionBase.h_dim_increase_type","title":"<code>h_dim_increase_type()</code>  <code>abstractmethod</code>","text":"<p>How does the dimension of the output features increases after each layer?</p> <p>Returns:</p> Name Type Description <code>h_dim_increase_type</code> <p>None or str - <code>None</code>: The dimension of the output features do not change at each layer. E.g. ResNet.</p> <ul> <li> <p>\"previous\": The dimension of the output features is the concatenation of the previous layer with the new layer.</p> </li> <li> <p>\"cumulative\": The dimension of the output features is the concatenation of all previous layers.</p> </li> </ul>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionBase.has_weights","title":"<code>has_weights()</code>  <code>abstractmethod</code>","text":"<p>Returns:</p> Name Type Description <code>has_weights</code> <p>bool Whether the residual connection uses weights</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionConcat","title":"<code>ResidualConnectionConcat</code>","text":"<p>         Bases: <code>ResidualConnectionBase</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionConcat.__init__","title":"<code>__init__(skip_steps=1)</code>","text":"<p>Class for the simple residual connections proposed but where the skip connection features are concatenated to the current layer features.</p> <p>Parameters:</p> Name Type Description Default <code>skip_steps</code> <code>int</code> <p>int The number of steps to skip between the residual connections. If <code>1</code>, all the layers are connected. If <code>2</code>, half of the layers are connected.</p> <code>1</code>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionConcat.forward","title":"<code>forward(h, h_prev, step_idx)</code>","text":"<p>Concatenate <code>h</code> with the previous layers with skip connection <code>h_prev</code>.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>torch.Tensor</code> <p>torch.Tensor(..., m) The current layer features</p> required <code>h_prev</code> <code>torch.Tensor</code> <p>torch.Tensor(..., n), None The features from the previous layer with a skip connection. Usually, we have <code>n</code> equal to <code>m</code>. At <code>step_idx==0</code>, <code>h_prev</code> can be set to <code>None</code>.</p> required <code>step_idx</code> <code>int</code> <p>int Current layer index or step index in the forward loop of the architecture.</p> required <p>Returns:</p> Name Type Description <code>h</code> <p>torch.Tensor(..., m) or torch.Tensor(..., m + n) Either return <code>h</code> unchanged, or the concatenation with <code>h_prev</code>, depending on the <code>step_idx</code> and <code>self.skip_steps</code>.</p> <code>h_prev</code> <p>torch.Tensor(..., m) or torch.Tensor(..., m + n) Either return <code>h_prev</code> unchanged, or the same value as <code>h</code>, depending on the <code>step_idx</code> and <code>self.skip_steps</code>.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionConcat.h_dim_increase_type","title":"<code>h_dim_increase_type()</code>","text":"<p>Returns:</p> Type Description <p>\"previous\": The dimension of the output layer is the concatenation with the previous layer.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionConcat.has_weights","title":"<code>has_weights()</code>","text":"<p>Returns:</p> Type Description <p>False The current class does not use weights</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionDenseNet","title":"<code>ResidualConnectionDenseNet</code>","text":"<p>         Bases: <code>ResidualConnectionBase</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionDenseNet.__init__","title":"<code>__init__(skip_steps=1)</code>","text":"<p>Class for the residual connections proposed by DenseNet, where all previous skip connection features are concatenated to the current layer features.</p> <p>Parameters:</p> Name Type Description Default <code>skip_steps</code> <code>int</code> <p>int The number of steps to skip between the residual connections. If <code>1</code>, all the layers are connected. If <code>2</code>, half of the layers are connected.</p> <code>1</code>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionDenseNet.forward","title":"<code>forward(h, h_prev, step_idx)</code>","text":"<p>Concatenate <code>h</code> with all the previous layers with skip connection <code>h_prev</code>.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>torch.Tensor</code> <p>torch.Tensor(..., m) The current layer features</p> required <code>h_prev</code> <code>torch.Tensor</code> <p>torch.Tensor(..., n), None The features from the previous layers. n = ((step_idx // self.skip_steps) + 1) * m</p> <p>At <code>step_idx==0</code>, <code>h_prev</code> can be set to <code>None</code>.</p> required <code>step_idx</code> <code>int</code> <p>int Current layer index or step index in the forward loop of the architecture.</p> required <p>Returns:</p> Name Type Description <code>h</code> <p>torch.Tensor(..., m) or torch.Tensor(..., m + n) Either return <code>h</code> unchanged, or the concatenation with <code>h_prev</code>, depending on the <code>step_idx</code> and <code>self.skip_steps</code>.</p> <code>h_prev</code> <p>torch.Tensor(..., m) or torch.Tensor(..., m + n) Either return <code>h_prev</code> unchanged, or the same value as <code>h</code>, depending on the <code>step_idx</code> and <code>self.skip_steps</code>.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionDenseNet.h_dim_increase_type","title":"<code>h_dim_increase_type()</code>","text":"<p>Returns:</p> Type Description <p>\"cumulative\": The dimension of the output layer is the concatenation of all the previous layer.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionDenseNet.has_weights","title":"<code>has_weights()</code>","text":"<p>Returns:</p> Type Description <p>False The current class does not use weights</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionNone","title":"<code>ResidualConnectionNone</code>","text":"<p>         Bases: <code>ResidualConnectionBase</code></p> <p>No residual connection. This class is only used for simpler code compatibility</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionNone.__repr__","title":"<code>__repr__()</code>","text":"<p>Controls how the class is printed</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionNone.forward","title":"<code>forward(h, h_prev, step_idx)</code>","text":"<p>Ignore the skip connection.</p> <p>Returns:</p> Name Type Description <code>h</code> <p>torch.Tensor(..., m) Return same as input.</p> <code>h_prev</code> <p>torch.Tensor(..., m) Return same as input.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionNone.h_dim_increase_type","title":"<code>h_dim_increase_type()</code>","text":"<p>Returns:</p> Name Type Description <code>None</code> <p>The dimension of the output features do not change at each layer.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionNone.has_weights","title":"<code>has_weights()</code>","text":"<p>Returns:</p> Type Description <p>False The current class does not use weights</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionRandom","title":"<code>ResidualConnectionRandom</code>","text":"<p>         Bases: <code>ResidualConnectionBase</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionRandom.__init__","title":"<code>__init__(skip_steps=1, out_dims=None, num_layers=None)</code>","text":"<p>Class for the random residual connection, where each layer is connected to each following layer with a random weight between 0 and 1.</p> <p>Parameters:</p> Name Type Description Default <code>skip_steps</code> <p>Parameter only there for compatibility with other classes of the same parent.</p> <code>1</code> <code>out_dims</code> <code>List[int]</code> <p>The list of output dimensions. Only required to get the number of layers. Must be provided if <code>num_layers</code> is None.</p> <code>None</code> <code>num_layers</code> <code>int</code> <p>The number of layers. Must be provided if <code>out_dims</code> is None.</p> <code>None</code>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionRandom.forward","title":"<code>forward(h, h_prev, step_idx)</code>","text":"<p>Add <code>h</code> with the previous layers with skip connection <code>h_prev</code>, similar to ResNet.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>torch.Tensor</code> <p>torch.Tensor(..., m) The current layer features</p> required <code>h_prev</code> <code>torch.Tensor</code> <p>torch.Tensor(..., m), None The features from the previous layer with a skip connection. At <code>step_idx==0</code>, <code>h_prev</code> can be set to <code>None</code>.</p> required <code>step_idx</code> <code>int</code> <p>int Current layer index or step index in the forward loop of the architecture.</p> required <p>Returns:</p> Name Type Description <code>h</code> <p>torch.Tensor(..., m) Either return <code>h</code> unchanged, or the sum with on <code>h_prev</code>, depending on the <code>step_idx</code> and <code>self.skip_steps</code>.</p> <code>h_prev</code> <p>torch.Tensor(..., m) Either return <code>h_prev</code> unchanged, or the same value as <code>h</code>, depending on the <code>step_idx</code> and <code>self.skip_steps</code>.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionRandom.h_dim_increase_type","title":"<code>h_dim_increase_type()</code>","text":"<p>Returns:</p> Name Type Description <code>None</code> <p>The dimension of the output features do not change at each layer.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionRandom.has_weights","title":"<code>has_weights()</code>","text":"<p>Returns:</p> Type Description <p>False The current class does not use weights</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionSimple","title":"<code>ResidualConnectionSimple</code>","text":"<p>         Bases: <code>ResidualConnectionBase</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionSimple.__init__","title":"<code>__init__(skip_steps=1)</code>","text":"<p>Class for the simple residual connections proposed by ResNet, where the current layer output is summed to a previous layer output.</p> <p>Parameters:</p> Name Type Description Default <code>skip_steps</code> <code>int</code> <p>int The number of steps to skip between the residual connections. If <code>1</code>, all the layers are connected. If <code>2</code>, half of the layers are connected.</p> <code>1</code>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionSimple.forward","title":"<code>forward(h, h_prev, step_idx)</code>","text":"<p>Add <code>h</code> with the previous layers with skip connection <code>h_prev</code>, similar to ResNet.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>torch.Tensor</code> <p>torch.Tensor(..., m) The current layer features</p> required <code>h_prev</code> <code>torch.Tensor</code> <p>torch.Tensor(..., m), None The features from the previous layer with a skip connection. At <code>step_idx==0</code>, <code>h_prev</code> can be set to <code>None</code>.</p> required <code>step_idx</code> <code>int</code> <p>int Current layer index or step index in the forward loop of the architecture.</p> required <p>Returns:</p> Name Type Description <code>h</code> <p>torch.Tensor(..., m) Either return <code>h</code> unchanged, or the sum with on <code>h_prev</code>, depending on the <code>step_idx</code> and <code>self.skip_steps</code>.</p> <code>h_prev</code> <p>torch.Tensor(..., m) Either return <code>h_prev</code> unchanged, or the same value as <code>h</code>, depending on the <code>step_idx</code> and <code>self.skip_steps</code>.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionSimple.h_dim_increase_type","title":"<code>h_dim_increase_type()</code>","text":"<p>Returns:</p> Name Type Description <code>None</code> <p>The dimension of the output features do not change at each layer.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionSimple.has_weights","title":"<code>has_weights()</code>","text":"<p>Returns:</p> Type Description <p>False The current class does not use weights</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionWeighted","title":"<code>ResidualConnectionWeighted</code>","text":"<p>         Bases: <code>ResidualConnectionBase</code></p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionWeighted.__init__","title":"<code>__init__(out_dims, skip_steps=1, dropout=0.0, activation='none', normalization='none', bias=False)</code>","text":"<p>Class for the simple residual connections proposed by ResNet, with an added layer in the residual connection itself. The layer output is summed to a a non-linear transformation of a previous layer output.</p> <p>Parameters:</p> Name Type Description Default <code>skip_steps</code> <code>int</code> <p>int The number of steps to skip between the residual connections. If <code>1</code>, all the layers are connected. If <code>2</code>, half of the layers are connected.</p> <code>1</code> <code>out_dims</code> <p>list(int) list of all output dimensions for the network that will use this residual connection. E.g. <code>out_dims = [4, 8, 8, 8, 2]</code>.</p> required <code>dropout</code> <p>float value between 0 and 1.0 representing the percentage of dropout to use in the weights</p> <code>0.0</code> <code>activation</code> <code>Union[str, Callable]</code> <p>str, Callable The activation function to use after the skip weights</p> <code>'none'</code> <code>normalization</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization in the hidden layers.</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'none'</code> <code>bias</code> <p>bool Whether to apply add a bias after the weights</p> <code>False</code>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionWeighted.forward","title":"<code>forward(h, h_prev, step_idx)</code>","text":"<p>Add <code>h</code> with the previous layers with skip connection <code>h_prev</code>, after a feed-forward layer.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>torch.Tensor</code> <p>torch.Tensor(..., m) The current layer features</p> required <code>h_prev</code> <code>torch.Tensor</code> <p>torch.Tensor(..., m), None The features from the previous layer with a skip connection. At <code>step_idx==0</code>, <code>h_prev</code> can be set to <code>None</code>.</p> required <code>step_idx</code> <code>int</code> <p>int Current layer index or step index in the forward loop of the architecture.</p> required <p>Returns:</p> Name Type Description <code>h</code> <p>torch.Tensor(..., m) Either return <code>h</code> unchanged, or the sum with the output of a NN layer on <code>h_prev</code>, depending on the <code>step_idx</code> and <code>self.skip_steps</code>.</p> <code>h_prev</code> <p>torch.Tensor(..., m) Either return <code>h_prev</code> unchanged, or the same value as <code>h</code>, depending on the <code>step_idx</code> and <code>self.skip_steps</code>.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionWeighted.h_dim_increase_type","title":"<code>h_dim_increase_type()</code>","text":"<p>Returns:</p> Name Type Description <code>None</code> <p>The dimension of the output features do not change at each layer.</p>"},{"location":"api/goli.nn/goli.nn.html#goli.nn.residual_connections.ResidualConnectionWeighted.has_weights","title":"<code>has_weights()</code>","text":"<p>Returns:</p> Type Description <p>True The current class uses weights</p>"},{"location":"api/goli.nn/pyg_layers.html","title":"goli.nn.pyg_layers","text":""},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gated_gcn_pyg","title":"<code>goli.nn.pyg_layers.gated_gcn_pyg</code>","text":"<p>Unit tests for the different layers of goli/nn/pyg_layers/...</p> <p>The layers are not thoroughly tested due to the difficulty of testing them</p> <p>adapated from https://github.com/rampasek/GraphGPS/blob/main/graphgps/layer/gps_layer.py</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gated_gcn_pyg.GatedGCNPyg","title":"<code>GatedGCNPyg</code>","text":"<p>         Bases: <code>MessagePassing</code>, <code>BaseGraphStructure</code></p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gated_gcn_pyg.GatedGCNPyg.layer_inputs_edges","title":"<code>layer_inputs_edges: bool</code>  <code>property</code>","text":"<p>Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>True</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gated_gcn_pyg.GatedGCNPyg.layer_outputs_edges","title":"<code>layer_outputs_edges: bool</code>  <code>property</code>","text":"<p>Abstract method. Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>True</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gated_gcn_pyg.GatedGCNPyg.out_dim_factor","title":"<code>out_dim_factor: int</code>  <code>property</code>","text":"<p>Get the factor by which the output dimension is multiplied for the next layer.</p> <p>For standard layers, this will return <code>1</code>.</p> <p>But for others, such as <code>GatLayer</code>, the output is the concatenation of the outputs from each head, so the out_dim gets multiplied by the number of heads, and this function should return the number of heads.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Always <code>1</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gated_gcn_pyg.GatedGCNPyg.__init__","title":"<code>__init__(in_dim, out_dim, in_dim_edges, out_dim_edges=None, activation='relu', dropout=0.0, normalization='none', **kwargs)</code>","text":"<p>ResGatedGCN: Residual Gated Graph ConvNets An Experimental Study of Neural Networks for Variable Graphs (Xavier Bresson and Thomas Laurent, ICLR 2018) https://arxiv.org/pdf/1711.07553v2.pdf</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input feature dimensions of the layer</p> required <code>out_dim</code> <code>int</code> <p>Output feature dimensions of the layer, and for the edges</p> required <code>in_dim_edges</code> <code>int</code> <p>Input edge-feature dimensions of the layer</p> required <code>activation</code> <code>Union[Callable, str]</code> <p>activation function to use in the layer</p> <code>'relu'</code> <code>dropout</code> <code>float</code> <p>The ratio of units to dropout. Must be between 0 and 1</p> <code>0.0</code> <code>normalization</code> <code>Union[str, Callable]</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'none'</code>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gated_gcn_pyg.GatedGCNPyg.aggregate","title":"<code>aggregate(sigma_ij, index, Bx_j, Bx)</code>","text":"<p>aggregation function of the layer</p> <p>Parameters:</p> Name Type Description Default <code>sigma_ij</code> <code>torch.Tensor</code> <p>the output from message() function with dim [n_edges, out_dim]</p> required <code>index</code> <code>torch.Tensor</code> <p>dim [n_edges]</p> required <code>Bx_j</code> <code>torch.Tensor</code> <p>dim [n_edges, out_dim]</p> required <code>Bx</code> <code>torch.Tensor</code> <p>dim [n_nodes, out_dim]</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>torch.Tensor</code> <p>dim [n_nodes, out_dim]</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gated_gcn_pyg.GatedGCNPyg.forward","title":"<code>forward(batch)</code>","text":"<p>Forward pass the Gated GCN layer extract the following from the batch: x, node features with dim [n_nodes, in_dim] e, edge features with dim [n_edges, in_dim] edge_index with dim [2, n_edges]</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Union[Data, Batch]</code> <p>pyg Batch graph to pass through the layer</p> required <p>Returns:</p> Name Type Description <code>batch</code> <code>Union[Data, Batch]</code> <p>pyg Batch graph</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gated_gcn_pyg.GatedGCNPyg.layer_supports_edges","title":"<code>layer_supports_edges()</code>","text":"<p>Return a boolean specifying if the layer type supports edges or not.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>True</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gated_gcn_pyg.GatedGCNPyg.message","title":"<code>message(Dx_i, Ex_j, Ce)</code>","text":"<p>message function</p> <p>Parameters:</p> Name Type Description Default <code>Dx_i</code> <code>torch.Tensor</code> <p>tensor with dimension [n_edges, out_dim]</p> required <code>Ex_j</code> <code>torch.Tensor</code> <p>tensor with dimension [n_edges, out_dim]</p> required <code>Ce</code> <code>torch.Tensor</code> <p>tensor with dimension [n_edges, out_dim]</p> required <p>Returns:</p> Name Type Description <code>sigma_ij</code> <code>torch.Tensor</code> <p>tensor with dimension [n_edges, out_dim]</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gated_gcn_pyg.GatedGCNPyg.update","title":"<code>update(aggr_out, Ax)</code>","text":"<p>update function of the layer</p> <p>Parameters:</p> Name Type Description Default <code>aggr_out</code> <code>torch.Tensor</code> <p>the output from aggregate() function with dim [n_nodes, out_dim]</p> required <code>Ax</code> <code>torch.Tensor</code> <p>tensor with dim [n_nodes, out_dim]</p> required <p>Returns:</p> Name Type Description <code>x</code> <p>dim [n_nodes, out_dim]</p> <code>e_out</code> <p>dim [n_edges, out_dim_edges]</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg","title":"<code>goli.nn.pyg_layers.gin_pyg</code>","text":""},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINConvPyg","title":"<code>GINConvPyg</code>","text":"<p>         Bases: <code>BaseGraphModule</code></p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINConvPyg.layer_inputs_edges","title":"<code>layer_inputs_edges: bool</code>  <code>property</code>","text":"<p>Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>False</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINConvPyg.layer_outputs_edges","title":"<code>layer_outputs_edges: bool</code>  <code>property</code>","text":"<p>Abstract method. Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>False</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINConvPyg.out_dim_factor","title":"<code>out_dim_factor: int</code>  <code>property</code>","text":"<p>Get the factor by which the output dimension is multiplied for the next layer.</p> <p>For standard layers, this will return <code>1</code>.</p> <p>But for others, such as <code>GatLayer</code>, the output is the concatenation of the outputs from each head, so the out_dim gets multiplied by the number of heads, and this function should return the number of heads.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Always <code>1</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINConvPyg.__init__","title":"<code>__init__(in_dim, out_dim, activation='relu', dropout=0.0, normalization='none', **kwargs)</code>","text":"<p>GIN: Graph Isomorphism Networks HOW POWERFUL ARE GRAPH NEURAL NETWORKS? (Keyulu Xu, Weihua Hu, Jure Leskovec and Stefanie Jegelka, ICLR 2019) https://arxiv.org/pdf/1810.00826.pdf</p> <p>[!] code uses the pytorch-geometric implementation of GINConv</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input feature dimensions of the layer</p> required <code>out_dim</code> <code>int</code> <p>Output feature dimensions of the layer</p> required <code>activation</code> <code>Union[Callable, str]</code> <p>activation function to use in the layer</p> <code>'relu'</code> <code>dropout</code> <code>float</code> <p>The ratio of units to dropout. Must be between 0 and 1</p> <code>0.0</code> <code>normalization</code> <code>Union[str, Callable]</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'none'</code> <code>init_eps</code> <p>Initial :math:<code>\\epsilon</code> value, default: <code>0</code>.</p> required <code>learn_eps</code> <p>If True, :math:<code>\\epsilon</code> will be a learnable parameter.</p> required"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINConvPyg.forward","title":"<code>forward(batch)</code>","text":"<p>forward function of the layer</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Union[Data, Batch]</code> <p>pyg Batch graphs to pass through the layer</p> required <p>Returns:</p> Name Type Description <code>batch</code> <code>Union[Data, Batch]</code> <p>pyg Batch graphs</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINConvPyg.layer_supports_edges","title":"<code>layer_supports_edges()</code>","text":"<p>Return a boolean specifying if the layer type supports edges or not.</p> <p>Returns:</p> Name Type Description <code>supports_edges</code> <code>bool</code> <p>bool Always <code>False</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINEConvPyg","title":"<code>GINEConvPyg</code>","text":"<p>         Bases: <code>BaseGraphModule</code></p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINEConvPyg.layer_inputs_edges","title":"<code>layer_inputs_edges: bool</code>  <code>property</code>","text":"<p>Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>True</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINEConvPyg.layer_outputs_edges","title":"<code>layer_outputs_edges: bool</code>  <code>property</code>","text":"<p>Abstract method. Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>False</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINEConvPyg.out_dim_factor","title":"<code>out_dim_factor: int</code>  <code>property</code>","text":"<p>Get the factor by which the output dimension is multiplied for the next layer.</p> <p>For standard layers, this will return <code>1</code>.</p> <p>But for others, such as <code>GatLayer</code>, the output is the concatenation of the outputs from each head, so the out_dim gets multiplied by the number of heads, and this function should return the number of heads.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Always <code>1</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINEConvPyg.__init__","title":"<code>__init__(in_dim, out_dim, in_dim_edges=None, activation='relu', dropout=0.0, normalization='none', **kwargs)</code>","text":"<p>GINE: Graph Isomorphism Networks with Edges Strategies for Pre-training Graph Neural Networks Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, Jure Leskovec https://arxiv.org/abs/1905.12265</p> <p>[!] code uses the pytorch-geometric implementation of GINEConv</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input feature dimensions of the layer</p> required <code>out_dim</code> <code>int</code> <p>Output feature dimensions of the layer</p> required <code>activation</code> <code>Union[Callable, str]</code> <p>activation function to use in the layer</p> <code>'relu'</code> <code>dropout</code> <code>float</code> <p>The ratio of units to dropout. Must be between 0 and 1</p> <code>0.0</code> <code>normalization</code> <code>Union[str, Callable]</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'none'</code> <code>init_eps</code> <p>Initial :math:<code>\\epsilon</code> value, default: <code>0</code>.</p> required <code>learn_eps</code> <p>If True, :math:<code>\\epsilon</code> will be a learnable parameter.</p> required"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINEConvPyg.forward","title":"<code>forward(batch)</code>","text":"<p>forward function of the layer</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Union[Data, Batch]</code> <p>pyg Batch graphs to pass through the layer</p> required <p>Returns:</p> Name Type Description <code>batch</code> <code>Union[Data, Batch]</code> <p>pyg Batch graphs</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gin_pyg.GINEConvPyg.layer_supports_edges","title":"<code>layer_supports_edges()</code>","text":"<p>Return a boolean specifying if the layer type supports edges or not.</p> <p>Returns:</p> Name Type Description <code>supports_edges</code> <code>bool</code> <p>bool Always <code>True</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gps_pyg","title":"<code>goli.nn.pyg_layers.gps_pyg</code>","text":""},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gps_pyg.GPSLayerPyg","title":"<code>GPSLayerPyg</code>","text":"<p>         Bases: <code>BaseGraphModule</code></p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gps_pyg.GPSLayerPyg.layer_inputs_edges","title":"<code>layer_inputs_edges: bool</code>  <code>property</code>","text":"<p>Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>True</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gps_pyg.GPSLayerPyg.layer_outputs_edges","title":"<code>layer_outputs_edges: bool</code>  <code>property</code>","text":"<p>Abstract method. Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>False</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gps_pyg.GPSLayerPyg.out_dim_factor","title":"<code>out_dim_factor: int</code>  <code>property</code>","text":"<p>Get the factor by which the output dimension is multiplied for the next layer.</p> <p>For standard layers, this will return <code>1</code>.</p> <p>But for others, such as <code>GatLayer</code>, the output is the concatenation of the outputs from each head, so the out_dim gets multiplied by the number of heads, and this function should return the number of heads.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Always <code>1</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gps_pyg.GPSLayerPyg.__init__","title":"<code>__init__(in_dim, out_dim, in_dim_edges=None, out_dim_edges=None, activation='relu', dropout=0.0, node_residual=True, normalization='none', mpnn_type='pyg:gine', mpnn_kwargs=None, attn_type='full-attention', biased_attention_key=None, attn_kwargs=None, droppath_rate_attn=0.0, droppath_rate_ffn=0.0, hidden_dim_scaling=4.0, **kwargs)</code>","text":"<p>GPS layer implementation in pyg adapated from https://github.com/rampasek/GraphGPS/blob/main/graphgps/layer/gps_layer.py GPS: Recipe for a General, Powerful, Scalable Graph Transformer Ladislav Ramp\u00e1\u0161ek, Mikhail Galkin, Vijay Prakash Dwivedi, Anh Tuan Luu, Guy Wolf, Dominique Beaini https://arxiv.org/abs/2205.12454</p> <p>GPS++: An Optimised Hybrid MPNN/Transformer for Molecular Property Prediction Dominic Masters, Josef Dean, Kerstin Klaser, Zhiyi Li, Sam Maddrell-Mander, Adam Sanders, Hatem Helal, Deniz Beker, Ladislav Ramp\u00e1\u0161ek, Dominique Beaini https://arxiv.org/abs/2212.02229</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input node feature dimensions of the layer</p> required <code>out_dim</code> <code>int</code> <p>Output node feature dimensions of the layer</p> required <code>in_dim</code> <code>int</code> <p>Input edge feature dimensions of the layer</p> required <code>out_dim</code> <code>int</code> <p>Output edge feature dimensions of the layer</p> required <code>in_dim_edges</code> <code>Optional[int]</code> <p>input edge-feature dimensions of the layer</p> <code>None</code> <code>out_dim_edges</code> <code>Optional[int]</code> <p>output edge-feature dimensions of the layer</p> <code>None</code> <code>activation</code> <code>Union[Callable, str]</code> <p>activation function to use in the layer</p> <code>'relu'</code> <code>dropout</code> <code>float</code> <p>The ratio of units to dropout. Must be between 0 and 1</p> <code>0.0</code> <code>node_residual</code> <code>Optional[bool]</code> <p>If node residual is used after on the gnn layer output</p> <code>True</code> <code>normalization</code> <code>Union[str, Callable]</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'none'</code> <code>mpnn_type</code> <code>str</code> <p>type of mpnn used, choose from \"pyg:gin\", \"pyg:gine\", \"pyg:gated-gcn\", \"pyg:pna-msgpass\" and \"pyg:mpnnplus\"</p> <code>'pyg:gine'</code> <code>mpnn_kwargs</code> <p>kwargs for mpnn layer</p> <code>None</code> <code>attn_type</code> <code>str</code> <p>type of attention used, choose from \"full-attention\" and \"none\"</p> <code>'full-attention'</code> <code>attn_kwargs</code> <p>kwargs for attention layer</p> <code>None</code> <code>droppath_rate_attn</code> <code>float</code> <p>stochastic depth drop rate for attention layer https://arxiv.org/abs/1603.09382</p> <code>0.0</code> <code>droppath_rate_ffn</code> <code>float</code> <p>stochastic depth drop rate for ffn layer https://arxiv.org/abs/1603.09382</p> <code>0.0</code> <code>mpnn_type</code> <code>str</code> <p>Type of MPNN layer to use. Choices specified in PYG_LAYERS_DICT</p> <code>'pyg:gine'</code> <code>mpnn_kwargs</code> <p>Keyword arguments to pass to the MPNN layer</p> <code>None</code> <code>attn_type</code> <code>str</code> <p>Type of attention layer to use. Choices specified in ATTENTION_LAYERS_DICT</p> <code>'full-attention'</code> <code>biased_attention_key</code> <code>Optional[str]</code> <p>indicates if biased attention is used by specifying a key corresponding to the pyg attribute in the batch (processed by the gaussian kernel encoder) default: None means biased attention is not used</p> <code>None</code> <code>attn_kwargs</code> <p>Keyword arguments to pass to the attention layer</p> <code>None</code>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gps_pyg.GPSLayerPyg.forward","title":"<code>forward(batch)</code>","text":"<p>forward function of the layer</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Batch</code> <p>pyg Batch graphs to pass through the layer</p> required <p>Returns:</p> Name Type Description <code>batch</code> <code>Batch</code> <p>pyg Batch graphs</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.gps_pyg.GPSLayerPyg.layer_supports_edges","title":"<code>layer_supports_edges()</code>","text":"<p>Return a boolean specifying if the layer type supports edges or not.</p> <p>Returns:</p> Name Type Description <code>supports_edges</code> <code>bool</code> <p>bool Always <code>True</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.mpnn_pyg","title":"<code>goli.nn.pyg_layers.mpnn_pyg</code>","text":""},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.mpnn_pyg.MPNNPlusPyg","title":"<code>MPNNPlusPyg</code>","text":"<p>         Bases: <code>BaseGraphModule</code></p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.mpnn_pyg.MPNNPlusPyg.layer_inputs_edges","title":"<code>layer_inputs_edges: bool</code>  <code>property</code>","text":"<p>Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>True</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.mpnn_pyg.MPNNPlusPyg.layer_outputs_edges","title":"<code>layer_outputs_edges: bool</code>  <code>property</code>","text":"<p>Abstract method. Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>True</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.mpnn_pyg.MPNNPlusPyg.out_dim_factor","title":"<code>out_dim_factor: int</code>  <code>property</code>","text":"<p>Get the factor by which the output dimension is multiplied for the next layer.</p> <p>For standard layers, this will return <code>1</code>.</p> <p>But for others, such as <code>GatLayer</code>, the output is the concatenation of the outputs from each head, so the out_dim gets multiplied by the number of heads, and this function should return the number of heads.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Always <code>1</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.mpnn_pyg.MPNNPlusPyg.__init__","title":"<code>__init__(in_dim=64, out_dim=64, activation='gelu', dropout=0.3, normalization='layer_norm', gather_from='both', scatter_to='both', node_combine_method='concat', num_node_mlp=2, mlp_expansion_ratio=4, use_edges=True, in_dim_edges=32, out_dim_edges=32, aggregation_method=['sum'], num_edge_mlp=2, use_globals=True, edge_dropout_rate=0.0035, **kwargs)</code>","text":"<pre><code>MPNNPlusPyg: InteractionNetwork layer witg edges and global feature, GPS++ type of GNN layer\nGPS++: An Optimised Hybrid MPNN/Transformer for Molecular Property Prediction\nDominic Masters, Josef Dean, Kerstin Klaser, Zhiyi Li, Sam Maddrell-Mander, Adam Sanders,\nHatem Helal, Deniz Beker, Ladislav Ramp\u00e1\u0161ek, Dominique Beaini\nhttps://arxiv.org/abs/2212.02229\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input feature dimensions of the nodes</p> <code>64</code> <code>out_dim</code> <code>int</code> <p>Output feature dimensions of the nodes</p> <code>64</code> <code>activation</code> <code>Union[str, Callable]</code> <p>Activation function to use in the edge and node model</p> <code>'gelu'</code> <code>dropout</code> <code>float</code> <p>The ratio of units to dropout at the end within apply_norm_activation_dropout.</p> <code>0.3</code> <code>normalization</code> <code>Union[str, Callable]</code> <p>Normalization to use with the edge, node models and at the end within apply_norm_activation_dropout. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'layer_norm'</code> <code>gather_from</code> <code>str</code> <p>The method to gather features from. Could choose from: \"senders\", \"receivers\" and \"both\".</p> <code>'both'</code> <code>scatter_to</code> <code>str</code> <p>The method to scatter features to. Could choose from: \"senders\", \"receivers\" and \"both\".</p> <code>'both'</code> <code>node_combine_method</code> <code>str</code> <p>The method to combine the node features, Could choose from: \"sum\" and \"concat\".</p> <code>'concat'</code> <code>aggregation_method</code> <code>Optional[List[Union[str, Aggregation]]]</code> <p>Methods for aggregating (scatter) messages built from node and edge features. Provide a list of <code>Aggregation</code> or strings. supported strings are:</p> <ul> <li>\"sum\" / \"add\" (Default)</li> <li>\"mean\"</li> <li>\"max\"</li> <li>\"min\"</li> <li>\"softmax\"</li> <li>\"median\"</li> <li>\"std\"</li> <li>\"var\"</li> </ul> <code>['sum']</code> <code>num_node_mlp</code> <code>int</code> <p>Number of mlp layer used for node model</p> <code>2</code> <code>mlp_expansion_ratio</code> <code>int</code> <p>Expansion ratio for node and edge mlp</p> <code>4</code> <code>use_edges</code> <code>bool</code> <p>If edge features are used</p> <code>True</code> <code>in_dim_edges</code> <code>Optional[int]</code> <p>Input feature dimensions of the edges</p> <code>32</code> <code>out_dim_edges</code> <code>Optional[int]</code> <p>Output feature dimensions of the edges</p> <code>32</code> <code>num_edge_mlp</code> <code>Optional[int]</code> <p>Number of mlp layer used for edge model</p> <code>2</code> <code>edge_dropout_rate</code> <code>Optional[float]</code> <p>dropout rate for the edges</p> <code>0.0035</code>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.mpnn_pyg.MPNNPlusPyg.aggregate_features","title":"<code>aggregate_features(input_features, senders, receivers, sender_features, receiver_features, size)</code>","text":"<p>Function to aggregate (scatter) messages built from node and edge features.</p> <p>Parameters:</p> Name Type Description Default <code>input_features</code> <code>Tensor</code> <p>Edge features of the batch</p> required <code>senders</code> <code>Union[IntTensor, LongTensor]</code> <p>Senders of the edge_index of the batch</p> required <code>receivers</code> <code>Union[IntTensor, LongTensor]</code> <p>Receivers of the edge_index of the batch</p> required <code>sender_features</code> <code>Tensor</code> <p>Senders features gathered from the gather_features function</p> required <code>receiver_features</code> <code>Tensor</code> <p>Receiver features gathered from the gather_features function</p> required <code>size</code> <code>int</code> <p>size of the aggregation, equals to the total number of nodes</p> required Output <p>Aggregated node features</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.mpnn_pyg.MPNNPlusPyg.forward","title":"<code>forward(batch)</code>","text":"<p>Forward function of the MPNN Plus layer</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Batch</code> <p>pyg Batch graph to pass through the layer</p> required <p>Returns:</p> Name Type Description <code>batch</code> <code>Batch</code> <p>pyg Batch graph with updated node and edge features</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.mpnn_pyg.MPNNPlusPyg.gather_features","title":"<code>gather_features(input_features, senders, receivers)</code>","text":"<p>Function to gather node features based on the senders and receivers of the edge indices.</p> <p>Parameters:</p> Name Type Description Default <code>input_features</code> <code>Tensor</code> <p>Node features of the batch</p> required <code>senders</code> <code>Union[IntTensor, LongTensor]</code> <p>Senders of the edge_index of the batch</p> required <code>receivers</code> <code>Union[IntTensor, LongTensor]</code> <p>Receivers of the edge_index of the batch</p> required Output <p>Gathered node features (sender and receiver) summed up or concatenated Gathered sender features Gathered receiver features</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.mpnn_pyg.MPNNPlusPyg.layer_supports_edges","title":"<code>layer_supports_edges()</code>","text":"<p>Return a boolean specifying if the layer type supports edges or not.</p> <p>Returns:</p> Name Type Description <code>supports_edges</code> <code>bool</code> <p>bool Always <code>True</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pna_pyg","title":"<code>goli.nn.pyg_layers.pna_pyg</code>","text":""},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pna_pyg.PNAMessagePassingPyg","title":"<code>PNAMessagePassingPyg</code>","text":"<p>         Bases: <code>MessagePassing</code>, <code>BaseGraphStructure</code></p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pna_pyg.PNAMessagePassingPyg.layer_inputs_edges","title":"<code>layer_inputs_edges: bool</code>  <code>property</code>","text":"<p>Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Returns <code>self.edge_features</code></p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pna_pyg.PNAMessagePassingPyg.layer_outputs_edges","title":"<code>layer_outputs_edges: bool</code>  <code>property</code>","text":"<p>Abstract method. Return a boolean specifying if the layer type uses edges as input or not. It is different from <code>layer_supports_edges</code> since a layer that supports edges can decide to not use them.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>False</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pna_pyg.PNAMessagePassingPyg.out_dim_factor","title":"<code>out_dim_factor: int</code>  <code>property</code>","text":"<p>Get the factor by which the output dimension is multiplied for the next layer.</p> <p>For standard layers, this will return <code>1</code>.</p> <p>But for others, such as <code>GatLayer</code>, the output is the concatenation of the outputs from each head, so the out_dim gets multiplied by the number of heads, and this function should return the number of heads.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Always <code>1</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pna_pyg.PNAMessagePassingPyg.__init__","title":"<code>__init__(in_dim, out_dim, aggregators, scalers, activation='relu', dropout=0.0, normalization='none', avg_d={'log': 1.0, 'lin': 1.0}, last_activation='none', posttrans_layers=1, pretrans_layers=1, in_dim_edges=0, **kwargs)</code>","text":"<p>Implementation of the message passing architecture of the PNA message passing layer, previously known as <code>PNALayerComplex</code>. This layer applies an MLP as pretransformation to the concatenation of \\([h_u, h_v, e_{uv}]\\) to generate the messages, with \\(h_u\\) the node feature, \\(h_v\\) the neighbour node features, and \\(e_{uv}\\) the edge feature between the nodes \\(u\\) and \\(v\\).</p> <p>After the pre-transformation, it aggregates the messages multiple aggregators and scalers, concatenates their results, then applies an MLP on the concatenated features.</p> <p>PNA: Principal Neighbourhood Aggregation Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Lio, Petar Velickovic https://arxiv.org/abs/2004.05718</p> <p>[!] code adapted from pytorch-geometric implementation of PNAConv</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input feature dimensions of the layer</p> required <code>out_dim</code> <code>int</code> <p>Output feature dimensions of the layer</p> required <code>aggregators</code> <code>List[str]</code> <p>Set of aggregation function identifiers, e.g. \"mean\", \"max\", \"min\", \"std\", \"sum\", \"var\", \"moment3\". The results from all aggregators will be concatenated.</p> required <code>scalers</code> <code>List[str]</code> <p>Set of scaling functions identifiers e.g. \"identidy\", \"amplification\", \"attenuation\" The results from all scalers will be concatenated</p> required <code>activation</code> <code>Union[Callable, str]</code> <p>activation function to use in the layer</p> <code>'relu'</code> <code>dropout</code> <code>float</code> <p>The ratio of units to dropout. Must be between 0 and 1</p> <code>0.0</code> <code>normalization</code> <code>Union[str, Callable]</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'none'</code> <code>avg_d</code> <code>Dict[str, float]</code> <p>Average degree of nodes in the training set, used by scalers to normalize</p> <code>{'log': 1.0, 'lin': 1.0}</code> <code>last_activation</code> <code>Union[Callable, str]</code> <p>activation function to use in the last layer of the internal MLP</p> <code>'none'</code> <code>posttrans_layers</code> <code>int</code> <p>number of layers in the MLP transformation after the aggregation</p> <code>1</code> <code>pretrans_layers</code> <code>int</code> <p>number of layers in the transformation before the aggregation</p> <code>1</code> <code>in_dim_edges</code> <code>int</code> <p>size of the edge features. If 0, edges are ignored</p> <code>0</code>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pna_pyg.PNAMessagePassingPyg.aggregate","title":"<code>aggregate(inputs, index, edge_index, dim_size=None)</code>","text":"<p>aggregate function</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Tensor</code> <p>input features</p> required <code>index</code> <code>Tensor</code> <p>index of the nodes</p> required <code>edge_index</code> <code>Tensor</code> <p>edge index</p> required <code>dim_size</code> <code>Optional[int]</code> <p>dimension size</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>Tensor</code> <p>aggregated features</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pna_pyg.PNAMessagePassingPyg.forward","title":"<code>forward(batch)</code>","text":"<p>forward function of the layer</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Union[Data, Batch]</code> <p>pyg Batch graphs</p> required <p>Returns:</p> Name Type Description <code>batch</code> <code>Union[Data, Batch]</code> <p>pyg Batch graphs</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pna_pyg.PNAMessagePassingPyg.layer_supports_edges","title":"<code>layer_supports_edges()</code>","text":"<p>Return a boolean specifying if the layer type supports edges or not.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Always <code>True</code> for the current class</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pna_pyg.PNAMessagePassingPyg.message","title":"<code>message(x_i, x_j, edge_feat)</code>","text":"<p>message function</p> <p>Parameters:</p> Name Type Description Default <code>x_i</code> <code>Tensor</code> <p>node features</p> required <code>x_j</code> <code>Tensor</code> <p>neighbour node features</p> required <code>edge_feat</code> <code>OptTensor</code> <p>edge features</p> required <p>Returns:</p> Name Type Description <code>feat</code> <code>Tensor</code> <p>the message</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pooling_pyg","title":"<code>goli.nn.pyg_layers.pooling_pyg</code>","text":""},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pooling_pyg.PoolingWrapperPyg","title":"<code>PoolingWrapperPyg</code>","text":"<p>         Bases: <code>ModuleWrap</code></p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pooling_pyg.PoolingWrapperPyg.forward","title":"<code>forward(g, feature, *args, **kwargs)</code>","text":"<p>forward function</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Batch</code> <p>the pyg batch graph</p> required <code>feature</code> <code>Tensor</code> <p>the node features</p> required <p>Returns:</p> Type Description <p>the pooled features</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pooling_pyg.VirtualNodePyg","title":"<code>VirtualNodePyg</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pooling_pyg.VirtualNodePyg.__init__","title":"<code>__init__(in_dim, out_dim, in_dim_edges, out_dim_edges, vn_type='sum', activation='relu', dropout=0.0, normalization='none', bias=True, residual=True, use_edges=False, **kwargs)</code>","text":"<p>The VirtualNode is a layer that pool the features of the graph, applies a neural network layer on the pooled features, then add the result back to the node features of every node.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input feature dimensions of the virtual node layer.</p> required <code>out_dim</code> <code>int</code> <p>Output feature dimensions of the virtual node layer.</p> required <code>in_dim_edges</code> <code>Optional[int]</code> <p>Input feature dimensions of the virtual node layer for the edges.</p> required <code>out_dim_edges</code> <code>Optional[int]</code> <p>Output feature dimensions of the virtual node layer for the edges.</p> required <code>vn_type</code> <code>Union[type(None), str]</code> <p>The type of the virtual node. Choices are:</p> <ul> <li>\"none\": No pooling</li> <li>\"sum\": Sum all the nodes for each graph</li> <li>\"mean\": Mean all the nodes for each graph</li> <li>\"logsum\": Mean all the nodes then multiply by log(num_nodes) for each graph</li> <li>\"max\": Max all the nodes for each graph</li> <li>\"min\": Min all the nodes for each graph</li> <li>\"std\": Standard deviation of all the nodes for each graph</li> </ul> <code>'sum'</code> <code>activation</code> <code>Union[str, Callable]</code> <p>activation function to use in the neural network layer.</p> <code>'relu'</code> <code>dropout</code> <code>float</code> <p>The ratio of units to dropout. Must be between 0 and 1</p> <code>0.0</code> <code>normalization</code> <code>Union[str, Callable]</code> <p>Normalization to use. Choices:</p> <ul> <li>\"none\" or <code>None</code>: No normalization</li> <li>\"batch_norm\": Batch normalization</li> <li>\"layer_norm\": Layer normalization</li> <li><code>Callable</code>: Any callable function</li> </ul> <code>'none'</code> <code>bias</code> <code>bool</code> <p>Whether to add a bias to the neural network</p> <code>True</code> <code>residual</code> <code>bool</code> <p>Whether all virtual nodes should be connected together via a residual connection</p> <code>True</code> <code>use_edges</code> <code>bool</code> <p>Boolean flag to select if edges are used in the global node aggregation and update of features</p> <code>False</code>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pooling_pyg.VirtualNodePyg.forward","title":"<code>forward(g, feat, vn_feat, edge_feat)</code>","text":"<p>Apply the virtual node layer.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Union[Data, Batch]</code> <p>PyG Graphs or Batched graphs.</p> required <code>feat</code> <code>torch.Tensor[..., N, Din]</code> <p>Node feature tensor, before convolution. <code>N</code> is the number of nodes, <code>Din</code> is the input features</p> required <code>vn_feat</code> <code>torch.Tensor[..., M, Din]</code> <p>Graph feature of the previous virtual node, or <code>None</code> <code>M</code> is the number of graphs, <code>Din</code> is the input features. It is added to the result after the MLP, as a residual connection</p> required <code>edge_feat</code> <code>torch.Tensor[..., E, Din]</code> <p>Edge feature tensor, before convolution. <code>E</code> is the number of edges, <code>Din</code> is the input features</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p><code>feat = torch.Tensor[..., N, Dout]</code>: Node feature tensor, after convolution and residual. <code>N</code> is the number of nodes, <code>Dout</code> is the output features of the layer and residual</p> <code>Tensor</code> <p><code>vn_feat = torch.Tensor[..., M, Dout]</code>: Graph feature tensor to be used at the next virtual node, or <code>None</code> <code>M</code> is the number of graphs, <code>Dout</code> is the output features</p> <code>Tensor</code> <p><code>edge_feat = torch.Tensor[..., N, Dout]</code>: Edge feature tensor, after convolution and residual - if edges are used, otherwise returned unchanged. <code>N</code> is the number of edges, <code>Dout</code> is the output features of the layer and residual</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pooling_pyg.parse_pooling_layer_pyg","title":"<code>parse_pooling_layer_pyg(in_dim, pooling, feat_type='node', **kwargs)</code>","text":"<p>Select the pooling layers from a list of strings, and put them in a Module that concatenates their outputs.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>The dimension at the input layer of the pooling</p> required <code>pooling</code> <code>Union[str, List[str]]</code> <p>The list of pooling layers to use. The accepted strings are:</p> <ul> <li>\"none\": No pooling</li> <li>\"sum\": Sum all the nodes for each graph</li> <li>\"mean\": Mean all the nodes for each graph</li> <li>\"logsum\": Mean all the nodes then multiply by log(num_nodes) for each graph</li> <li>\"max\": Max all the nodes for each graph</li> <li>\"min\": Min all the nodes for each graph</li> <li>\"std\": Standard deviation of all the nodes for each graph</li> </ul> required"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pooling_pyg.scatter_logsum_pool","title":"<code>scatter_logsum_pool(x, batch, dim=0, dim_size=None)</code>","text":"<p>Apply pooling over the nodes in the graph using a mean aggregation, but scaled by the log of the number of nodes. This gives the same expressive power as the sum, but helps deal with graphs that are significantly larger than others by using a logarithmic scale.</p> \\[r^{(i)} = \\frac{\\log N_i}{N_i}\\sum_{k=1}^{N_i} x^{(i)}_k\\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Node feature matrix :math:<code>\\mathbf{X} \\in \\mathbb{R}^{(N_1 + \\ldots + N_B) \\times F}</code>.</p> required <code>batch</code> <code>LongTensor</code> <p>Batch vector :math:<code>\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N</code>, which assigns each node to a specific example.</p> required <code>size</code> <code>int</code> <p>Batch-size :math:<code>B</code>. Automatically calculated if not given. (default: :obj:<code>None</code>)</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>the pooled features tensor</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.pooling_pyg.scatter_std_pool","title":"<code>scatter_std_pool(x, batch, dim=0, dim_size=None)</code>","text":"<p>Returns batch-wise graph-level-outputs by taking the channel-wise minimum across the node dimension, so that for a single graph :math:<code>\\mathcal{G}_i</code> its output is computed by</p> <p>.. math::     \\mathbf{r}i = \\mathrm{max}{n=1}^{N_i} \\, \\mathbf{x}_n</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Node feature matrix :math:<code>\\mathbf{X} \\in \\mathbb{R}^{(N_1 + \\ldots + N_B) \\times F}</code>.</p> required <code>batch</code> <code>LongTensor</code> <p>Batch vector :math:<code>\\mathbf{b} \\in {\\{ 0, \\ldots, B-1\\}}^N</code>, which assigns each node to a specific example.</p> required <code>size</code> <code>int</code> <p>Batch-size :math:<code>B</code>. Automatically calculated if not given. (default: :obj:<code>None</code>)</p> required <p>Returns:</p> Type Description <p>the pooled features tensor</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.utils","title":"<code>goli.nn.pyg_layers.utils</code>","text":""},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.utils.GaussianLayer","title":"<code>GaussianLayer</code>","text":"<p>         Bases: <code>nn.Module</code></p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.utils.GaussianLayer.__init__","title":"<code>__init__(num_kernels=128, in_dim=3)</code>","text":"<pre><code>Gaussian kernel function that applied on the all-to-all 3D distances.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>num_kernels</code> <p>Number of gaussian kernel used.</p> <code>128</code>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.utils.PreprocessPositions","title":"<code>PreprocessPositions</code>","text":"<p>         Bases: <code>nn.Module</code></p> <p>Compute 3D attention bias and 3D node features according to the 3D position information.</p>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.utils.PreprocessPositions.__init__","title":"<code>__init__(num_heads, embed_dim, num_kernel, in_dim=3, num_layers=2, activation='gelu', first_normalization='none')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>num_heads</code> <p>Number of attention heads used in self-attention.</p> required <code>embed_dim</code> <p>Hidden dimension of node features.</p> required <code>num_kernel</code> <p>Number of gaussian kernels.</p> required <code>num_layers</code> <p>The number of layers in the MLP.</p> <code>2</code> <code>activation</code> <p>The activation function used in the MLP.</p> <code>'gelu'</code> <code>first_normalization</code> <p>The normalization function used before the gaussian kernel.</p> <code>'none'</code>"},{"location":"api/goli.nn/pyg_layers.html#goli.nn.pyg_layers.utils.PreprocessPositions.forward","title":"<code>forward(batch, max_num_nodes_per_graph, on_ipu, positions_3d_key)</code>","text":"Inputs <p>batch:     Batch object. max_num_nodes_per_graph:     Maximum number of nodes per graph. on_ipu:     If model rus on IPU. positions_3d_key:     The key of the pyg graph object that contains the 3D positions.</p>"},{"location":"tutorials/basics/csv_to_parquet.html","title":"Convert CSV to Parquet files","text":"In\u00a0[2]: Copied! <pre>import os\nimport pyarrow as pa\nimport pyarrow.parquet as pq\nimport pandas as pd\nfrom google.cloud import storage\nfrom io import StringIO\nimport goli\nimport os\nfrom os.path import dirname, abspath\n\nMAIN_DIR = dirname(dirname(abspath(goli.__file__)))\n\n# TODO create funciton to read parquet, test from GCP storage (put it in path, should support gs and path, explore function from Pandas instead of parquet \"pq\")\ndef _csv_to_parquet(csv_path, parquet_path):\n    df = pd.read_csv(csv_path)\n    df.to_parquet(parquet_path)\n\n_csv_to_parquet(MAIN_DIR + '/goli/data/QM9/micro_qm9.csv', MAIN_DIR + '/goli/data/QM9/micro_qm9.parquet')\n</pre> import os import pyarrow as pa import pyarrow.parquet as pq import pandas as pd from google.cloud import storage from io import StringIO import goli import os from os.path import dirname, abspath  MAIN_DIR = dirname(dirname(abspath(goli.__file__)))  # TODO create funciton to read parquet, test from GCP storage (put it in path, should support gs and path, explore function from Pandas instead of parquet \"pq\") def _csv_to_parquet(csv_path, parquet_path):     df = pd.read_csv(csv_path)     df.to_parquet(parquet_path)  _csv_to_parquet(MAIN_DIR + '/goli/data/QM9/micro_qm9.csv', MAIN_DIR + '/goli/data/QM9/micro_qm9.parquet') In\u00a0[\u00a0]: Copied! <pre># TODO create funciton to specify if you read parquet or csv\n    # TODO replace all location with call for _read_csv and make sure to read all files if path ends with \"*\"\n    # def read_table:\n</pre>     # TODO create funciton to specify if you read parquet or csv     # TODO replace all location with call for _read_csv and make sure to read all files if path ends with \"*\"     # def read_table: In\u00a0[1]: Copied! <pre>!pwd\n</pre> !pwd <pre>/home/oleksandr/code/goli/docs/tutorials/basics\n</pre> In\u00a0[3]: Copied! <pre>import goli\nimport os\nfrom os.path import dirname, abspath\nMAIN_DIR = dirname(dirname(abspath(goli.__file__)))\nos.chdir(MAIN_DIR) # No need for this file\n</pre> import goli import os from os.path import dirname, abspath MAIN_DIR = dirname(dirname(abspath(goli.__file__))) os.chdir(MAIN_DIR) # No need for this file Out[3]: <pre>'/home/oleksandr/code/goli/goli'</pre>"},{"location":"tutorials/basics/implementing_gnn_layers.html","title":"Creating GNN layers","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport torch\nimport dgl\nfrom copy import deepcopy\n\nfrom goli.nn.dgl_layers import BaseDGLLayer\nfrom goli.nn.base_layers import FCLayer\nfrom goli.utils.decorators import classproperty\n\n\n_ = torch.manual_seed(42)\n</pre> %load_ext autoreload %autoreload 2  import torch import dgl from copy import deepcopy  from goli.nn.dgl_layers import BaseDGLLayer from goli.nn.base_layers import FCLayer from goli.utils.decorators import classproperty   _ = torch.manual_seed(42) <pre>Using backend: pytorch\n</pre> In\u00a0[2]: Copied! <pre>in_dim = 5          # Input node-feature dimensions\nout_dim = 11        # Desired output node-feature dimensions\nin_dim_edges = 13   # Input edge-feature dimensions\n\n# Let's create 2 simple graphs. Here the tensors represent the connectivity between nodes\ng1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\ng2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))\n\n# We add some node features to the graphs\ng1.ndata[\"h\"] = torch.rand(g1.num_nodes(), in_dim, dtype=float)\ng2.ndata[\"h\"] = torch.rand(g2.num_nodes(), in_dim, dtype=float)\n\n# We also add some edge features to the graphs\ng1.edata[\"e\"] = torch.rand(g1.num_edges(), in_dim_edges, dtype=float)\ng2.edata[\"e\"] = torch.rand(g2.num_edges(), in_dim_edges, dtype=float)\n\n# Finally we batch the graphs in a way compatible with the DGL library\nbg = dgl.batch([g1, g2])\nbg = dgl.add_self_loop(bg)\n\n# The batched graph will show as a single graph with 7 nodes\nprint(bg)\n</pre> in_dim = 5          # Input node-feature dimensions out_dim = 11        # Desired output node-feature dimensions in_dim_edges = 13   # Input edge-feature dimensions  # Let's create 2 simple graphs. Here the tensors represent the connectivity between nodes g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))) g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))  # We add some node features to the graphs g1.ndata[\"h\"] = torch.rand(g1.num_nodes(), in_dim, dtype=float) g2.ndata[\"h\"] = torch.rand(g2.num_nodes(), in_dim, dtype=float)  # We also add some edge features to the graphs g1.edata[\"e\"] = torch.rand(g1.num_edges(), in_dim_edges, dtype=float) g2.edata[\"e\"] = torch.rand(g2.num_edges(), in_dim_edges, dtype=float)  # Finally we batch the graphs in a way compatible with the DGL library bg = dgl.batch([g1, g2]) bg = dgl.add_self_loop(bg)  # The batched graph will show as a single graph with 7 nodes print(bg) <pre>Graph(num_nodes=7, num_edges=14,\n      ndata_schemes={'h': Scheme(shape=(5,), dtype=torch.float64)}\n      edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float64)})\n</pre> In\u00a0[3]: Copied! <pre>class SimpleMeanLayer(BaseDGLLayer):\n    def __init__(self, in_dim, out_dim, activation, dropout, normalization):\n        # Initialize the parent class\n        super().__init__(   in_dim=in_dim, out_dim=out_dim, activation=activation,\n                            dropout=dropout, normalization=normalization)\n\n        # Create the layer with learned parameters\n        self.layer = FCLayer(in_dim=in_dim, out_dim=out_dim)\n\n    def forward(self, g, h):\n        # We first apply the mean aggregation\n        g.ndata[\"h\"] = h\n        g.update_all(message_func=dgl.function.copy_u(\"h\", \"m\"), \n                    reduce_func=dgl.function.mean(\"m\", \"h\"))\n\n        # Then we apply the FCLayer, and the non-linearities\n        h = g.ndata[\"h\"]\n        h = self.layer(h)\n        h = self.apply_norm_activation_dropout(h)\n        return h\n\n    # Finally, we define all the virtual properties according to how\n    # the class works\n    @classproperty\n    def layer_supports_edges(cls):\n        return False\n\n    @property\n    def layer_inputs_edges(self):\n        return False\n\n    @property\n    def layer_outputs_edges(self):\n        return False\n\n    @property\n    def out_dim_factor(self):\n        return 1\n</pre> class SimpleMeanLayer(BaseDGLLayer):     def __init__(self, in_dim, out_dim, activation, dropout, normalization):         # Initialize the parent class         super().__init__(   in_dim=in_dim, out_dim=out_dim, activation=activation,                             dropout=dropout, normalization=normalization)          # Create the layer with learned parameters         self.layer = FCLayer(in_dim=in_dim, out_dim=out_dim)      def forward(self, g, h):         # We first apply the mean aggregation         g.ndata[\"h\"] = h         g.update_all(message_func=dgl.function.copy_u(\"h\", \"m\"),                      reduce_func=dgl.function.mean(\"m\", \"h\"))          # Then we apply the FCLayer, and the non-linearities         h = g.ndata[\"h\"]         h = self.layer(h)         h = self.apply_norm_activation_dropout(h)         return h      # Finally, we define all the virtual properties according to how     # the class works     @classproperty     def layer_supports_edges(cls):         return False      @property     def layer_inputs_edges(self):         return False      @property     def layer_outputs_edges(self):         return False      @property     def out_dim_factor(self):         return 1    <p>Now, we are ready to test the <code>SimpleMeanLayer</code> on some DGL graphs. Note that in this example, we ignore the edge features since they are not supported.</p> In\u00a0[4]: Copied! <pre>graph = deepcopy(bg)\nh_in = graph.ndata[\"h\"]\nlayer = SimpleMeanLayer(\n            in_dim=in_dim, out_dim=out_dim, \n            activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)\nh_out = layer(graph, h_in)\n\nprint(h_in.shape)\nprint(h_out.shape)\n</pre> graph = deepcopy(bg) h_in = graph.ndata[\"h\"] layer = SimpleMeanLayer(             in_dim=in_dim, out_dim=out_dim,              activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float) h_out = layer(graph, h_in)  print(h_in.shape) print(h_out.shape) <pre>torch.Size([7, 5])\ntorch.Size([7, 11])\n</pre> In\u00a0[5]: Copied! <pre>class ComplexMeanLayer(BaseDGLLayer):\n    def __init__(self, in_dim, out_dim, in_dim_edges, activation, dropout, normalization):\n        # Initialize the parent class\n        super().__init__(   in_dim=in_dim, out_dim=out_dim, activation=activation,\n                            dropout=dropout, normalization=normalization)\n\n        # Create the layer with learned parameters. Note the addition\n        self.layer = FCLayer(in_dim=in_dim + in_dim_edges, out_dim=out_dim)\n\n    def cat_nodes_edges(self, edges):\n        # Create a message \"m\" by concatenating \"h\" and \"e\" for each pair of nodes\n        nodes_edges = torch.cat([edges.src[\"h\"], edges.data[\"e\"]], dim=-1)\n        return {\"m\": nodes_edges}\n\n    def get_edges_messages(self, edges): # Simply return the messages on the edges\n        return {\"m\": edges.data[\"m\"]}\n\n    def forward(self, g, h, e):\n\n        # We first concatenate both the node and edge features on the edges\n        g.ndata[\"h\"] = h\n        g.edata[\"e\"] = e\n        g.apply_edges(self.cat_nodes_edges)\n\n        # Then we apply the mean aggregation to generate a message \"m\"\n        g.update_all(message_func=self.get_edges_messages, \n                    reduce_func=dgl.function.mean(\"m\", \"h\"))\n\n        # Finally we apply the FCLayer, and the non-linearities\n        h = g.ndata[\"h\"]\n        h = self.layer(h)\n        h = self.apply_norm_activation_dropout(h)\n        return h\n\n    # Finally, we define all the virtual properties according to how\n    # the class works\n    @classproperty\n    def layer_supports_edges(cls):\n        return True\n\n    @property\n    def layer_inputs_edges(self):\n        return True\n\n    @property\n    def layer_outputs_edges(self):\n        return False\n\n    @property\n    def out_dim_factor(self):\n        return 1\n</pre> class ComplexMeanLayer(BaseDGLLayer):     def __init__(self, in_dim, out_dim, in_dim_edges, activation, dropout, normalization):         # Initialize the parent class         super().__init__(   in_dim=in_dim, out_dim=out_dim, activation=activation,                             dropout=dropout, normalization=normalization)          # Create the layer with learned parameters. Note the addition         self.layer = FCLayer(in_dim=in_dim + in_dim_edges, out_dim=out_dim)      def cat_nodes_edges(self, edges):         # Create a message \"m\" by concatenating \"h\" and \"e\" for each pair of nodes         nodes_edges = torch.cat([edges.src[\"h\"], edges.data[\"e\"]], dim=-1)         return {\"m\": nodes_edges}      def get_edges_messages(self, edges): # Simply return the messages on the edges         return {\"m\": edges.data[\"m\"]}      def forward(self, g, h, e):          # We first concatenate both the node and edge features on the edges         g.ndata[\"h\"] = h         g.edata[\"e\"] = e         g.apply_edges(self.cat_nodes_edges)          # Then we apply the mean aggregation to generate a message \"m\"         g.update_all(message_func=self.get_edges_messages,                      reduce_func=dgl.function.mean(\"m\", \"h\"))          # Finally we apply the FCLayer, and the non-linearities         h = g.ndata[\"h\"]         h = self.layer(h)         h = self.apply_norm_activation_dropout(h)         return h      # Finally, we define all the virtual properties according to how     # the class works     @classproperty     def layer_supports_edges(cls):         return True      @property     def layer_inputs_edges(self):         return True      @property     def layer_outputs_edges(self):         return False      @property     def out_dim_factor(self):         return 1    <p>Now, we are ready to test the <code>ComplexMeanLayer</code> on some DGL graphs. Note that in this example, we use the edge features since they are mandatory.</p> In\u00a0[6]: Copied! <pre>graph = deepcopy(bg)\nh_in = graph.ndata[\"h\"]\ne_in = graph.edata[\"e\"]\nlayer = ComplexMeanLayer(\n            in_dim=in_dim, out_dim=out_dim, in_dim_edges=in_dim_edges,\n            activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)\nh_out = layer(graph, h_in, e_in)\n\nprint(h_in.shape)\nprint(h_out.shape)\n</pre> graph = deepcopy(bg) h_in = graph.ndata[\"h\"] e_in = graph.edata[\"e\"] layer = ComplexMeanLayer(             in_dim=in_dim, out_dim=out_dim, in_dim_edges=in_dim_edges,             activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float) h_out = layer(graph, h_in, e_in)  print(h_in.shape) print(h_out.shape) <pre>torch.Size([7, 5])\ntorch.Size([7, 11])\n</pre>"},{"location":"tutorials/basics/implementing_gnn_layers.html#creating-gnn-layers","title":"Creating GNN layers\u00b6","text":"<p>One of the primary advantage of the current library is the fact that GNN layers are independant from model architecture, thus allowing more flexibility with the code by easily swapping different layer types as hyper-parameters. However, this requires that the layers be implemented using the DGL library, and must be inherited from the class <code>BaseDGLLayer</code>, which standardizes the inputs, outputs and properties of the layers. Thus, the architecture can be handled independantly using the class <code>FeedForwardDGL</code>, or any similar custom class.</p> <p>We will first start by a simple layer that does not use edges, to a more complex layer that uses edges.</p> <p>Since these examples are built on top of DGL, we recommend looking at their library for more info.</p>"},{"location":"tutorials/basics/implementing_gnn_layers.html#pre-defining-test-variables","title":"Pre-defining test variables\u00b6","text":"<p>We define below a small batched graph on which we can test the created layers</p>"},{"location":"tutorials/basics/implementing_gnn_layers.html#creating-a-simple-layer","title":"Creating a simple layer\u00b6","text":"<p>Here, we will show how to create a GNN layer that does a mean aggregation on the neighbouring features.</p> <p>First, for the layer to be fully compatible with the flexible architecture provided by <code>FeedForwardDGL</code>, it needs to inherit from the class <code>BaseDGLLayer</code>. This base-layer has multiple virtual methods that must be implemented in any class that inherits from it.</p> <p>The virtual methods are below</p> <ul> <li><code>layer_supports_edges</code>: We want to return <code>False</code> since our layer doesn't support edges</li> <li><code>layer_inputs_edges</code>: We want to return <code>False</code> since our layer doesn't input edges</li> <li><code>layer_outputs_edges</code>: We want to return <code>False</code> since our layer doesn't output edges</li> <li><code>layer_outdim_factor</code>: We want to return <code>1</code> since the output dimension does not depend on internal parameters.</li> </ul> <p>The example is given below</p>"},{"location":"tutorials/basics/implementing_gnn_layers.html#creating-a-complex-layer-with-edges","title":"Creating a complex layer with edges\u00b6","text":"<p>Here, we will show how to create a GNN layer that does a mean aggregation on the neighbouring features, concatenated to the edge features with their neighbours. In that case, only the node features will change, and the network will not update the edge features.</p> <p>The virtual methods will have different outputs</p> <ul> <li><code>layer_supports_edges</code>: We want to return <code>True</code> since our layer does support edges</li> <li><code>layer_inputs_edges</code>: We want to return <code>True</code> since our layer does input edges</li> <li><code>layer_outputs_edges</code>: We want to return <code>False</code> since our layer will not output new edges</li> <li><code>layer_outdim_factor</code>: We want to return <code>1</code> since the output dimension does not depend on internal parameters.</li> </ul> <p>The example is given below</p>"},{"location":"tutorials/basics/making_gnn_networks.html","title":"Making GNN Networks","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport torch\nimport dgl\nfrom copy import deepcopy\n\nfrom goli.nn.dgl_layers import PNAMessagePassingLayer\nfrom goli.nn.architectures import FullDGLNetwork\n\n_ = torch.manual_seed(42)\n</pre> %load_ext autoreload %autoreload 2  import torch import dgl from copy import deepcopy  from goli.nn.dgl_layers import PNAMessagePassingLayer from goli.nn.architectures import FullDGLNetwork  _ = torch.manual_seed(42) <pre>Using backend: pytorch\n</pre> <p>We will first create some simple batched graphs that will be used accross the examples. Here, <code>bg</code> is a batch containing 2 graphs with random node features.</p> In\u00a0[2]: Copied! <pre>in_dim = 5          # Input node-feature dimensions\nout_dim = 11        # Desired output node-feature dimensions\nin_dim_edges = 13   # Input edge-feature dimensions\n\n# Let's create 2 simple graphs. Here the tensors represent the connectivity between nodes\ng1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\ng2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))\n\n# We add some node features to the graphs\ng1.ndata[\"feat\"] = torch.rand(g1.num_nodes(), in_dim, dtype=float)\ng2.ndata[\"feat\"] = torch.rand(g2.num_nodes(), in_dim, dtype=float)\n\n# We also add some edge features to the graphs\ng1.edata[\"feat\"] = torch.rand(g1.num_edges(), in_dim_edges, dtype=float)\ng2.edata[\"feat\"] = torch.rand(g2.num_edges(), in_dim_edges, dtype=float)\n\n# Finally we batch the graphs in a way compatible with the DGL library\nbg = dgl.batch([g1, g2])\nbg = dgl.add_self_loop(bg)\n\n# The batched graph will show as a single graph with 7 nodes\nprint(bg)\n</pre> in_dim = 5          # Input node-feature dimensions out_dim = 11        # Desired output node-feature dimensions in_dim_edges = 13   # Input edge-feature dimensions  # Let's create 2 simple graphs. Here the tensors represent the connectivity between nodes g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))) g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))  # We add some node features to the graphs g1.ndata[\"feat\"] = torch.rand(g1.num_nodes(), in_dim, dtype=float) g2.ndata[\"feat\"] = torch.rand(g2.num_nodes(), in_dim, dtype=float)  # We also add some edge features to the graphs g1.edata[\"feat\"] = torch.rand(g1.num_edges(), in_dim_edges, dtype=float) g2.edata[\"feat\"] = torch.rand(g2.num_edges(), in_dim_edges, dtype=float)  # Finally we batch the graphs in a way compatible with the DGL library bg = dgl.batch([g1, g2]) bg = dgl.add_self_loop(bg)  # The batched graph will show as a single graph with 7 nodes print(bg)  <pre>Graph(num_nodes=7, num_edges=14,\n      ndata_schemes={'feat': Scheme(shape=(5,), dtype=torch.float64)}\n      edata_schemes={'feat': Scheme(shape=(13,), dtype=torch.float64)})\n</pre> In\u00a0[3]: Copied! <pre>temp_dim_1 = 23\ntemp_dim_2 = 17\n\npre_nn_kwargs = {\n        \"in_dim\": in_dim,\n        \"out_dim\": temp_dim_1,\n        \"hidden_dims\": [4, 4, 4],\n        \"activation\": \"relu\",\n        \"last_activation\": \"none\",\n        \"batch_norm\": True,\n        \"dropout\": 0.2,    }\n\npost_nn_kwargs = {\n        \"in_dim\": temp_dim_2,\n        \"out_dim\": out_dim,\n        \"hidden_dims\": [6, 6],\n        \"activation\": \"relu\",\n        \"last_activation\": \"sigmoid\",\n        \"batch_norm\": False,\n        \"dropout\": 0.,    }\n\nlayer_kwargs = {\n    \"aggregators\": [\"mean\", \"max\", \"sum\"], \n    \"scalers\": [\"identity\", \"amplification\"],}\n\ngnn_kwargs = {\n    \"in_dim\": temp_dim_1,\n    \"out_dim\": temp_dim_2,\n    \"hidden_dims\": [5, 5, 5, 5, 5, 5],\n    \"residual_type\": \"densenet\",\n    \"residual_skip_steps\": 2,\n    \"layer_type\": PNAMessagePassingLayer,\n    \"pooling\": [\"sum\"],\n    \"activation\": \"relu\",\n    \"last_activation\": \"none\",\n    \"batch_norm\": False,\n    \"dropout\": 0.2,\n    \"in_dim_edges\": in_dim_edges,\n    \"layer_kwargs\": layer_kwargs,\n}\n\ngnn_net = FullDGLNetwork(\n    pre_nn_kwargs=pre_nn_kwargs, \n    gnn_kwargs=gnn_kwargs, \n    post_nn_kwargs=post_nn_kwargs).to(float)\n</pre> temp_dim_1 = 23 temp_dim_2 = 17  pre_nn_kwargs = {         \"in_dim\": in_dim,         \"out_dim\": temp_dim_1,         \"hidden_dims\": [4, 4, 4],         \"activation\": \"relu\",         \"last_activation\": \"none\",         \"batch_norm\": True,         \"dropout\": 0.2,    }  post_nn_kwargs = {         \"in_dim\": temp_dim_2,         \"out_dim\": out_dim,         \"hidden_dims\": [6, 6],         \"activation\": \"relu\",         \"last_activation\": \"sigmoid\",         \"batch_norm\": False,         \"dropout\": 0.,    }  layer_kwargs = {     \"aggregators\": [\"mean\", \"max\", \"sum\"],      \"scalers\": [\"identity\", \"amplification\"],}  gnn_kwargs = {     \"in_dim\": temp_dim_1,     \"out_dim\": temp_dim_2,     \"hidden_dims\": [5, 5, 5, 5, 5, 5],     \"residual_type\": \"densenet\",     \"residual_skip_steps\": 2,     \"layer_type\": PNAMessagePassingLayer,     \"pooling\": [\"sum\"],     \"activation\": \"relu\",     \"last_activation\": \"none\",     \"batch_norm\": False,     \"dropout\": 0.2,     \"in_dim_edges\": in_dim_edges,     \"layer_kwargs\": layer_kwargs, }  gnn_net = FullDGLNetwork(     pre_nn_kwargs=pre_nn_kwargs,      gnn_kwargs=gnn_kwargs,      post_nn_kwargs=post_nn_kwargs).to(float) In\u00a0[4]: Copied! <pre>graph = deepcopy(bg)\nh_in = graph.ndata[\"feat\"]\n\nh_out = gnn_net(graph)\n\nprint(h_in.shape)\nprint(h_out.shape)\nprint(\"\\n\")\nprint(gnn_net)\n</pre> graph = deepcopy(bg) h_in = graph.ndata[\"feat\"]  h_out = gnn_net(graph)  print(h_in.shape) print(h_out.shape) print(\"\\n\") print(gnn_net)  <pre>torch.Size([7, 5])\ntorch.Size([1, 11])\n\n\nDGL_GNN\n---------\n    pre-NN(depth=4, ResidualConnectionNone)\n        [FCLayer[5 -&gt; 4 -&gt; 4 -&gt; 4 -&gt; 23]\n    \n    GNN(depth=7, ResidualConnectionDenseNet(skip_steps=2))\n        PNAMessagePassingLayer[23 -&gt; 5 -&gt; 5 -&gt; 5 -&gt; 5 -&gt; 5 -&gt; 5 -&gt; 17]\n        -&gt; Pooling(['sum']) -&gt; FCLayer(17 -&gt; 17, activation=None)\n    \n    post-NN(depth=3, ResidualConnectionNone)\n        [FCLayer[17 -&gt; 6 -&gt; 6 -&gt; 11]\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/basics/making_gnn_networks.html#making-gnn-networks","title":"Making GNN Networks\u00b6","text":"<p>In this example, you will learn how to easily build a full GNN network using any kind of GNN layer. This tutorial uses the architecture defined by the class <code>FullDGLNetwork</code>, which is compatible with any layer that inherits from <code>BaseDGLLayer</code>.</p> <p><code>FullDGLNetwork</code> is an architecture that takes as input node features and (optionally) edge features. It applies a pre-MLP on both sets of features, then it passes it into a main GNN network, and finally applies a post-MLP to produce the final output (either node predictions or graph property predictions).</p> <p>The network is very easy to built via a dictionnary of parameter that allow to custom each part of the network.</p>"},{"location":"tutorials/basics/making_gnn_networks.html#building-the-network","title":"Building the network\u00b6","text":"<p>To build the network, we must define the arguments to pass at the different steps:</p> <ul> <li><p><code>pre_nn_kwargs</code>: The parameters used by a feed-forward neural network on the input node-features, before passing to the convolutional layers. See class <code>FeedForwardNN</code> for details on the required parameters. Will be ignored if set to <code>None</code>.</p> </li> <li><p><code>gnn_kwargs</code>: The parameters used by a feed-forward graph neural network on the features after it has passed through the pre-processing neural network. See class <code>FeedForwardDGL</code> for details on the required parameters.</p> </li> <li><p><code>post_nn_kwargs</code>: The parameters used by a feed-forward neural network on the features after the GNN layers. See class <code>FeedForwardNN</code> for details on the required parameters. Will be ignored if set to <code>None</code>.</p> </li> </ul>"},{"location":"tutorials/basics/making_gnn_networks.html#applying-the-network","title":"Applying the network\u00b6","text":"<p>Once the network is defined, we only need to run the forward pass on the input graphs to get a prediction.</p> <p>The network will handle the node and edge features depending on it's parameters and layer type.</p> <p>Chosing between graph property prediction and node property prediction depends on the parameter given by <code>gnn_kwargs[\"pooling\"]</code>.</p>"},{"location":"tutorials/basics/parquet_reader.html","title":"Reading Parquet files","text":"In\u00a0[4]: Copied! <pre>import os\nimport pyarrow as pa\nimport pyarrow.parquet as pq\nimport pandas as pd\nfrom google.cloud import storage\nfrom io import StringIO\n\n# TODO create funciton to read parquet, test from GCP storage (put it in path, should support gs and path, explore function from Pandas instead of parquet \"pq\")\ndef _read_parquet(path, **kwargs):\n\n    bucket_name = path\n    destination_blob_name = 'Compound_000025001_000050000.parquet'\n    \n    storage_client = storage.Client()\n    bucket = storage_client.bucket(bucket_name)\n    blob = bucket.blob(destination_blob_name)\n \n    # read as string\n    read_output = blob.download_as_string()\n    df = pd.read_csv(StringIO(read_output))\n \n    print(\n        \"File {} read successfully  from Bucket  {}.\".format(\n            destination_blob_name, bucket_name\n        )\n    )\n\n_read_parquet('gs://goli-private/datasets/pm6')\n</pre> import os import pyarrow as pa import pyarrow.parquet as pq import pandas as pd from google.cloud import storage from io import StringIO  # TODO create funciton to read parquet, test from GCP storage (put it in path, should support gs and path, explore function from Pandas instead of parquet \"pq\") def _read_parquet(path, **kwargs):      bucket_name = path     destination_blob_name = 'Compound_000025001_000050000.parquet'          storage_client = storage.Client()     bucket = storage_client.bucket(bucket_name)     blob = bucket.blob(destination_blob_name)       # read as string     read_output = blob.download_as_string()     df = pd.read_csv(StringIO(read_output))       print(         \"File {} read successfully  from Bucket  {}.\".format(             destination_blob_name, bucket_name         )     )  _read_parquet('gs://goli-private/datasets/pm6') <pre>\n---------------------------------------------------------------------------\nInvalidResponse                           Traceback (most recent call last)\nFile ~/.venv/goli_ipu/lib/python3.8/site-packages/google/cloud/storage/client.py:1151, in Client.download_blob_to_file(self, blob_or_uri, file_obj, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\n   1150 try:\n-&gt; 1151     blob_or_uri._do_download(\n   1152         transport,\n   1153         file_obj,\n   1154         download_url,\n   1155         headers,\n   1156         start,\n   1157         end,\n   1158         raw_download,\n   1159         timeout=timeout,\n   1160         checksum=checksum,\n   1161         retry=retry,\n   1162     )\n   1163 except resumable_media.InvalidResponse as exc:\n\nFile ~/.venv/goli_ipu/lib/python3.8/site-packages/google/cloud/storage/blob.py:989, in Blob._do_download(self, transport, file_obj, download_url, headers, start, end, raw_download, timeout, checksum, retry)\n    988 download._retry_strategy = retry_strategy\n--&gt; 989 response = download.consume(transport, timeout=timeout)\n    990 self._extract_headers_from_download(response)\n\nFile ~/.venv/goli_ipu/lib/python3.8/site-packages/google/resumable_media/requests/download.py:214, in Download.consume(self, transport, timeout)\n    212     return result\n--&gt; 214 return _request_helpers.wait_and_retry(\n    215     retriable_request, self._get_status_code, self._retry_strategy\n    216 )\n\nFile ~/.venv/goli_ipu/lib/python3.8/site-packages/google/resumable_media/requests/_request_helpers.py:148, in wait_and_retry(func, get_status_code, retry_strategy)\n    147 try:\n--&gt; 148     response = func()\n    149 except _CONNECTION_ERROR_CLASSES as e:\n\nFile ~/.venv/goli_ipu/lib/python3.8/site-packages/google/resumable_media/requests/download.py:207, in Download.consume.&lt;locals&gt;.retriable_request()\n    203     self._object_generation = _helpers._parse_generation_header(\n    204         result, self._get_headers\n    205     )\n--&gt; 207 self._process_response(result)\n    209 if self._stream is not None:\n\nFile ~/.venv/goli_ipu/lib/python3.8/site-packages/google/resumable_media/_download.py:188, in Download._process_response(self, response)\n    187 self._finished = True\n--&gt; 188 _helpers.require_status_code(\n    189     response, _ACCEPTABLE_STATUS_CODES, self._get_status_code\n    190 )\n\nFile ~/.venv/goli_ipu/lib/python3.8/site-packages/google/resumable_media/_helpers.py:105, in require_status_code(response, status_codes, get_status_code, callback)\n    104         callback()\n--&gt; 105     raise common.InvalidResponse(\n    106         response,\n    107         \"Request failed with status code\",\n    108         status_code,\n    109         \"Expected one of\",\n    110         *status_codes\n    111     )\n    112 return status_code\n\nInvalidResponse: ('Request failed with status code', 404, 'Expected one of', &lt;HTTPStatus.OK: 200&gt;, &lt;HTTPStatus.PARTIAL_CONTENT: 206&gt;)\n\nDuring handling of the above exception, another exception occurred:\n\nNotFound                                  Traceback (most recent call last)\n/home/oleksandr/code/goli/tests/parquet_reader.ipynb Cell 1 in &lt;cell line: 39&gt;()\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=23'&gt;24&lt;/a&gt;     print(\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=24'&gt;25&lt;/a&gt;         \"File {} read successfully  from Bucket  {}.\".format(\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=25'&gt;26&lt;/a&gt;             destination_blob_name, bucket_name\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=26'&gt;27&lt;/a&gt;         )\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=27'&gt;28&lt;/a&gt;     )\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=29'&gt;30&lt;/a&gt;     # files = os.listdir(path)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=30'&gt;31&lt;/a&gt;     # print('files is', files)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=31'&gt;32&lt;/a&gt; \n   (...)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=35'&gt;36&lt;/a&gt;     # # df = pd.read_csv(path, **kwargs)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=36'&gt;37&lt;/a&gt;     # return df\n---&gt; &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=38'&gt;39&lt;/a&gt; _read_parquet('gs://goli-private/datasets/pm6')\n\n/home/oleksandr/code/goli/tests/parquet_reader.ipynb Cell 1 in _read_parquet(path, **kwargs)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=15'&gt;16&lt;/a&gt; blob = bucket.blob(destination_blob_name)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=17'&gt;18&lt;/a&gt; # read as string\n---&gt; &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=18'&gt;19&lt;/a&gt; read_output = blob.download_as_string()\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=20'&gt;21&lt;/a&gt; # blobstring = blob_service.get_blob_to_text(CONTAINERNAME,BLOBNAME)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B193.57.88.53/home/oleksandr/code/goli/tests/parquet_reader.ipynb#ch0000000vscode-remote?line=21'&gt;22&lt;/a&gt; df = pd.read_csv(StringIO(read_output))\n\nFile ~/.venv/goli_ipu/lib/python3.8/site-packages/google/cloud/storage/blob.py:1516, in Blob.download_as_string(self, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, retry)\n   1434 \"\"\"(Deprecated) Download the contents of this blob as a bytes object.\n   1435 \n   1436 If :attr:`user_project` is set on the bucket, bills the API request\n   (...)\n   1511 :raises: :class:`google.cloud.exceptions.NotFound`\n   1512 \"\"\"\n   1513 warnings.warn(\n   1514     _DOWNLOAD_AS_STRING_DEPRECATED, PendingDeprecationWarning, stacklevel=2\n   1515 )\n-&gt; 1516 return self.download_as_bytes(\n   1517     client=client,\n   1518     start=start,\n   1519     end=end,\n   1520     raw_download=raw_download,\n   1521     if_etag_match=if_etag_match,\n   1522     if_etag_not_match=if_etag_not_match,\n   1523     if_generation_match=if_generation_match,\n   1524     if_generation_not_match=if_generation_not_match,\n   1525     if_metageneration_match=if_metageneration_match,\n   1526     if_metageneration_not_match=if_metageneration_not_match,\n   1527     timeout=timeout,\n   1528     retry=retry,\n   1529 )\n\nFile ~/.venv/goli_ipu/lib/python3.8/site-packages/google/cloud/storage/blob.py:1401, in Blob.download_as_bytes(self, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\n   1399 client = self._require_client(client)\n   1400 string_buffer = BytesIO()\n-&gt; 1401 client.download_blob_to_file(\n   1402     self,\n   1403     string_buffer,\n   1404     start=start,\n   1405     end=end,\n   1406     raw_download=raw_download,\n   1407     if_etag_match=if_etag_match,\n   1408     if_etag_not_match=if_etag_not_match,\n   1409     if_generation_match=if_generation_match,\n   1410     if_generation_not_match=if_generation_not_match,\n   1411     if_metageneration_match=if_metageneration_match,\n   1412     if_metageneration_not_match=if_metageneration_not_match,\n   1413     timeout=timeout,\n   1414     checksum=checksum,\n   1415     retry=retry,\n   1416 )\n   1417 return string_buffer.getvalue()\n\nFile ~/.venv/goli_ipu/lib/python3.8/site-packages/google/cloud/storage/client.py:1164, in Client.download_blob_to_file(self, blob_or_uri, file_obj, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\n   1151     blob_or_uri._do_download(\n   1152         transport,\n   1153         file_obj,\n   (...)\n   1161         retry=retry,\n   1162     )\n   1163 except resumable_media.InvalidResponse as exc:\n-&gt; 1164     _raise_from_invalid_response(exc)\n\nFile ~/.venv/goli_ipu/lib/python3.8/site-packages/google/cloud/storage/blob.py:4457, in _raise_from_invalid_response(error)\n   4453     error_message = str(error)\n   4455 message = f\"{response.request.method} {response.request.url}: {error_message}\"\n-&gt; 4457 raise exceptions.from_http_status(response.status_code, message, response=response)\n\nNotFound: 404 GET https://storage.googleapis.com/download/storage/v1/b/gs://goli-private/datasets/pm6/o/Compound_000025001_000050000.parquet?alt=media: Not Found: ('Request failed with status code', 404, 'Expected one of', &lt;HTTPStatus.OK: 200&gt;, &lt;HTTPStatus.PARTIAL_CONTENT: 206&gt;)</pre> In\u00a0[1]: Copied! <pre>import pandas as pd\nimport goli\nimport os\nfrom os.path import dirname, abspath\n\nMAIN_DIR = dirname(dirname(abspath(goli.__file__)))\n\nfilename = MAIN_DIR + '/goli/data/QM9/micro_qm9'\ndf = pd.read_parquet(f'{filename}.parquet')\n\ndf\n</pre> import pandas as pd import goli import os from os.path import dirname, abspath  MAIN_DIR = dirname(dirname(abspath(goli.__file__)))  filename = MAIN_DIR + '/goli/data/QM9/micro_qm9' df = pd.read_parquet(f'{filename}.parquet')  df Out[1]: mol_id smiles A B C mu alpha homo lumo gap ... zpve u0 u298 h298 g298 cv u0_atom u298_atom h298_atom g298_atom 0 gdb_1 C 157.71180 157.709970 157.706990 0.0000 13.21 -0.3877 0.1171 0.5048 ... 0.044749 -40.478930 -40.476062 -40.475117 -40.498597 6.469 -395.999595 -398.643290 -401.014647 -372.471772 1 gdb_2 N 293.60975 293.541110 191.393970 1.6256 9.46 -0.2570 0.0829 0.3399 ... 0.034358 -56.525887 -56.523026 -56.522082 -56.544961 6.316 -276.861363 -278.620271 -280.399259 -259.338802 2 gdb_3 O 799.58812 437.903860 282.945450 1.8511 6.31 -0.2928 0.0687 0.3615 ... 0.021375 -76.404702 -76.401867 -76.400922 -76.422349 6.002 -213.087624 -213.974294 -215.159658 -201.407171 3 gdb_4 C#C 0.00000 35.610036 35.610036 0.0000 16.28 -0.2845 0.0506 0.3351 ... 0.026841 -77.308427 -77.305527 -77.304583 -77.327429 8.574 -385.501997 -387.237686 -389.016047 -365.800724 4 gdb_5 C#N 0.00000 44.593883 44.593883 2.8937 12.99 -0.3604 0.0191 0.3796 ... 0.016601 -93.411888 -93.409370 -93.408425 -93.431246 6.278 -301.820534 -302.906752 -304.091489 -288.720028 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1001 gdb_94823 CC1OCC2(CC2)C=C1 3.73934 1.156580 1.019880 1.0639 86.86 -0.2291 0.0210 0.2501 ... 0.183181 -387.089386 -387.080974 -387.080030 -387.122163 33.410 -2037.744489 -2051.130511 -2062.985411 -1895.686491 1002 gdb_39986 C1CC11CC2C3OC2C13 4.01995 1.375230 1.276030 2.0583 78.65 -0.2263 0.0855 0.3118 ... 0.160873 -385.816258 -385.809490 -385.808546 -385.847235 28.507 -1866.696830 -1879.337372 -1890.006280 -1736.880279 1003 gdb_129889 c1c(nc2n1cno2)N 5.52693 1.335230 1.076560 4.4714 67.81 -0.2034 -0.0173 0.1861 ... 0.092058 -448.922474 -448.915855 -448.914911 -448.953258 25.857 -1339.274261 -1346.674475 -1353.785407 -1248.217057 1004 gdb_47001 O=C1NCC2COC1C2 2.67679 1.787180 1.428170 4.8266 70.94 -0.2282 0.0241 0.2522 ... 0.151811 -439.131708 -439.124600 -439.123656 -439.163299 28.066 -1779.364520 -1790.901901 -1800.977813 -1656.054609 1005 gdb_53123 CC#CC1C2C3CN1C23 4.54414 0.981090 0.944760 1.7549 84.57 -0.2224 0.0357 0.2581 ... 0.147781 -364.706764 -364.698604 -364.697660 -364.740861 30.373 -1786.060041 -1796.938537 -1807.014449 -1664.834715 <p>1006 rows \u00d7 21 columns</p>"},{"location":"tutorials/basics/timing_parallel.html","title":"pandarallel","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport joblib\n\nimport numpy as np\nimport datamol as dm\nimport pandas as pd\n\nfrom pandarallel import pandarallel\n\npandarallel.initialize(progress_bar=True, nb_workers=joblib.cpu_count())\n</pre> %load_ext autoreload %autoreload 2  import joblib  import numpy as np import datamol as dm import pandas as pd  from pandarallel import pandarallel  pandarallel.initialize(progress_bar=True, nb_workers=joblib.cpu_count()) <pre>INFO: Pandarallel will run on 240 workers.\nINFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n</pre> In\u00a0[2]: Copied! <pre># download from https://raw.githubusercontent.com/aspuru-guzik-group/chemical_vae/master/models/zinc_properties/250k_rndm_zinc_drugs_clean_3.csv\n# data = pd.read_csv(\"/home/hadim/250k_rndm_zinc_drugs_clean_3.csv\", usecols=[\"smiles\"])\n\n# download from https://storage.googleapis.com/goli-public/datasets/QM9/norm_qm9.csv\ndata = pd.read_csv(\"https://storage.googleapis.com/goli-public/datasets/QM9/norm_qm9.csv\", usecols=[\"smiles\"])\n</pre> # download from https://raw.githubusercontent.com/aspuru-guzik-group/chemical_vae/master/models/zinc_properties/250k_rndm_zinc_drugs_clean_3.csv # data = pd.read_csv(\"/home/hadim/250k_rndm_zinc_drugs_clean_3.csv\", usecols=[\"smiles\"])  # download from https://storage.googleapis.com/goli-public/datasets/QM9/norm_qm9.csv data = pd.read_csv(\"https://storage.googleapis.com/goli-public/datasets/QM9/norm_qm9.csv\", usecols=[\"smiles\"]) In\u00a0[3]: Copied! <pre>rows_number_list = [250_000]\nbatch_size_list = [10, 100, 1_000, 10_000]\n\n\ndef smiles_to_unique_mol_id(smiles):\n    try:\n        mol = dm.to_mol(mol=smiles)\n        mol_id = dm.unique_id(mol)\n    except:\n        mol_id = \"\"\n    if mol_id is None:\n        mol_id = \"\"\n    return mol_id\n\n\ndef smiles_to_unique_mol_id_batch(smiles_list):\n    mol_id_list = []\n    for smiles in smiles_list:\n        mol_id_list.append(smiles_to_unique_mol_id(smiles))\n    return mol_id_list\n</pre> rows_number_list = [250_000] batch_size_list = [10, 100, 1_000, 10_000]   def smiles_to_unique_mol_id(smiles):     try:         mol = dm.to_mol(mol=smiles)         mol_id = dm.unique_id(mol)     except:         mol_id = \"\"     if mol_id is None:         mol_id = \"\"     return mol_id   def smiles_to_unique_mol_id_batch(smiles_list):     mol_id_list = []     for smiles in smiles_list:         mol_id_list.append(smiles_to_unique_mol_id(smiles))     return mol_id_list In\u00a0[4]: Copied! <pre>benchmark = []\n</pre> benchmark = [] In\u00a0[5]: Copied! <pre>for n in rows_number_list:\n    df = data.iloc[:n]\n\n    with dm.utils.perf.watch_duration(log=False) as d:\n        out = dm.parallelized(\n            smiles_to_unique_mol_id,\n            df[\"smiles\"].values,\n            progress=True,\n            n_jobs=-1,\n            scheduler=\"processes\",\n        )\n\n    datum = {\n        \"batch\": False,\n        \"batch_size\": None,\n        \"scheduler\": \"loky_processes\",\n        \"duration_minutes\": d.duration_minutes,\n        \"duration_seconds\": d.duration,\n        \"n_rows\": len(df),\n    }\n    benchmark.append(datum)\n</pre> for n in rows_number_list:     df = data.iloc[:n]      with dm.utils.perf.watch_duration(log=False) as d:         out = dm.parallelized(             smiles_to_unique_mol_id,             df[\"smiles\"].values,             progress=True,             n_jobs=-1,             scheduler=\"processes\",         )      datum = {         \"batch\": False,         \"batch_size\": None,         \"scheduler\": \"loky_processes\",         \"duration_minutes\": d.duration_minutes,         \"duration_seconds\": d.duration,         \"n_rows\": len(df),     }     benchmark.append(datum) <pre>  0%|          | 0/133885 [00:00&lt;?, ?it/s]</pre> In\u00a0[5]: Copied! <pre>for batch_size in batch_size_list:\n    for n in rows_number_list:\n        df = data.iloc[:n]\n\n        with dm.utils.perf.watch_duration(log=False) as d:\n            out = dm.parallelized_with_batches(\n                smiles_to_unique_mol_id_batch,\n                df[\"smiles\"].values,\n                batch_size=batch_size,\n                progress=True,\n                n_jobs=-1,\n                scheduler=\"processes\",\n            )\n        assert len(out) == len(df), f\"{len(out)} != {len(df)}\"\n\n        datum = {\n            \"batch\": True,\n            \"batch_size\": batch_size,\n            \"scheduler\": \"loky_processes\",\n            \"duration_minutes\": d.duration_minutes,\n            \"duration_seconds\": d.duration,\n            \"n_rows\": len(df),\n        }\n        benchmark.append(datum)\n</pre> for batch_size in batch_size_list:     for n in rows_number_list:         df = data.iloc[:n]          with dm.utils.perf.watch_duration(log=False) as d:             out = dm.parallelized_with_batches(                 smiles_to_unique_mol_id_batch,                 df[\"smiles\"].values,                 batch_size=batch_size,                 progress=True,                 n_jobs=-1,                 scheduler=\"processes\",             )         assert len(out) == len(df), f\"{len(out)} != {len(df)}\"          datum = {             \"batch\": True,             \"batch_size\": batch_size,             \"scheduler\": \"loky_processes\",             \"duration_minutes\": d.duration_minutes,             \"duration_seconds\": d.duration,             \"n_rows\": len(df),         }         benchmark.append(datum) <pre>  0%|          | 0/13388 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/1338 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/133 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/13 [00:00&lt;?, ?it/s]</pre> In\u00a0[7]: Copied! <pre>for n in rows_number_list:\n    df = data.iloc[:n]\n\n    with dm.utils.perf.watch_duration(log=False) as d:\n        _ = df[\"smiles\"].parallel_apply(smiles_to_unique_mol_id)\n\n    datum = {\n        \"batch\": False,\n        \"batch_size\": None,\n        \"scheduler\": \"pandarallel\",\n        \"duration_minutes\": d.duration_minutes,\n        \"duration_seconds\": d.duration,\n        \"n_rows\": len(df),\n    }\n    benchmark.append(datum)\n</pre> for n in rows_number_list:     df = data.iloc[:n]      with dm.utils.perf.watch_duration(log=False) as d:         _ = df[\"smiles\"].parallel_apply(smiles_to_unique_mol_id)      datum = {         \"batch\": False,         \"batch_size\": None,         \"scheduler\": \"pandarallel\",         \"duration_minutes\": d.duration_minutes,         \"duration_seconds\": d.duration,         \"n_rows\": len(df),     }     benchmark.append(datum) <pre>VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=558), Label(value='0 / 558'))), HB\u2026</pre> In\u00a0[8]: Copied! <pre>b = pd.DataFrame(benchmark)\nb[\"duration_seconds_per_mol\"] = b[\"duration_seconds\"] / b[\"n_rows\"]\n\nb.sort_values(\"duration_seconds_per_mol\")\n</pre> b = pd.DataFrame(benchmark) b[\"duration_seconds_per_mol\"] = b[\"duration_seconds\"] / b[\"n_rows\"]  b.sort_values(\"duration_seconds_per_mol\") Out[8]: batch batch_size scheduler duration_minutes duration_seconds n_rows duration_seconds_per_mol 3 True 1000.0 loky_processes 0.014199 0.851930 133885 0.000006 2 True 100.0 loky_processes 0.037132 2.227947 133885 0.000017 4 True 10000.0 loky_processes 0.047438 2.846266 133885 0.000021 5 False NaN pandarallel 0.118230 7.093791 133885 0.000053 1 True 10.0 loky_processes 0.222177 13.330603 133885 0.000100 0 False NaN loky_processes 4.002346 240.140754 133885 0.001794 In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/basics/timing_parallel.html#setup","title":"Setup\u00b6","text":""},{"location":"tutorials/basics/timing_parallel.html#benchmarks","title":"Benchmarks\u00b6","text":""},{"location":"tutorials/basics/timing_parallel.html#no-batch","title":"No batch\u00b6","text":""},{"location":"tutorials/basics/timing_parallel.html#batch","title":"Batch\u00b6","text":""},{"location":"tutorials/basics/timing_parallel.html#pandarallel","title":"pandarallel\u00b6","text":""},{"location":"tutorials/basics/timing_parallel.html#results","title":"Results\u00b6","text":""},{"location":"tutorials/basics/using_gnn_layers.html","title":"Using GNN layers","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport torch\nimport dgl\nfrom copy import deepcopy\n\nfrom goli.nn.dgl_layers import (\n    GCNLayer,\n    GINLayer,\n    GATLayer,\n    GatedGCNLayer,\n    PNAConvolutionalLayer,\n    PNAMessagePassingLayer,\n)\n\n_ = torch.manual_seed(42)\n</pre> %load_ext autoreload %autoreload 2  import torch import dgl from copy import deepcopy  from goli.nn.dgl_layers import (     GCNLayer,     GINLayer,     GATLayer,     GatedGCNLayer,     PNAConvolutionalLayer,     PNAMessagePassingLayer, )  _ = torch.manual_seed(42) <pre>Using backend: pytorch\n</pre> <p>We will first create some simple batched graphs that will be used accross the examples. Here, <code>bg</code> is a batch of 2 graphs containing random node features <code>bg.ndata[\"h\"]</code> and edge features <code>bg.edata[\"e\"]</code>.</p> In\u00a0[2]: Copied! <pre>in_dim = 5          # Input node-feature dimensions\nout_dim = 11        # Desired output node-feature dimensions\nin_dim_edges = 13   # Input edge-feature dimensions\n\n# Let's create 2 simple graphs. Here the tensors represent the connectivity between nodes\ng1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\ng2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))\n\n# We add some node features to the graphs\ng1.ndata[\"h\"] = torch.rand(g1.num_nodes(), in_dim, dtype=float)\ng2.ndata[\"h\"] = torch.rand(g2.num_nodes(), in_dim, dtype=float)\n\n# We also add some edge features to the graphs\ng1.edata[\"e\"] = torch.rand(g1.num_edges(), in_dim_edges, dtype=float)\ng2.edata[\"e\"] = torch.rand(g2.num_edges(), in_dim_edges, dtype=float)\n\n# Finally we batch the graphs in a way compatible with the DGL library\nbg = dgl.batch([g1, g2])\nbg = dgl.add_self_loop(bg)\n\n# The batched graph will show as a single graph with 7 nodes\nprint(bg)\n</pre> in_dim = 5          # Input node-feature dimensions out_dim = 11        # Desired output node-feature dimensions in_dim_edges = 13   # Input edge-feature dimensions  # Let's create 2 simple graphs. Here the tensors represent the connectivity between nodes g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))) g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))  # We add some node features to the graphs g1.ndata[\"h\"] = torch.rand(g1.num_nodes(), in_dim, dtype=float) g2.ndata[\"h\"] = torch.rand(g2.num_nodes(), in_dim, dtype=float)  # We also add some edge features to the graphs g1.edata[\"e\"] = torch.rand(g1.num_edges(), in_dim_edges, dtype=float) g2.edata[\"e\"] = torch.rand(g2.num_edges(), in_dim_edges, dtype=float)  # Finally we batch the graphs in a way compatible with the DGL library bg = dgl.batch([g1, g2]) bg = dgl.add_self_loop(bg)  # The batched graph will show as a single graph with 7 nodes print(bg)  <pre>Graph(num_nodes=7, num_edges=14,\n      ndata_schemes={'h': Scheme(shape=(5,), dtype=torch.float64)}\n      edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float64)})\n</pre> In\u00a0[3]: Copied! <pre># We first need to extract the node features from the graph.\n# The GCN method doesn't support edge features, so we ignore them\ngraph = deepcopy(bg)\nh_in = graph.ndata[\"h\"]\n\n# We create the layer\nlayer = GCNLayer(\n            in_dim=in_dim, out_dim=out_dim, \n            activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)\n\n# We apply the forward loop on the node features\nh_out = layer(graph, h_in)\n\n# 7 is the number of nodes, 5 number of input features and 11 number of output features\nprint(layer)\nprint(h_in.shape)\nprint(h_out.shape)\n</pre> # We first need to extract the node features from the graph. # The GCN method doesn't support edge features, so we ignore them graph = deepcopy(bg) h_in = graph.ndata[\"h\"]  # We create the layer layer = GCNLayer(             in_dim=in_dim, out_dim=out_dim,              activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)  # We apply the forward loop on the node features h_out = layer(graph, h_in)  # 7 is the number of nodes, 5 number of input features and 11 number of output features print(layer) print(h_in.shape) print(h_out.shape) <pre>GCNLayer(5 -&gt; 11, activation=relu)\ntorch.Size([7, 5])\ntorch.Size([7, 11])\n</pre> In\u00a0[4]: Copied! <pre>graph = deepcopy(bg)\nh_in = graph.ndata[\"h\"]\nlayer = GINLayer(\n            in_dim=in_dim, out_dim=out_dim, \n            activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)\nh_out = layer(graph, h_in)\n\nprint(layer)\nprint(h_in.shape)\nprint(h_out.shape)\n</pre> graph = deepcopy(bg) h_in = graph.ndata[\"h\"] layer = GINLayer(             in_dim=in_dim, out_dim=out_dim,              activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float) h_out = layer(graph, h_in)  print(layer) print(h_in.shape) print(h_out.shape) <pre>GINLayer(5 -&gt; 11, activation=relu)\ntorch.Size([7, 5])\ntorch.Size([7, 11])\n</pre> In\u00a0[5]: Copied! <pre>graph = deepcopy(bg)\nh_in = graph.ndata[\"h\"]\nlayer = GATLayer(\n            in_dim=in_dim, out_dim=out_dim, num_heads=5,\n            activation=\"elu\", dropout=.3, normalization=\"batch_norm\").to(float)\nh_out = layer(graph, h_in)\n\nprint(layer)\nprint(h_in.shape)\nprint(h_out.shape)\n</pre> graph = deepcopy(bg) h_in = graph.ndata[\"h\"] layer = GATLayer(             in_dim=in_dim, out_dim=out_dim, num_heads=5,             activation=\"elu\", dropout=.3, normalization=\"batch_norm\").to(float) h_out = layer(graph, h_in)  print(layer) print(h_in.shape) print(h_out.shape) <pre>GATLayer(5 -&gt; 11 * 5, activation=elu)\ntorch.Size([7, 5])\ntorch.Size([7, 55])\n</pre> In\u00a0[6]: Copied! <pre># We first need to extract the node and edge features from the graph.\ngraph = deepcopy(bg)\nh_in = graph.ndata[\"h\"]\ne_in = graph.edata[\"e\"]\n\n# We create the layer\nlayer = GatedGCNLayer(\n        in_dim=in_dim, out_dim=out_dim, \n        in_dim_edges=in_dim_edges, out_dim_edges=out_dim,\n        activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)\n\n# We apply the forward loop on the node features\nh_out, e_out = layer(graph, h_in, e_in)\n\n# 7 is the number of nodes, 5 number of input features and 11 number of output features\n# 13 is the number of input edge features\nprint(layer)\nprint(h_in.shape)\nprint(h_out.shape)\nprint(e_in.shape)\nprint(e_out.shape)\n</pre> # We first need to extract the node and edge features from the graph. graph = deepcopy(bg) h_in = graph.ndata[\"h\"] e_in = graph.edata[\"e\"]  # We create the layer layer = GatedGCNLayer(         in_dim=in_dim, out_dim=out_dim,          in_dim_edges=in_dim_edges, out_dim_edges=out_dim,         activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)  # We apply the forward loop on the node features h_out, e_out = layer(graph, h_in, e_in)  # 7 is the number of nodes, 5 number of input features and 11 number of output features # 13 is the number of input edge features print(layer) print(h_in.shape) print(h_out.shape) print(e_in.shape) print(e_out.shape) <pre>GatedGCNLayer(5 -&gt; 11, activation=relu)\ntorch.Size([7, 5])\ntorch.Size([7, 11])\ntorch.Size([14, 13])\ntorch.Size([14, 11])\n</pre> In\u00a0[7]: Copied! <pre>graph = deepcopy(bg)\nh_in = graph.ndata[\"h\"]\n\n# We create the layer, and need to specify the aggregators and scalers\nlayer = PNAConvolutionalLayer(\n    in_dim=in_dim, out_dim=out_dim, \n    aggregators=[\"mean\", \"max\", \"min\", \"std\"],\n    scalers=[\"identity\", \"amplification\", \"attenuation\"],\n    activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)\n\nh_out = layer(graph, h_in)\n\nprint(layer)\nprint(h_in.shape)\nprint(h_out.shape)\n</pre> graph = deepcopy(bg) h_in = graph.ndata[\"h\"]  # We create the layer, and need to specify the aggregators and scalers layer = PNAConvolutionalLayer(     in_dim=in_dim, out_dim=out_dim,      aggregators=[\"mean\", \"max\", \"min\", \"std\"],     scalers=[\"identity\", \"amplification\", \"attenuation\"],     activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)  h_out = layer(graph, h_in)  print(layer) print(h_in.shape) print(h_out.shape) <pre>PNAConvolutionalLayer(5 -&gt; 11, activation=relu)\ntorch.Size([7, 5])\ntorch.Size([7, 11])\n</pre> In\u00a0[8]: Copied! <pre>graph = deepcopy(bg)\nh_in = graph.ndata[\"h\"]\ne_in = graph.edata[\"e\"]\n\n# We create the layer, and need to specify the aggregators and scalers\nlayer = PNAMessagePassingLayer(\n    in_dim=in_dim, out_dim=out_dim, in_dim_edges=in_dim_edges,\n    aggregators=[\"mean\", \"max\", \"min\", \"std\"],\n    scalers=[\"identity\", \"amplification\", \"attenuation\"],\n    activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)\n\nh_out = layer(graph, h_in, e_in)\n\nprint(layer)\nprint(h_in.shape)\nprint(h_out.shape)\n</pre> graph = deepcopy(bg) h_in = graph.ndata[\"h\"] e_in = graph.edata[\"e\"]  # We create the layer, and need to specify the aggregators and scalers layer = PNAMessagePassingLayer(     in_dim=in_dim, out_dim=out_dim, in_dim_edges=in_dim_edges,     aggregators=[\"mean\", \"max\", \"min\", \"std\"],     scalers=[\"identity\", \"amplification\", \"attenuation\"],     activation=\"relu\", dropout=.3, normalization=\"batch_norm\").to(float)  h_out = layer(graph, h_in, e_in)  print(layer) print(h_in.shape) print(h_out.shape) <pre>PNAMessagePassingLayer(5 -&gt; 11, activation=relu)\ntorch.Size([7, 5])\ntorch.Size([7, 11])\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/basics/using_gnn_layers.html#using-gnn-layers","title":"Using GNN layers\u00b6","text":"<p>The current library implements multiple state-of-the-art graph neural networks. In this tutorial, you will learn how to use the GCN, GIN, Gated-GCN and PNA layers in a simple <code>forward</code> context.</p> <p>Other layers such as DGN require additional positional encoding to work.</p>"},{"location":"tutorials/basics/using_gnn_layers.html#gcn-layer","title":"GCN Layer\u00b6","text":"<p>To use the GCN layer from the Kipf et al. paper, the steps are very simple. We create the layer with the desired attributes, and apply it to the graph.</p> <p>Kipf, Thomas N., and Max Welling. \"Semi-supervised classification with graph convolutional networks.\" arXiv preprint arXiv:1609.02907 (2016).</p>"},{"location":"tutorials/basics/using_gnn_layers.html#gin-layer","title":"GIN Layer\u00b6","text":"<p>To use the GIN layer from the Xu et al. paper, the steps are identical to GCN.</p> <p>Xu, Keyulu, et al. \"How powerful are graph neural networks?.\" arXiv preprint arXiv:1810.00826 (2018).</p>"},{"location":"tutorials/basics/using_gnn_layers.html#gat-layer","title":"GAT Layer\u00b6","text":"<p>To use the GAT layer from the Velickovic et al. paper, the steps are identical to GCN, but the output dimension is multiplied by the number of heads.</p> <p>Velickovic, Petar, et al. \"Graph attention networks.\" arXiv preprint arXiv:1710.10903 (2017).</p>"},{"location":"tutorials/basics/using_gnn_layers.html#gated-gcn-layer","title":"Gated-GCN Layer\u00b6","text":"<p>To use the Gated-GCN layer from the Bresson et al. paper, the steps are different since the layer requires edge features as inputs, and outputs new edge features.</p> <p>Bresson, Xavier, and Thomas Laurent. \"Residual gated graph convnets.\" arXiv preprint arXiv:1711.07553 (2017).</p>"},{"location":"tutorials/basics/using_gnn_layers.html#pna","title":"PNA\u00b6","text":"<p>PNA is a multi-aggregator method proposed by Corso et al.. It supports 2 types of aggregations, convolutional PNA-conv or message passing PNA-msgpass.</p> <p>PNA: Principal Neighbourhood Aggregation  Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Lio, Petar Velickovic https://arxiv.org/abs/2004.05718</p>"},{"location":"tutorials/basics/using_gnn_layers.html#pna-conv","title":"PNA-conv\u00b6","text":"<p>First, let's focus on the PNA-conv. In this case, it works exactly as the GCN and GIN methods. Although not presented in the example, PNA-conv also supports edge features by concatenating them to the node features during convolution.</p>"},{"location":"tutorials/basics/using_gnn_layers.html#pna-msgpass","title":"PNA-msgpass\u00b6","text":"<p>The PNA message passing is typically more powerful that the convolutional one, and it supports edges as inputs, but doesn't output edges. It's usage is very similar to the PNA-conv. Here, we also present the option to specify the edge dimensions and features.</p>"},{"location":"tutorials/model_training/ipu_training.html","title":"Building and training on IPU from configurations","text":"In\u00a0[1]: Copied! <pre>from os.path import dirname, join\nimport goli\nGOLI_PATH = dirname(dirname(goli.__file__))\nwith open(join(GOLI_PATH, \"expts/configs/ipu.config\")) as f:\n    lines = f.readlines()\nprint(\"\".join(lines))\n</pre> from os.path import dirname, join import goli GOLI_PATH = dirname(dirname(goli.__file__)) with open(join(GOLI_PATH, \"expts/configs/ipu.config\")) as f:     lines = f.readlines() print(\"\".join(lines)) <pre>deviceIterations(16)\nreplicationFactor(1)\nTraining.gradientAccumulation(1)    # How many gradient steps to accumulate\nmodelName(\"reproduce_mixed\")        # TODO: Use the name from the main file, and add date/time\nenableProfiling(\"pro_vision\")       # The folder where the profile will be stored\nJit.traceModel(True)\nenableExecutableCaching(\"pop_compiler_cache\")\n\n</pre> In\u00a0[2]: Copied! <pre>import yaml\nimport omegaconf\n</pre> import yaml import omegaconf In\u00a0[3]: Copied! <pre>def print_config_with_key(config, key):\n    new_config = {key: config[key]}\n    print(omegaconf.OmegaConf.to_yaml(new_config))\n</pre> def print_config_with_key(config, key):     new_config = {key: config[key]}     print(omegaconf.OmegaConf.to_yaml(new_config)) In\u00a0[4]: Copied! <pre># First, let's read the yaml configuration file\nwith open(\"config_ipu_tutorials.yaml\", \"r\") as file:\n    yaml_config = yaml.load(file, Loader=yaml.FullLoader)\n\nprint(\"Yaml file loaded\")\n</pre> # First, let's read the yaml configuration file with open(\"config_ipu_tutorials.yaml\", \"r\") as file:     yaml_config = yaml.load(file, Loader=yaml.FullLoader)  print(\"Yaml file loaded\") <pre>Yaml file loaded\n</pre> In\u00a0[5]: Copied! <pre>print_config_with_key(yaml_config, \"constants\")\n</pre> print_config_with_key(yaml_config, \"constants\") <pre>constants:\n  name: tutorial_model\n  seed: 42\n  raise_train_error: true\n  accelerator:\n    type: ipu\n\n</pre> In\u00a0[6]: Copied! <pre>print_config_with_key(yaml_config[\"datamodule\"][\"args\"][\"task_specific_args\"], \"homo\")\n</pre> print_config_with_key(yaml_config[\"datamodule\"][\"args\"][\"task_specific_args\"], \"homo\") <pre>homo:\n  df: null\n  df_path: https://storage.googleapis.com/goli-public/datasets/QM9/norm_micro_qm9.csv\n  smiles_col: smiles\n  label_cols:\n  - homo\n  - lumo\n  split_val: 0.2\n  split_test: 0.2\n  split_seed: 42\n  splits_path: null\n  sample_size: null\n  idx_col: null\n  weights_col: null\n  weights_type: null\n\n</pre> In\u00a0[7]: Copied! <pre>print_config_with_key(yaml_config[\"datamodule\"][\"args\"], \"featurization\")\n</pre> print_config_with_key(yaml_config[\"datamodule\"][\"args\"], \"featurization\") <pre>featurization:\n  atom_property_list_onehot:\n  - atomic-number\n  - valence\n  atom_property_list_float:\n  - mass\n  - electronegativity\n  - in-ring\n  edge_property_list:\n  - bond-type-onehot\n  - stereo\n  - in-ring\n  add_self_loop: false\n  explicit_H: false\n  use_bonds_weights: false\n  pos_encoding_as_features:\n    pos_types:\n      la_pos:\n        pos_type: laplacian_eigvec_eigval\n        num_pos: 3\n        normalization: none\n        disconnected_comp: true\n      rw_pos:\n        pos_type: rwse\n        ksteps: 16\n\n</pre> In\u00a0[8]: Copied! <pre>print_config_with_key(yaml_config[\"architecture\"], \"pre_nn\")\n</pre> print_config_with_key(yaml_config[\"architecture\"], \"pre_nn\") <pre>pre_nn:\n  out_dim: 32\n  hidden_dims: 32\n  depth: 1\n  activation: relu\n  last_activation: none\n  dropout: 0.1\n  normalization: none\n  last_normalization: none\n  residual_type: none\n\n</pre> In\u00a0[9]: Copied! <pre>print_config_with_key(yaml_config[\"architecture\"], \"pre_nn_edges\")\n</pre> print_config_with_key(yaml_config[\"architecture\"], \"pre_nn_edges\") <pre>pre_nn_edges:\n  out_dim: 16\n  hidden_dims: 16\n  depth: 1\n  activation: relu\n  last_activation: none\n  dropout: 0.1\n  normalization: none\n  last_normalization: none\n  residual_type: none\n\n</pre> In\u00a0[10]: Copied! <pre>print_config_with_key(yaml_config[\"architecture\"], \"gnn\")\n</pre> print_config_with_key(yaml_config[\"architecture\"], \"gnn\") <pre>gnn:\n  out_dim: 32\n  hidden_dims: 32\n  depth: 3\n  activation: relu\n  last_activation: none\n  dropout: 0.1\n  normalization: none\n  last_normalization: none\n  residual_type: simple\n  pooling:\n  - sum\n  - mean\n  - max\n  virtual_node: none\n  layer_type: pyg:gps\n  layer_kwargs:\n    mpnn_type: pyg:gine\n    mpnn_kwargs: null\n    attn_type: full-attention\n    attn_kwargs: null\n\n</pre> In\u00a0[11]: Copied! <pre>print_config_with_key(yaml_config[\"architecture\"], \"post_nn\")\n</pre> print_config_with_key(yaml_config[\"architecture\"], \"post_nn\") <pre>post_nn:\n  out_dim: 32\n  hidden_dims: 32\n  depth: 1\n  activation: relu\n  last_activation: none\n  dropout: 0.1\n  normalization: none\n  last_normalization: none\n  residual_type: none\n\n</pre> In\u00a0[12]: Copied! <pre>print_config_with_key(yaml_config[\"architecture\"], \"task_heads\")\n</pre> print_config_with_key(yaml_config[\"architecture\"], \"task_heads\")  <pre>task_heads:\n- task_name: homo\n  out_dim: 2\n  hidden_dims: 32\n  depth: 2\n  activation: relu\n  last_activation: none\n  dropout: 0.1\n  normalization: none\n  last_normalization: none\n  residual_type: none\n- task_name: alpha\n  out_dim: 1\n  hidden_dims: 32\n  depth: 2\n  activation: relu\n  last_activation: none\n  dropout: 0.1\n  normalization: none\n  last_normalization: none\n  residual_type: none\n- task_name: cv\n  out_dim: 1\n  hidden_dims: 32\n  depth: 2\n  activation: relu\n  last_activation: none\n  dropout: 0.1\n  normalization: none\n  last_normalization: none\n  residual_type: none\n\n</pre> In\u00a0[13]: Copied! <pre>print_config_with_key(yaml_config, \"predictor\")\n</pre> print_config_with_key(yaml_config, \"predictor\") <pre>predictor:\n  metrics_on_progress_bar:\n    homo:\n    - mae\n    - pearsonr\n    alpha:\n    - mae\n    cv:\n    - mae\n    - pearsonr\n  loss_fun:\n    homo: mse_ipu\n    alpha: mse_ipu\n    cv: mse_ipu\n  random_seed: 42\n  optim_kwargs:\n    lr: 0.001\n  torch_scheduler_kwargs: null\n  scheduler_kwargs: null\n  target_nan_mask: null\n  flag_kwargs:\n    n_steps: 0\n    alpha: 0.0\n\n</pre> In\u00a0[14]: Copied! <pre>print_config_with_key(yaml_config, \"metrics\")\n</pre> print_config_with_key(yaml_config, \"metrics\") <pre>metrics:\n  homo:\n  - name: mae\n    metric: mae\n    threshold_kwargs: null\n  - name: pearsonr\n    metric: pearsonr\n    threshold_kwargs: null\n    target_nan_mask: ignore-mean-label\n  alpha:\n  - name: mae\n    metric: mae\n    threshold_kwargs: null\n  - name: pearsonr\n    metric: pearsonr\n    threshold_kwargs: null\n  cv:\n  - name: mae\n    metric: mae\n    threshold_kwargs: null\n  - name: pearsonr\n    metric: pearsonr\n    threshold_kwargs: null\n\n</pre> In\u00a0[15]: Copied! <pre>print_config_with_key(yaml_config, \"trainer\")\n</pre> print_config_with_key(yaml_config, \"trainer\") <pre>trainer:\n  logger:\n    save_dir: logs/QM9\n    name: tutorial_model\n  model_checkpoint:\n    dirpath: models_checkpoints/QM9/\n    filename: tutorial_model\n    save_top_k: 1\n    every_n_epochs: 1\n  trainer:\n    precision: 32\n    max_epochs: 5\n    min_epochs: 1\n\n</pre> In\u00a0[16]: Copied! <pre># General imports\nimport os\nfrom os.path import dirname, abspath\nimport yaml\nfrom copy import deepcopy\nfrom omegaconf import DictConfig\nimport timeit\nfrom loguru import logger\nfrom pytorch_lightning.utilities.model_summary import ModelSummary\n\n# Current project imports\nimport goli\nfrom goli.config._loader import load_datamodule, load_metrics, load_architecture, load_predictor, load_trainer\nfrom goli.utils.safe_run import SafeRun\n\n# WandB\nimport wandb\n</pre> # General imports import os from os.path import dirname, abspath import yaml from copy import deepcopy from omegaconf import DictConfig import timeit from loguru import logger from pytorch_lightning.utilities.model_summary import ModelSummary  # Current project imports import goli from goli.config._loader import load_datamodule, load_metrics, load_architecture, load_predictor, load_trainer from goli.utils.safe_run import SafeRun  # WandB import wandb In\u00a0[17]: Copied! <pre># Set up the working directory\nMAIN_DIR = dirname(dirname(abspath(goli.__file__)))\nCONFIG_FILE = \"docs/tutorials/model_training/config_ipu_tutorials.yaml\"\nos.chdir(MAIN_DIR)\n\nwith open(os.path.join(MAIN_DIR, CONFIG_FILE), \"r\") as f:\n    cfg = yaml.safe_load(f)\n</pre>  # Set up the working directory MAIN_DIR = dirname(dirname(abspath(goli.__file__))) CONFIG_FILE = \"docs/tutorials/model_training/config_ipu_tutorials.yaml\" os.chdir(MAIN_DIR)  with open(os.path.join(MAIN_DIR, CONFIG_FILE), \"r\") as f:     cfg = yaml.safe_load(f) In\u00a0[18]: Copied! <pre># Load and initialize the dataset\ndatamodule = load_datamodule(cfg)\ndatamodule.prepare_data()\n</pre> # Load and initialize the dataset datamodule = load_datamodule(cfg) datamodule.prepare_data() <pre>[17:16:35.918] [poptorch::python] [warning] trace_model=True is deprecated since version 3.0 and will be removed in a future release\n2022-09-20 17:16:35.920 | INFO     | goli.data.datamodule:prepare_data:699 - Reading data for task 'homo'\n2022-09-20 17:16:36.462 | INFO     | goli.data.datamodule:prepare_data:699 - Reading data for task 'alpha'\n2022-09-20 17:16:36.585 | INFO     | goli.data.datamodule:prepare_data:699 - Reading data for task 'cv'\n2022-09-20 17:16:36.707 | INFO     | goli.data.datamodule:prepare_data:721 - Done reading datasets\n2022-09-20 17:16:36.707 | INFO     | goli.data.datamodule:prepare_data:733 - Prepare single-task dataset for task 'homo' with 1005 data points.\n2022-09-20 17:16:36.708 | INFO     | goli.data.datamodule:prepare_data:733 - Prepare single-task dataset for task 'alpha' with 1005 data points.\n2022-09-20 17:16:36.709 | INFO     | goli.data.datamodule:prepare_data:733 - Prepare single-task dataset for task 'cv' with 1005 data points.\n</pre> <pre>mols to ids:   0%|          | 0/3015 [00:00&lt;?, ?it/s]</pre> <pre>featurizing_smiles:   0%|          | 0/1005 [00:00&lt;?, ?it/s]</pre> In\u00a0[19]: Copied! <pre># Initialize the network\nmodel_class, model_kwargs = load_architecture(\n    cfg,\n    in_dims=datamodule.in_dims,\n)\n\nmetrics = load_metrics(cfg)\nlogger.info(metrics)\n\npredictor = load_predictor(cfg, model_class, model_kwargs, metrics)\npredictor.set_max_nodes_edges_per_graph(datamodule, stages=[\"train\", \"val\"])\n\nlogger.info(predictor.model)\nlogger.info(ModelSummary(predictor, max_depth=4))\n\ntrainer = load_trainer(cfg, \"tutorial-run\")\n</pre> # Initialize the network model_class, model_kwargs = load_architecture(     cfg,     in_dims=datamodule.in_dims, )  metrics = load_metrics(cfg) logger.info(metrics)  predictor = load_predictor(cfg, model_class, model_kwargs, metrics) predictor.set_max_nodes_edges_per_graph(datamodule, stages=[\"train\", \"val\"])  logger.info(predictor.model) logger.info(ModelSummary(predictor, max_depth=4))  trainer = load_trainer(cfg, \"tutorial-run\") <pre>2022-09-20 17:16:46.768 | INFO     | __main__:&lt;cell line: 8&gt;:8 - {'homo': {'mae': mean_absolute_error, 'pearsonr': pearson_corrcoef}, 'alpha': {'mae': mean_absolute_error, 'pearsonr': pearson_corrcoef}, 'cv': {'mae': mean_absolute_error, 'pearsonr': pearson_corrcoef}}\n2022-09-20 17:16:46.812 | INFO     | __main__:&lt;cell line: 12&gt;:12 - Multitask_GNN\n---------------\n    pre-NN(depth=1, ResidualConnectionNone)\n        [FCLayer[87 -&gt; 32]\n    \n    pre-NN-edges(depth=1, ResidualConnectionNone)\n        [FCLayer[13 -&gt; 16]\n    \n    GNN(depth=3, ResidualConnectionSimple(skip_steps=1))\n        GPSLayerPyg[32 -&gt; 32 -&gt; 32 -&gt; 32]\n        -&gt; Pooling(['sum', 'mean', 'max']) -&gt; FCLayer(96 -&gt; 32, activation=None)\n    \n    post-NN(depth=1, ResidualConnectionNone)\n        [FCLayer[32 -&gt; 32]\n2022-09-20 17:16:46.813 | INFO     | __main__:&lt;cell line: 13&gt;:13 -    | Name                                | Type                      | Params\n-----------------------------------------------------------------------------------\n0  | model                               | FullGraphMultiTaskNetwork | 47.6 K\n1  | model.pe_encoders                   | ModuleDict                | 681   \n2  | model.pe_encoders.la_pos            | LapPENodeEncoder          | 137   \n3  | model.pe_encoders.la_pos.linear_A   | Linear                    | 9     \n4  | model.pe_encoders.la_pos.pe_encoder | MLP                       | 128   \n5  | model.pe_encoders.rw_pos            | MLPEncoder                | 544   \n6  | model.pe_encoders.rw_pos.pe_encoder | MLP                       | 544   \n7  | model.pre_nn                        | FeedForwardNN             | 2.8 K \n8  | model.pre_nn.activation             | ReLU                      | 0     \n9  | model.pre_nn.residual_layer         | ResidualConnectionNone    | 0     \n10 | model.pre_nn.layers                 | ModuleList                | 2.8 K \n11 | model.pre_nn.layers.0               | FCLayer                   | 2.8 K \n12 | model.pre_nn_edges                  | FeedForwardNN             | 224   \n13 | model.pre_nn_edges.activation       | ReLU                      | 0     \n14 | model.pre_nn_edges.residual_layer   | ResidualConnectionNone    | 0     \n15 | model.pre_nn_edges.layers           | ModuleList                | 224   \n16 | model.pre_nn_edges.layers.0         | FCLayer                   | 224   \n17 | model.gnn                           | FeedForwardPyg            | 39.5 K\n18 | model.gnn.activation                | ReLU                      | 0     \n19 | model.gnn.layers                    | ModuleList                | 36.4 K\n20 | model.gnn.layers.0                  | GPSLayerPyg               | 12.1 K\n21 | model.gnn.layers.1                  | GPSLayerPyg               | 12.1 K\n22 | model.gnn.layers.2                  | GPSLayerPyg               | 12.1 K\n23 | model.gnn.virtual_node_layers       | ModuleList                | 0     \n24 | model.gnn.virtual_node_layers.0     | VirtualNodePyg            | 0     \n25 | model.gnn.virtual_node_layers.1     | VirtualNodePyg            | 0     \n26 | model.gnn.residual_layer            | ResidualConnectionSimple  | 0     \n27 | model.gnn.global_pool_layer         | ModuleListConcat          | 0     \n28 | model.gnn.global_pool_layer.0       | PoolingWrapperPyg         | 0     \n29 | model.gnn.global_pool_layer.1       | PoolingWrapperPyg         | 0     \n30 | model.gnn.global_pool_layer.2       | PoolingWrapperPyg         | 0     \n31 | model.gnn.out_linear                | FCLayer                   | 3.1 K \n32 | model.gnn.out_linear.linear         | Linear                    | 3.1 K \n33 | model.gnn.out_linear.dropout        | Dropout                   | 0     \n34 | model.post_nn                       | FeedForwardNN             | 1.1 K \n35 | model.post_nn.activation            | ReLU                      | 0     \n36 | model.post_nn.residual_layer        | ResidualConnectionNone    | 0     \n37 | model.post_nn.layers                | ModuleList                | 1.1 K \n38 | model.post_nn.layers.0              | FCLayer                   | 1.1 K \n39 | model.task_heads                    | TaskHeads                 | 3.3 K \n40 | model.task_heads.task_heads         | ModuleDict                | 3.3 K \n41 | model.task_heads.task_heads.homo    | TaskHead                  | 1.1 K \n42 | model.task_heads.task_heads.alpha   | TaskHead                  | 1.1 K \n43 | model.task_heads.task_heads.cv      | TaskHead                  | 1.1 K \n-----------------------------------------------------------------------------------\n47.6 K    Trainable params\n0         Non-trainable params\n47.6 K    Total params\n0.190     Total estimated model params size (MB)\n[17:16:46.843] [poptorch::python] [warning] trace_model=True is deprecated since version 3.0 and will be removed in a future release\n/home/dom/.venv/goli_ipu/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ipu.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ipu.IPUPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ipu.IPUStrategy` instead.\n  rank_zero_deprecation(\nFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\nwandb: Currently logged in as: dbeaini_mila (multitask-gnn). Use `wandb login --relogin` to force relogin\n</pre>  wandb version 0.13.3 is available!  To upgrade, please run:  $ pip install wandb --upgrade   Tracking run with wandb version 0.13.2   Run data is saved locally in <code>/home/dom/goli/wandb/run-20220920_171648-1ss172i9</code>  Syncing run tutorial-run to Weights &amp; Biases (docs) <pre>/home/dom/.venv/goli_ipu/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing &lt;goli.ipu.ipu_wrapper.IPUPluginGoli object at 0x7f4431dfc220&gt; `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=&lt;goli.ipu.ipu_wrapper.IPUPluginGoli object at 0x7f4431dfc220&gt;)` instead.\n  rank_zero_deprecation(\n/home/dom/.venv/goli_ipu/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:469: UserWarning: more than one device specific flag has been set\n  rank_zero_warn(\"more than one device specific flag has been set\")\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nIPU available: True, using: 1 IPUs\nHPU available: False, using: 0 HPUs\n</pre> In\u00a0[20]: Copied! <pre># Run the model training\nwith SafeRun(name=\"TRAINING\", raise_error=cfg[\"constants\"][\"raise_train_error\"], verbose=True):\n    trainer.fit(model=predictor, datamodule=datamodule)\n\n# Exit WandB\nwandb.finish()\n</pre> # Run the model training with SafeRun(name=\"TRAINING\", raise_error=cfg[\"constants\"][\"raise_train_error\"], verbose=True):     trainer.fit(model=predictor, datamodule=datamodule)  # Exit WandB wandb.finish() <pre>/home/dom/.venv/goli_ipu/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:326: LightningDeprecationWarning: Base `LightningModule.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n  rank_zero_deprecation(\n/home/dom/.venv/goli_ipu/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:154: LightningDeprecationWarning: The `LightningModule.get_progress_bar_dict` method was deprecated in v1.5 and will be removed in v1.7. Please use the `ProgressBarBase.get_metrics` instead.\n  rank_zero_deprecation(\n</pre> <pre>mols to ids:   0%|          | 0/1809 [00:00&lt;?, ?it/s]</pre> <pre>mols to ids:   0%|          | 0/603 [00:00&lt;?, ?it/s]</pre> <pre>/home/dom/.venv/goli_ipu/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/dom/goli/models_checkpoints/QM9 exists and is not empty.\n  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n\n  | Name  | Type                      | Params\n----------------------------------------------------\n0 | model | FullGraphMultiTaskNetwork | 47.6 K\n----------------------------------------------------\n47.6 K    Trainable params\n0         Non-trainable params\n47.6 K    Total params\n0.190     Total estimated model params size (MB)\n</pre> <pre>-------------------\nMultitaskDataset\n\tabout = training set\n\tnum_graphs_total = 603\n\tnum_nodes_total = 5285\n\tmax_num_nodes_per_graph = 9\n\tmin_num_nodes_per_graph = 1\n\tstd_num_nodes_per_graph = 0.6989218547197285\n\tmean_num_nodes_per_graph = 8.764510779436153\n\tnum_edges_total = 11316\n\tmax_num_edges_per_graph = 26\n\tmin_num_edges_per_graph = 0\n\tstd_num_edges_per_graph = 2.6821780989470896\n\tmean_num_edges_per_graph = 18.766169154228855\n-------------------\n\n-------------------\nMultitaskDataset\n\tabout = validation set\n\tnum_graphs_total = 201\n\tnum_nodes_total = 1756\n\tmax_num_nodes_per_graph = 9\n\tmin_num_nodes_per_graph = 2\n\tstd_num_nodes_per_graph = 0.7949619835770694\n\tmean_num_nodes_per_graph = 8.7363184079602\n\tnum_edges_total = 3736\n\tmax_num_edges_per_graph = 24\n\tmin_num_edges_per_graph = 2\n\tstd_num_edges_per_graph = 2.7704251592456193\n\tmean_num_edges_per_graph = 18.587064676616915\n-------------------\n\n</pre> <pre>Sanity Checking: 0it [00:00, ?it/s]</pre> <pre>2022-09-20 17:16:59.088 | INFO     | goli.ipu.ipu_dataloader:create_ipu_dataloader:230 - Estimating pack max_pack_size=54 or max_pack_size_per_graph=9.0\n2022-09-20 17:16:59.089 | INFO     | goli.ipu.ipu_dataloader:create_ipu_dataloader:233 - Provided `max_num_nodes=72`\n[17:17:02.052] [poptorch:cpp] [warning] Graph contains an unused input %this_input : Long(1, strides=[1], requires_grad=0, device=cpu)\n[17:17:02.054] [poptorch:cpp] [warning] %value.3 : Long(2, 144, strides=[144, 1], requires_grad=0, device=cpu) = aten::to(%tensor.1, %111, %112, %113, %114) # /home/dom/.venv/goli_ipu/lib/python3.8/site-packages/poptorch/_poplar_executor.py:1315:0: torch.int64 is not supported natively on IPU, loss of range/precision may occur. We will only warn on the first instance.\nGraph compilation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:01&lt;00:00]\n2022-09-20 17:17:07.541 | INFO     | goli.ipu.ipu_dataloader:create_ipu_dataloader:230 - Estimating pack max_pack_size=54 or max_pack_size_per_graph=9.0\n2022-09-20 17:17:07.542 | INFO     | goli.ipu.ipu_dataloader:create_ipu_dataloader:233 - Provided `max_num_nodes=72`\n/home/dom/.venv/goli_ipu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n  rank_zero_warn(\n</pre> <pre>Training: 0it [00:00, ?it/s]</pre> <pre>/home/dom/goli/goli/ipu/ipu_wrapper.py:274: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if all([this_input.shape[0] == 1 for this_input in inputs]):\n/home/dom/goli/goli/ipu/ipu_wrapper.py:307: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  batch_idx = batch.pop(\"_batch_idx\").item()\n/home/dom/goli/goli/nn/base_layers.py:169: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n  if torch.prod(torch.as_tensor(h.shape[:-1])) == 0:\n/home/dom/goli/goli/nn/base_layers.py:169: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if torch.prod(torch.as_tensor(h.shape[:-1])) == 0:\n/home/dom/goli/goli/nn/architectures/pyg_architectures.py:139: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  assert node_feats.shape[0] == g.num_nodes\n/home/dom/goli/goli/nn/architectures/pyg_architectures.py:154: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  assert edge_feats.shape[0] == g.num_edges\n/home/dom/goli/goli/nn/architectures/global_architectures.py:1190: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n  if torch.prod(torch.as_tensor(e.shape[:-1])) == 0:\n/home/dom/goli/goli/nn/architectures/global_architectures.py:1190: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if torch.prod(torch.as_tensor(e.shape[:-1])) == 0:\n/home/dom/goli/goli/nn/base_graph_layer.py:277: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  assert edge_index.min() &gt;= 0\n/home/dom/goli/goli/nn/base_graph_layer.py:278: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  assert edge_index.max() &lt; torch.iinfo(edge_index.dtype).max\n/home/dom/goli/goli/nn/base_graph_layer.py:281: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  assert edge_index.size(0) == 2\n/home/dom/goli/goli/nn/pyg_layers/gps_pyg.py:144: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  on_ipu = (\"graph_is_true\" in batch.keys) and (not batch.graph_is_true.all())\n/home/dom/goli/goli/nn/pyg_layers/gps_pyg.py:146: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  max_num_nodes_per_graph = batch.dataset_max_nodes_per_graph[0].item()\n/home/dom/goli/goli/ipu/to_dense_batch.py:57: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  batch_size = int(batch.max()) + 1\n/home/dom/goli/goli/ipu/to_dense_batch.py:80: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  assert (\n/home/dom/goli/goli/ipu/ipu_wrapper.py:20: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if targets[task].shape == preds[task].shape:\n/home/dom/goli/goli/trainer/predictor.py:422: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n  total_norm = torch.tensor(0.0)\n/home/dom/.venv/goli_ipu/lib/python3.8/site-packages/wandb/util.py:604: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  return obj.item(), True\n[17:17:11.240] [poptorch:cpp] [warning] Graph contains an unused input %this_input : Long(1, strides=[1], requires_grad=0, device=cpu)\nGraph compilation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:02&lt;00:00]\n</pre> <pre>Validation: 0it [00:00, ?it/s]</pre> <pre>Validation: 0it [00:00, ?it/s]</pre> <pre>Validation: 0it [00:00, ?it/s]</pre> <pre>Validation: 0it [00:00, ?it/s]</pre> <pre>Validation: 0it [00:00, ?it/s]</pre>  Waiting for W&amp;B process to finish... (success). <pre>VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max\u2026</pre> Run history:alpha/MSELossIPU/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581alpha/MSELossIPU/val\u2584\u2588\u2583\u2584\u2581alpha/loss/val\u2584\u2588\u2583\u2584\u2581alpha/mae/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581alpha/mae/val\u2585\u2588\u2583\u2584\u2581alpha/mean_pred/train\u2588\u2586\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581alpha/mean_pred/val\u2584\u2588\u2582\u2582\u2581alpha/mean_target/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581alpha/mean_target/val\u2581\u2581\u2581\u2581\u2581alpha/median_pred/train\u2588\u2588\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581alpha/median_pred/val\u2581\u2588\u2583\u2583\u2581alpha/median_target/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581alpha/median_target/val\u2581\u2581\u2581\u2581\u2581alpha/pearsonr/train\u2581\u2588\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586alpha/pearsonr/val\u2581\u2587\u2586\u2587\u2588alpha/std_pred/train\u2588\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581alpha/std_pred/val\u2588\u2583\u2582\u2581\u2583alpha/std_target/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581alpha/std_target/val\u2581\u2581\u2581\u2581\u2581cv/MSELossIPU/train\u2581\u2588\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581cv/MSELossIPU/val\u2584\u2588\u2584\u2583\u2581cv/loss/val\u2584\u2588\u2584\u2583\u2581cv/mae/train\u2588\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581cv/mae/val\u2585\u2588\u2584\u2583\u2581cv/mean_pred/train\u2588\u2584\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581cv/mean_pred/val\u2581\u2588\u2585\u2584\u2582cv/mean_target/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581cv/mean_target/val\u2581\u2581\u2581\u2581\u2581cv/median_pred/train\u2588\u2582\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581cv/median_pred/val\u2581\u2588\u2584\u2583\u2582cv/median_target/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581cv/median_target/val\u2581\u2581\u2581\u2581\u2581cv/pearsonr/train\u2588\u2586\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581cv/pearsonr/val\u2581\u2587\u2586\u2588\u2588cv/std_pred/train\u2588\u2584\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581cv/std_pred/val\u2588\u2584\u2584\u2581\u2585cv/std_target/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581cv/std_target/val\u2581\u2581\u2581\u2581\u2581epoch\u2581\u2583\u2585\u2586\u2588grad_norm\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581homo/MSELossIPU/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581homo/MSELossIPU/val\u2588\u2585\u2581\u2582\u2582homo/loss/val\u2588\u2585\u2581\u2582\u2582homo/mae/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581homo/mae/val\u2588\u2585\u2581\u2583\u2583homo/mean_pred/train\u2581\u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588homo/mean_pred/val\u2581\u2588\u2584\u2584\u2584homo/mean_target/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581homo/mean_target/val\u2581\u2581\u2581\u2581\u2581homo/median_pred/train\u2588\u2581\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585homo/median_pred/val\u2581\u2585\u2584\u2587\u2588homo/median_target/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581homo/median_target/val\u2581\u2581\u2581\u2581\u2581homo/pearsonr/train\u2588\u2581\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586homo/pearsonr/val\u2588\u2588\u2588\u2585\u2581homo/std_pred/train\u2588\u2583\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581homo/std_pred/val\u2588\u2583\u2582\u2581\u2582homo/std_target/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581homo/std_target/val\u2581\u2581\u2581\u2581\u2581loss\u2581\u2581\u2581loss/train\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581loss/val\u2585\u2588\u2583\u2583\u2581train/grad_norm\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581trainer/global_step\u2581\u2581\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2587\u2586\u2587\u2587\u2587\u2588\u2588\u2588\u2588Run summary:alpha/MSELossIPU/train10.27925alpha/MSELossIPU/val0.90438alpha/loss/val0.90438alpha/mae/train1.92692alpha/mae/val0.5743alpha/mean_pred/train-0.0alpha/mean_pred/val0.05032alpha/mean_target/train-1.47591alpha/mean_target/val-0.05393alpha/median_pred/train-0.0alpha/median_pred/val0.09372alpha/median_target/train-0.81494alpha/median_target/val-0.04535alpha/pearsonr/train0.24189alpha/pearsonr/val0.70787alpha/std_pred/train0.0alpha/std_pred/val0.63476alpha/std_target/train3.11787alpha/std_target/val1.28429cv/MSELossIPU/train7.34846cv/MSELossIPU/val0.71549cv/loss/val0.71549cv/mae/train1.7832cv/mae/val0.59933cv/mean_pred/train-0.0cv/mean_pred/val0.02737cv/mean_target/train-1.33105cv/mean_target/val-0.08344cv/median_pred/train-0.0cv/median_pred/val0.08583cv/median_target/train-0.73486cv/median_target/val-0.0361cv/pearsonr/train-0.84246cv/pearsonr/val0.61503cv/std_pred/train0.0cv/std_pred/val0.60702cv/std_target/train2.58691cv/std_target/val1.06456epoch4grad_norm0.0homo/MSELossIPU/train3.00724homo/MSELossIPU/val1.10813homo/loss/val1.10813homo/mae/train0.92035homo/mae/val0.81845homo/mean_pred/train0.0homo/mean_pred/val0.02063homo/mean_target/train-0.43686homo/mean_target/val-0.0837homo/median_pred/train0.0homo/median_pred/val0.00169homo/median_target/train0.04636homo/median_target/val-0.10706homo/pearsonr/train0.01569homo/pearsonr/val0.11083homo/std_pred/train0.0homo/std_pred/val0.2037homo/std_target/train1.75284homo/std_target/val1.05716loss6.87832loss/train6.87832loss/val0.90933train/grad_norm0.0trainer/global_step29  Synced tutorial-run: https://wandb.ai/multitask-gnn/multitask-gnn/runs/1ss172i9Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)   Find logs at: <code>./wandb/run-20220920_171648-1ss172i9/logs</code> In\u00a0[21]: Copied! <pre>ckpt_path = trainer.checkpoint_callbacks[0].best_model_path\npredictor.set_max_nodes_edges_per_graph(datamodule, stages=['test'])\ntrainer.test(model=predictor, datamodule=datamodule, ckpt_path=ckpt_path)\n</pre> ckpt_path = trainer.checkpoint_callbacks[0].best_model_path predictor.set_max_nodes_edges_per_graph(datamodule, stages=['test']) trainer.test(model=predictor, datamodule=datamodule, ckpt_path=ckpt_path) <pre>/home/dom/.venv/goli_ipu/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:154: LightningDeprecationWarning: The `LightningModule.get_progress_bar_dict` method was deprecated in v1.5 and will be removed in v1.7. Please use the `ProgressBarBase.get_metrics` instead.\n  rank_zero_deprecation(\n</pre> <pre>mols to ids:   0%|          | 0/603 [00:00&lt;?, ?it/s]</pre> <pre>Restoring states from the checkpoint path at /home/dom/goli/models_checkpoints/QM9/tutorial_model.ckpt\nLoaded model weights from checkpoint at /home/dom/goli/models_checkpoints/QM9/tutorial_model.ckpt\n2022-09-20 17:18:37.268 | INFO     | goli.ipu.ipu_dataloader:create_ipu_dataloader:230 - Estimating pack max_pack_size=54 or max_pack_size_per_graph=9.0\n2022-09-20 17:18:37.268 | INFO     | goli.ipu.ipu_dataloader:create_ipu_dataloader:233 - Provided `max_num_nodes=72`\n</pre> <pre>-------------------\nMultitaskDataset\n\tabout = test set\n\tnum_graphs_total = 201\n\tnum_nodes_total = 1751\n\tmax_num_nodes_per_graph = 9\n\tmin_num_nodes_per_graph = 1\n\tstd_num_nodes_per_graph = 0.9443829267824616\n\tmean_num_nodes_per_graph = 8.711442786069652\n\tnum_edges_total = 3748\n\tmax_num_edges_per_graph = 26\n\tmin_num_edges_per_graph = 0\n\tstd_num_edges_per_graph = 3.0647412282392468\n\tmean_num_edges_per_graph = 18.64676616915423\n-------------------\n\n</pre> <pre>Testing: 0it [00:00, ?it/s]</pre> <pre>[17:18:40.730] [poptorch:cpp] [warning] Graph contains an unused input %this_input : Long(1, strides=[1], requires_grad=0, device=cpu)\nGraph compilation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:01&lt;00:00]\nException in thread SockSrvRdThr:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n    self.run()\n  File \"/home/dom/.venv/goli_ipu/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 113, in run\n    shandler(sreq)\n  File \"/home/dom/.venv/goli_ipu/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 172, in server_record_publish\n    iface = self._mux.get_stream(stream_id).interface\n  File \"/home/dom/.venv/goli_ipu/lib/python3.8/site-packages/wandb/sdk/service/streams.py\", line 186, in get_stream\n    stream = self._streams[stream_id]\nKeyError: '1ss172i9'\n</pre> <pre>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n       Test metric             DataLoader 0\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  alpha/MSELossIPU/test     1.0208719968795776\n     alpha/loss/test        1.0208719968795776\n     alpha/mae/test         0.5369145274162292\n  alpha/mean_pred/test     -0.043575093150138855\n alpha/mean_target/test     -0.1731886863708496\n alpha/median_pred/test    0.020035069435834885\nalpha/median_target/test     -0.05999755859375\n   alpha/pearsonr/test      0.6431294679641724\n   alpha/std_pred/test      0.6613938808441162\n  alpha/std_target/test     1.2930139303207397\n   cv/MSELossIPU/test       0.7984611392021179\n      cv/loss/test          0.7984611392021179\n       cv/mae/test          0.5717160701751709\n    cv/mean_pred/test      -0.06430188566446304\n   cv/mean_target/test     -0.08974086493253708\n   cv/median_pred/test     0.014351803809404373\n  cv/median_target/test      -0.06439208984375\n    cv/pearsonr/test         0.663591742515564\n    cv/std_pred/test         0.63597571849823\n   cv/std_target/test        1.180733561515808\n  homo/MSELossIPU/test       1.14460027217865\n     homo/loss/test          1.14460027217865\n      homo/mae/test         0.7968456149101257\n   homo/mean_pred/test     0.004068718757480383\n  homo/mean_target/test     0.1092241033911705\n  homo/median_pred/test    0.0017465166747570038\n homo/median_target/test      0.1390380859375\n   homo/pearsonr/test       0.1387491226196289\n   homo/std_pred/test       0.2090565264225006\n  homo/std_target/test       1.07249116897583\n        loss/test           0.9879778027534485\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</pre> Out[21]: <pre>[{'homo/mean_pred/test': 0.004068718757480383,\n  'homo/std_pred/test': 0.2090565264225006,\n  'homo/median_pred/test': 0.0017465166747570038,\n  'homo/mean_target/test': 0.1092241033911705,\n  'homo/std_target/test': 1.07249116897583,\n  'homo/median_target/test': 0.1390380859375,\n  'homo/mae/test': 0.7968456149101257,\n  'homo/pearsonr/test': 0.1387491226196289,\n  'homo/MSELossIPU/test': 1.14460027217865,\n  'homo/loss/test': 1.14460027217865,\n  'alpha/mean_pred/test': -0.043575093150138855,\n  'alpha/std_pred/test': 0.6613938808441162,\n  'alpha/median_pred/test': 0.020035069435834885,\n  'alpha/mean_target/test': -0.1731886863708496,\n  'alpha/std_target/test': 1.2930139303207397,\n  'alpha/median_target/test': -0.05999755859375,\n  'alpha/mae/test': 0.5369145274162292,\n  'alpha/pearsonr/test': 0.6431294679641724,\n  'alpha/MSELossIPU/test': 1.0208719968795776,\n  'alpha/loss/test': 1.0208719968795776,\n  'cv/mean_pred/test': -0.06430188566446304,\n  'cv/std_pred/test': 0.63597571849823,\n  'cv/median_pred/test': 0.014351803809404373,\n  'cv/mean_target/test': -0.08974086493253708,\n  'cv/std_target/test': 1.180733561515808,\n  'cv/median_target/test': -0.06439208984375,\n  'cv/mae/test': 0.5717160701751709,\n  'cv/pearsonr/test': 0.663591742515564,\n  'cv/MSELossIPU/test': 0.7984611392021179,\n  'cv/loss/test': 0.7984611392021179,\n  'loss/test': 0.9879778027534485}]</pre>"},{"location":"tutorials/model_training/ipu_training.html#building-and-training-on-ipu-from-configurations","title":"Building and training on IPU from configurations\u00b6","text":"<p>This tutorial will walk you through how to use a configuration file to define all the parameters of a model and of the trainer. This tutorial focuses on training from SMILES data in a CSV format.</p> <p>There are multiple examples of YAML files located in the folder <code>goli/expts</code> that one can refer to when training a new model. The file <code>docs/tutorials/model_training/config_ipu_tutorials.yaml</code> shows an example of multi-task regression from a CSV file provided by goli.</p> <p>If you are not familiar with PyTorch or PyTorch-Lightning, we highly recommend going through their tutorial first.</p>"},{"location":"tutorials/model_training/ipu_training.html#the-ipu-config-file","title":"The ipu config file\u00b6","text":"<p>The IPU config file can be found at <code>expts/configs/ipu.config</code>. And is given below.</p>"},{"location":"tutorials/model_training/ipu_training.html#creating-the-yaml-file","title":"Creating the yaml file\u00b6","text":"<p>The first step is to create a YAML file containing all the required configurations, with an example given at <code>goli/docs/tutorials/model_training/config_ipu_tutorials.yaml</code>. We will go through each part of the configurations.</p>"},{"location":"tutorials/model_training/ipu_training.html#constants","title":"Constants\u00b6","text":"<p>First, we define the constants such as the random seed and whether the model should raise or ignore an error. The <code>name</code> here will be used to log the metrics into WandB and log the models. The <code>accelerator</code> is used to define the device. It supports <code>cpu</code>, <code>ipu</code> or <code>gpu</code>. This is the only part that needs to change when working with IPUs.</p>"},{"location":"tutorials/model_training/ipu_training.html#datamodule","title":"Datamodule\u00b6","text":"<p>Here, we define all the parameters required by the datamodule to run correctly, such as the dataset path, whether to cache, the columns for the training, the molecular featurization to use, the train/val/test splits and the batch size.</p> <p>The <code>MultitaskFromSmilesDataModule</code> allows us to define a set of tasks within different CSV or parquet files, and use them to train the model simultaneously via the path <code>datamodule: args: task_specific_args</code></p> <p>For more details, see class <code>goli.data.datamodule.MultitaskFromSmilesDataModule</code></p>"},{"location":"tutorials/model_training/ipu_training.html#reading-a-csv-file-and-trainvaltest-splits","title":"Reading a CSV file and train/val/test splits\u00b6","text":"<p>Here is an example of configuration regarding the task named \"homo\", which reads the file located in <code>https://storage.googleapis.com/goli-public/datasets/QM9/norm_mini_qm9.csv</code> , selects the columns \"homo\" and \"lumo\", and splits into validation and test set with rations of 20% each</p>"},{"location":"tutorials/model_training/ipu_training.html#featurizing-a-molecule","title":"Featurizing a molecule\u00b6","text":"<p>Molecules can be featurized using various properties and positional / structural encoding. A list of all features is available here:</p> <ul> <li><code>goli.features.featurizer.get_mol_atomic_features_onehot</code></li> <li><code>goli.features.featurizer.get_mol_atomic_features_float</code></li> <li><code>goli.features.featurizer.get_mol_edge_features</code></li> <li><code>goli.features.spectral.compute_laplacian_positional_eigvecs</code></li> <li><code>goli.features.rw.compute_rwse</code></li> </ul> <p>Example of a configuration for featurization below. Notice the list of atomic and edge properties. Notice <code>pos_encoding_as_features</code> that defines both the laplacian and random-walk positional encodings.</p>"},{"location":"tutorials/model_training/ipu_training.html#architecture","title":"Architecture\u00b6","text":"<p>In the architecture, we define all the layers for the model, including the layers for the pre-processing MLP (input layers <code>pre-nn</code>), the post-processing MLP (output layers <code>post-nn</code>), and the main GNN (graph neural network <code>gnn</code>).</p> <p>The parameters allow to chose the feature size, the depth, the skip connections, the pooling and the virtual node. It also support different GNN layers such as <code>pyg:gcn</code>, <code>pyg:gin</code>, <code>pyg:gine</code>,  <code>pyg:gated-gcn</code>, <code>pyg:pna-msgpass</code>, and <code>pyg:gps</code>.</p> <p>For more details, see the following classes:</p> <ul> <li><code>goli.nn.global_architecture.FullGraphNetwork</code>: Main class for the architecture</li> <li><code>goli.nn.global_architecture.FeedForwardNN</code>: Main class for the inputs and outputs MLP</li> <li><code>goli.nn.pyg_architecture.FeedForwardPyg</code>: Main class for the GNN layers</li> </ul>"},{"location":"tutorials/model_training/ipu_training.html#parameters-for-the-node-pre-processing-nn","title":"Parameters for the node pre-processing NN\u00b6","text":""},{"location":"tutorials/model_training/ipu_training.html#parameters-for-the-edge-pre-processing-nn","title":"Parameters for the edge pre-processing NN\u00b6","text":""},{"location":"tutorials/model_training/ipu_training.html#parameters-for-the-gnn","title":"Parameters for the GNN\u00b6","text":"<p>Here is an example of a GraphGPS layer, with it's MPNN being a GINE model</p>"},{"location":"tutorials/model_training/ipu_training.html#parameters-for-the-node-post-processing-nn-after-the-gnn","title":"Parameters for the node post-processing NN (after the GNN)\u00b6","text":""},{"location":"tutorials/model_training/ipu_training.html#parameters-for-the-multi-task-output-heads","title":"Parameters for the multi-task output heads\u00b6","text":"<p>Here is the example for the task heads. Notice that <code>\"task_name\"</code> should match the tasks in the section <code>datamodule: args: task_specific_args</code>.</p>"},{"location":"tutorials/model_training/ipu_training.html#predictor","title":"Predictor\u00b6","text":"<p>In the predictor, we define the loss functions, the metrics to track on the progress bar, and all the parameters necessary for the optimizer.</p> <p>Again, each of these arguments depend on the task. And the <code>task_name</code> should match the ones from <code>datamodule: args: task_specific_args</code></p>"},{"location":"tutorials/model_training/ipu_training.html#metrics","title":"Metrics\u00b6","text":"<p>All the metrics can be defined there. If we want to use a classification metric, we can also define a threshold.</p> <p>See class <code>goli.trainer.metrics.MetricWrapper</code> for more details.</p> <p>See <code>goli.trainer.metrics.METRICS_CLASSIFICATION</code> and <code>goli.trainer.metrics.METRICS_REGRESSION</code> for a dictionnary of accepted metrics.</p> <p>Again, the metrics are task-dependant and must match the names in <code>datamodule: args: task_specific_args</code></p>"},{"location":"tutorials/model_training/ipu_training.html#trainer","title":"Trainer\u00b6","text":"<p>Finally, the Trainer defines the parameters for the number of epochs to train, the checkpoints, and the patience.</p>"},{"location":"tutorials/model_training/ipu_training.html#training-the-model","title":"Training the model\u00b6","text":"<p>Now that we defined all the configuration files, we want to train the model. The steps are fairly easy using the config loaders, and are given below.</p>"},{"location":"tutorials/model_training/ipu_training.html#first-lets-do-our-imports","title":"First, let's do our imports\u00b6","text":""},{"location":"tutorials/model_training/ipu_training.html#then-lets-load-the-configuration-file","title":"Then, let's load the configuration file\u00b6","text":""},{"location":"tutorials/model_training/ipu_training.html#now-lets-process-the-data","title":"Now let's process the data\u00b6","text":""},{"location":"tutorials/model_training/ipu_training.html#lets-build-the-architecture-metrics-and-set-up-the-trainer","title":"Let's build the architecture, metrics, and set-up the trainer\u00b6","text":""},{"location":"tutorials/model_training/ipu_training.html#finally-lets-run-the-model","title":"Finally, let's run the model\u00b6","text":""},{"location":"tutorials/model_training/ipu_training.html#testing-the-model","title":"Testing the model\u00b6","text":"<p>Once the model is trained, we can use the same datamodule to get the results on the test set. Here, <code>ckpt_path</code> refers to the checkpoint path where the model at the best validation step was saved. Thus, the results on the test set represent the early stopping.</p> <p>All the metrics that were computed on the validation set are then computed on the test set, printed, and saved into the <code>metrics.yaml</code> file.</p>"},{"location":"tutorials/model_training/ipu_training_demo.html","title":"General imports","text":"In\u00a0[\u00a0]: Copied! <pre># General imports\nimport os\nfrom os.path import dirname, abspath\nimport yaml\nfrom copy import deepcopy\nfrom omegaconf import DictConfig\nimport timeit\nfrom loguru import logger\nfrom pytorch_lightning.utilities.model_summary import ModelSummary\n</pre> # General imports import os from os.path import dirname, abspath import yaml from copy import deepcopy from omegaconf import DictConfig import timeit from loguru import logger from pytorch_lightning.utilities.model_summary import ModelSummary In\u00a0[\u00a0]: Copied! <pre># Current project imports\nimport goli\nfrom goli.config._loader import load_datamodule, load_metrics, load_architecture, load_predictor, load_trainer\nfrom goli.utils.safe_run import SafeRun\n</pre> # Current project imports import goli from goli.config._loader import load_datamodule, load_metrics, load_architecture, load_predictor, load_trainer from goli.utils.safe_run import SafeRun <p>from torch_geometric.nn.aggr import Aggregation Aggregation.set_validate_args(False)</p> In\u00a0[\u00a0]: Copied! <pre># WandB\nimport wandb\n</pre> # WandB import wandb In\u00a0[\u00a0]: Copied! <pre># Set up the working directory\nMAIN_DIR = dirname(dirname(abspath(goli.__file__)))\n# CONFIG_FILE= \"expts/configs/config_ipu_allsizes.yaml\"\nCONFIG_FILE = \"docs/tutorials/model_training/config_ipu_tutorials.yaml\"\nos.chdir(MAIN_DIR)\n</pre> # Set up the working directory MAIN_DIR = dirname(dirname(abspath(goli.__file__))) # CONFIG_FILE= \"expts/configs/config_ipu_allsizes.yaml\" CONFIG_FILE = \"docs/tutorials/model_training/config_ipu_tutorials.yaml\" os.chdir(MAIN_DIR) In\u00a0[\u00a0]: Copied! <pre>with open(os.path.join(MAIN_DIR, CONFIG_FILE), \"r\") as f:\n    cfg = yaml.safe_load(f)\n</pre> with open(os.path.join(MAIN_DIR, CONFIG_FILE), \"r\") as f:     cfg = yaml.safe_load(f) In\u00a0[\u00a0]: Copied! <pre># Load and initialize the dataset\ndatamodule = load_datamodule(cfg)\ndatamodule.prepare_data()\n</pre> # Load and initialize the dataset datamodule = load_datamodule(cfg) datamodule.prepare_data() In\u00a0[\u00a0]: Copied! <pre># Initialize the network\nmodel_class, model_kwargs = load_architecture(\n    cfg,\n    in_dims=datamodule.in_dims,\n)\n</pre> # Initialize the network model_class, model_kwargs = load_architecture(     cfg,     in_dims=datamodule.in_dims, ) In\u00a0[\u00a0]: Copied! <pre>metrics = load_metrics(cfg)\nlogger.info(metrics)\n</pre> metrics = load_metrics(cfg) logger.info(metrics) In\u00a0[\u00a0]: Copied! <pre>predictor = load_predictor(cfg, model_class, model_kwargs, metrics)\npredictor.set_max_nodes_edges_per_graph(datamodule, stages=[\"train\", \"val\"])\n</pre> predictor = load_predictor(cfg, model_class, model_kwargs, metrics) predictor.set_max_nodes_edges_per_graph(datamodule, stages=[\"train\", \"val\"]) In\u00a0[\u00a0]: Copied! <pre>logger.info(predictor.model)\nlogger.info(ModelSummary(predictor, max_depth=4))\n</pre> logger.info(predictor.model) logger.info(ModelSummary(predictor, max_depth=4)) In\u00a0[\u00a0]: Copied! <pre>trainer = load_trainer(cfg, \"tutorial-run\")\n</pre> trainer = load_trainer(cfg, \"tutorial-run\") In\u00a0[\u00a0]: Copied! <pre># Run the model training\nwith SafeRun(name=\"TRAINING\", raise_error=cfg[\"constants\"][\"raise_train_error\"], verbose=True):\n    trainer.fit(model=predictor, datamodule=datamodule)\n</pre> # Run the model training with SafeRun(name=\"TRAINING\", raise_error=cfg[\"constants\"][\"raise_train_error\"], verbose=True):     trainer.fit(model=predictor, datamodule=datamodule) In\u00a0[\u00a0]: Copied! <pre># Exit WandB\nwandb.finish()\n</pre> # Exit WandB wandb.finish()"},{"location":"tutorials/model_training/simple-molecular-model.html","title":"Building and training a simple model from configurations","text":"In\u00a0[1]: Copied! <pre>import yaml\nimport omegaconf\n</pre> import yaml import omegaconf In\u00a0[2]: Copied! <pre>def print_config_with_key(config, key):\n    new_config = {key: config[key]}\n    print(omegaconf.OmegaConf.to_yaml(new_config))\n</pre> def print_config_with_key(config, key):     new_config = {key: config[key]}     print(omegaconf.OmegaConf.to_yaml(new_config)) In\u00a0[3]: Copied! <pre># First, let's read the yaml configuration file\nwith open(\"../../../expts/config_micro_ZINC.yaml\", \"r\") as file:\n    yaml_config = yaml.load(file, Loader=yaml.FullLoader)\n\nprint(\"Yaml file loaded\")\n</pre> # First, let's read the yaml configuration file with open(\"../../../expts/config_micro_ZINC.yaml\", \"r\") as file:     yaml_config = yaml.load(file, Loader=yaml.FullLoader)  print(\"Yaml file loaded\") <pre>Yaml file loaded\n</pre> In\u00a0[4]: Copied! <pre>print_config_with_key(yaml_config, \"constants\")\n</pre> print_config_with_key(yaml_config, \"constants\") <pre>constants:\n  seed: 42\n  raise_train_error: true\n\n</pre> In\u00a0[5]: Copied! <pre>print_config_with_key(yaml_config, \"datamodule\")\n</pre> print_config_with_key(yaml_config, \"datamodule\") <pre>datamodule:\n  module_type: DGLFromSmilesDataModule\n  args:\n    df_path: goli/data/micro_ZINC/micro_ZINC.csv\n    cache_data_path: goli/data/cache/micro_ZINC/full.cache\n    label_cols:\n    - score\n    smiles_col: SMILES\n    featurization_n_jobs: -1\n    featurization_progress: true\n    featurization:\n      atom_property_list_onehot:\n      - atomic-number\n      - valence\n      atom_property_list_float:\n      - mass\n      - electronegativity\n      - in-ring\n      edge_property_list:\n      - bond-type-onehot\n      - stereo\n      - in-ring\n      add_self_loop: false\n      explicit_H: false\n      use_bonds_weights: false\n      pos_encoding_as_features:\n        pos_type: laplacian_eigvec\n        num_pos: 3\n        normalization: none\n        disconnected_comp: true\n      pos_encoding_as_directions:\n        pos_type: laplacian_eigvec\n        num_pos: 3\n        normalization: none\n        disconnected_comp: true\n    split_val: 0.2\n    split_test: 0.2\n    split_seed: 42\n    splits_path: null\n    batch_size_training: 128\n    batch_size_inference: 128\n    num_workers: 0\n    pin_memory: false\n    persistent_workers: false\n\n</pre> In\u00a0[6]: Copied! <pre>print_config_with_key(yaml_config, \"architecture\")\n</pre> print_config_with_key(yaml_config, \"architecture\") <pre>architecture:\n  model_type: fulldglnetwork\n  pre_nn:\n    out_dim: 32\n    hidden_dims: 32\n    depth: 1\n    activation: relu\n    last_activation: none\n    dropout: 0.1\n    normalization: batch_norm\n    last_normalization: batch_norm\n    residual_type: none\n  pre_nn_edges:\n    out_dim: 16\n    hidden_dims: 16\n    depth: 2\n    activation: relu\n    last_activation: none\n    dropout: 0.1\n    normalization: batch_norm\n    last_normalization: batch_norm\n    residual_type: none\n  gnn:\n    out_dim: 32\n    hidden_dims: 32\n    depth: 4\n    activation: relu\n    last_activation: none\n    dropout: 0.1\n    normalization: batch_norm\n    last_normalization: batch_norm\n    residual_type: simple\n    pooling:\n    - sum\n    - max\n    - dir1\n    virtual_node: sum\n    layer_type: dgn-msgpass\n    layer_kwargs:\n      aggregators:\n      - mean\n      - max\n      - dir1/dx_abs\n      - dir1/smooth\n      scalers:\n      - identity\n      - amplification\n      - attenuation\n  post_nn:\n    out_dim: 1\n    hidden_dims: 32\n    depth: 2\n    activation: relu\n    last_activation: none\n    dropout: 0.1\n    normalization: batch_norm\n    last_normalization: none\n    residual_type: none\n\n</pre> In\u00a0[7]: Copied! <pre>print_config_with_key(yaml_config, \"predictor\")\n</pre> print_config_with_key(yaml_config, \"predictor\") <pre>predictor:\n  metrics_on_progress_bar:\n  - mae\n  - pearsonr\n  - f1 &gt; 3\n  - precision &gt; 3\n  loss_fun: mse\n  random_seed: 42\n  optim_kwargs:\n    lr: 0.01\n    weight_decay: 1.0e-07\n  lr_reduce_on_plateau_kwargs:\n    factor: 0.5\n    patience: 7\n  scheduler_kwargs:\n    monitor: loss/val\n    frequency: 1\n  target_nan_mask: 0\n\n</pre> In\u00a0[8]: Copied! <pre>print_config_with_key(yaml_config, \"metrics\")\n</pre> print_config_with_key(yaml_config, \"metrics\") <pre>metrics:\n- name: mae\n  metric: mae\n  threshold_kwargs: null\n- name: pearsonr\n  metric: pearsonr\n  threshold_kwargs: null\n- name: f1 &gt; 3\n  metric: f1\n  num_classes: 2\n  average: micro\n  threshold_kwargs:\n    operator: greater\n    threshold: 3\n    th_on_preds: true\n    th_on_target: true\n    target_to_int: true\n- name: f1 &gt; 5\n  metric: f1\n  num_classes: 2\n  average: micro\n  threshold_kwargs:\n    operator: greater\n    threshold: 5\n    th_on_preds: true\n    th_on_target: true\n    target_to_int: true\n- name: precision &gt; 3\n  metric: precision\n  average: micro\n  threshold_kwargs:\n    operator: greater\n    threshold: 3\n    th_on_preds: true\n    th_on_target: true\n    target_to_int: true\n\n</pre> In\u00a0[9]: Copied! <pre>print_config_with_key(yaml_config, \"trainer\")\n</pre> print_config_with_key(yaml_config, \"trainer\") <pre>trainer:\n  logger:\n    save_dir: logs/micro_ZINC\n  early_stopping:\n    monitor: loss/val\n    min_delta: 0\n    patience: 10\n    mode: min\n  model_checkpoint:\n    dirpath: models_checkpoints/micro_ZINC/\n    filename: model\n    monitor: loss/val\n    mode: min\n    save_top_k: 1\n    every_n_epochs: 1\n  trainer:\n    max_epochs: 25\n    min_epochs: 5\n    gpus: 1\n\n</pre> In\u00a0[10]: Copied! <pre>from os.path import dirname, abspath\nfrom copy import deepcopy\n\nimport goli\nfrom goli.config._loader import (load_datamodule, load_metrics, load_architecture, load_predictor, load_trainer)\n\nMAIN_DIR = dirname(dirname(abspath(goli.__file__)))\nos.chdir(MAIN_DIR)\n\ncfg = dict(deepcopy(yaml_config))\n\n# Load and initialize the dataset\ndatamodule = load_datamodule(cfg)\nprint(\"\\ndatamodule:\\n\", datamodule, \"\\n\")\n\n# Initialize the network\nmodel_class, model_kwargs = load_architecture(\n    cfg,\n    in_dim_nodes=datamodule.num_node_feats_with_positional_encoding,\n    in_dim_edges=datamodule.num_edge_feats,\n)\n\n# Load and print the metrics\nmetrics = load_metrics(cfg)\nprint(metrics)\n\n# Load the predictor, print the model, and print a summary of the number of parameters\npredictor = load_predictor(cfg, model_class, model_kwargs, metrics)\nprint(predictor.model)\nprint(predictor.summarize(max_depth=4))\n\n# Load the trainer, and start the training\ntrainer = load_trainer(cfg)\ntrainer.fit(model=predictor, datamodule=datamodule)\n</pre> from os.path import dirname, abspath from copy import deepcopy  import goli from goli.config._loader import (load_datamodule, load_metrics, load_architecture, load_predictor, load_trainer)  MAIN_DIR = dirname(dirname(abspath(goli.__file__))) os.chdir(MAIN_DIR)  cfg = dict(deepcopy(yaml_config))  # Load and initialize the dataset datamodule = load_datamodule(cfg) print(\"\\ndatamodule:\\n\", datamodule, \"\\n\")  # Initialize the network model_class, model_kwargs = load_architecture(     cfg,     in_dim_nodes=datamodule.num_node_feats_with_positional_encoding,     in_dim_edges=datamodule.num_edge_feats, )  # Load and print the metrics metrics = load_metrics(cfg) print(metrics)  # Load the predictor, print the model, and print a summary of the number of parameters predictor = load_predictor(cfg, model_class, model_kwargs, metrics) print(predictor.model) print(predictor.summarize(max_depth=4))  # Load the trainer, and start the training trainer = load_trainer(cfg) trainer.fit(model=predictor, datamodule=datamodule) <pre>Using backend: pytorch\nc:\\users\\domin\\documents\\gits\\goli_windows\\goli\\features\\spectral.py:43: ComplexWarning: Casting complex values to real discards the imaginary part\n  eigvecs[comp, :] = this_eigvecs\nc:\\users\\domin\\documents\\gits\\goli_windows\\goli\\features\\spectral.py:44: ComplexWarning: Casting complex values to real discards the imaginary part\n  eigvals_tile[comp, :] = this_eigvals\n2021-06-24 14:39:46.691 | WARNING  | goli.config._loader:load_trainer:126 - Number of GPUs selected is `1`, but will be ignored since no GPU are available on this device\n\ndatamodule:\n name: DGLFromSmilesDataModule\nlen: 1000\ntrain_size: null\nval_size: null\ntest_size: null\nbatch_size_training: 128\nbatch_size_inference: 128\nnum_node_feats: 55\nnum_node_feats_with_positional_encoding: 58\nnum_edge_feats: 13\nnum_labels: 1\ncollate_fn: goli_collate_fn\nfeaturization:\n  atom_property_list_onehot:\n  - atomic-number\n  - valence\n  atom_property_list_float:\n  - mass\n  - electronegativity\n  - in-ring\n  edge_property_list:\n  - bond-type-onehot\n  - stereo\n  - in-ring\n  add_self_loop: false\n  explicit_H: false\n  use_bonds_weights: false\n  pos_encoding_as_features:\n    pos_type: laplacian_eigvec\n    num_pos: 3\n    normalization: none\n    disconnected_comp: true\n  pos_encoding_as_directions:\n    pos_type: laplacian_eigvec\n    num_pos: 3\n    normalization: none\n    disconnected_comp: true\n \n\n{'mae': mean_absolute_error, 'pearsonr': pearsonr, 'f1 &gt; 3': f1(&gt;3), 'f1 &gt; 5': f1(&gt;5), 'precision &gt; 3': precision(&gt;3)}\nDGL_GNN\n---------\n    pre-NN(depth=1, ResidualConnectionNone)\n        [FCLayer[58 -&gt; 32]\n    \n    pre-NN-edges(depth=2, ResidualConnectionNone)\n        [FCLayer[13 -&gt; 16 -&gt; 16]\n    \n    GNN(depth=4, ResidualConnectionSimple(skip_steps=1))\n        DGNMessagePassingLayer[32 -&gt; 32 -&gt; 32 -&gt; 32 -&gt; 32]\n        -&gt; Pooling(['sum', 'max', 'dir1']) -&gt; FCLayer(96 -&gt; 32, activation=None)\n    \n    post-NN(depth=2, ResidualConnectionNone)\n        [FCLayer[32 -&gt; 32 -&gt; 1]\n   | Name                              | Type                     | Params\n--------------------------------------------------------------------------------\n0  | model                             | FullDGLNetwork           | 74.4 K\n1  | model.pre_nn                      | FeedForwardNN            | 2.0 K \n2  | model.pre_nn.activation           | ReLU                     | 0     \n3  | model.pre_nn.residual_layer       | ResidualConnectionNone   | 0     \n4  | model.pre_nn.layers               | ModuleList               | 2.0 K \n5  | model.pre_nn.layers.0             | FCLayer                  | 2.0 K \n6  | model.pre_nn_edges                | FeedForwardNN            | 560   \n7  | model.pre_nn_edges.activation     | ReLU                     | 0     \n8  | model.pre_nn_edges.residual_layer | ResidualConnectionNone   | 0     \n9  | model.pre_nn_edges.layers         | ModuleList               | 560   \n10 | model.pre_nn_edges.layers.0       | FCLayer                  | 256   \n11 | model.pre_nn_edges.layers.1       | FCLayer                  | 304   \n12 | model.gnn                         | FeedForwardDGL           | 70.8 K\n13 | model.gnn.activation              | ReLU                     | 0     \n14 | model.gnn.layers                  | ModuleList               | 64.3 K\n15 | model.gnn.layers.0                | DGNMessagePassingLayer   | 16.1 K\n16 | model.gnn.layers.1                | DGNMessagePassingLayer   | 16.1 K\n17 | model.gnn.layers.2                | DGNMessagePassingLayer   | 16.1 K\n18 | model.gnn.layers.3                | DGNMessagePassingLayer   | 16.1 K\n19 | model.gnn.virtual_node_layers     | ModuleList               | 3.4 K \n20 | model.gnn.virtual_node_layers.0   | VirtualNode              | 1.1 K \n21 | model.gnn.virtual_node_layers.1   | VirtualNode              | 1.1 K \n22 | model.gnn.virtual_node_layers.2   | VirtualNode              | 1.1 K \n23 | model.gnn.residual_layer          | ResidualConnectionSimple | 0     \n24 | model.gnn.global_pool_layer       | ModuleListConcat         | 0     \n25 | model.gnn.global_pool_layer.0     | SumPooling               | 0     \n26 | model.gnn.global_pool_layer.1     | MaxPooling               | 0     \n27 | model.gnn.global_pool_layer.2     | DirPooling               | 0     \n28 | model.gnn.out_linear              | FCLayer                  | 3.2 K \n29 | model.gnn.out_linear.linear       | Linear                   | 3.1 K \n30 | model.gnn.out_linear.normalization         | BatchNorm1d              | 64    \n31 | model.gnn.out_linear.dropout      | Dropout                  | 0     \n32 | model.post_nn                     | FeedForwardNN            | 1.2 K \n33 | model.post_nn.activation          | ReLU                     | 0     \n34 | model.post_nn.residual_layer      | ResidualConnectionNone   | 0     \n35 | model.post_nn.layers              | ModuleList               | 1.2 K \n36 | model.post_nn.layers.0            | FCLayer                  | 1.1 K \n37 | model.post_nn.layers.1            | FCLayer                  | 33    \n38 | loss_fun                          | MSELoss                  | 0     \n--------------------------------------------------------------------------------\n74.4 K    Trainable params\n0         Non-trainable params\n74.4 K    Total params\n0.298     Total estimated model params size (MB)\nC:\\Users\\Domin\\miniconda3\\envs\\goli\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: Checkpoint directory models_checkpoints/micro_ZINC/ exists and is not empty.\n  warnings.warn(*args, **kwargs)\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\n2021-06-24 14:39:46.714 | INFO     | goli.data.datamodule:_load_from_cache:567 - Try reloading the data module from goli/data/cache/micro_ZINC/full.cache.\n2021-06-24 14:40:42.701 | INFO     | goli.data.datamodule:_load_from_cache:605 - Datamodule correctly reloaded from cache.\nC:\\Users\\Domin\\miniconda3\\envs\\goli\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: RuntimeWarning: Found unsupported keys in the lr scheduler dict: ['mode']\n  warnings.warn(*args, **kwargs)\n\n  | Name     | Type           | Params\n--------------------------------------------\n0 | model    | FullDGLNetwork | 74.4 K\n1 | loss_fun | MSELoss        | 0     \n--------------------------------------------\n74.4 K    Trainable params\n0         Non-trainable params\n74.4 K    Total params\n0.298     Total estimated model params size (MB)\nValidation sanity check:   0%|          | 0/2 [00:00&lt;?, ?it/s]C:\\Users\\Domin\\miniconda3\\envs\\goli\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  warnings.warn(*args, **kwargs)\nEpoch 0:   0%|          | 0/7 [00:00&lt;?, ?it/s] C:\\Users\\Domin\\miniconda3\\envs\\goli\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  warnings.warn(*args, **kwargs)\nEpoch 0:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 5/7 [00:02&lt;00:00,  2.17it/s, loss=3.97, v_num=18, loss/val=3.110, mae/val=1.390, pearsonr/val=-2.68e-6, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nEpoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.67it/s, loss=3.97, v_num=18, loss/val=3.110, mae/val=1.390, pearsonr/val=-2.68e-6, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.47it/s, loss=3.97, v_num=18, loss/val=5.480, mae/val=1.920, pearsonr/val=-.244, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]   \nEpoch 1:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.63it/s, loss=3.62, v_num=18, loss/val=5.480, mae/val=1.920, pearsonr/val=-.244, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  4.17it/s]\nEpoch 1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.53it/s, loss=3.62, v_num=18, loss/val=2.980, mae/val=1.370, pearsonr/val=0.137, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 2:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.40it/s, loss=3.32, v_num=18, loss/val=2.980, mae/val=1.370, pearsonr/val=0.137, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  2.59it/s]\nEpoch 2: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:03&lt;00:00,  2.15it/s, loss=3.32, v_num=18, loss/val=3.850, mae/val=1.490, pearsonr/val=0.457, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 3:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.52it/s, loss=3.09, v_num=18, loss/val=3.850, mae/val=1.490, pearsonr/val=0.457, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.81it/s]\nEpoch 3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.46it/s, loss=3.09, v_num=18, loss/val=7.770, mae/val=2.380, pearsonr/val=0.548, f1 &gt; 3/val=0.0476, precision &gt; 3/val=nan.0]\nEpoch 4:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.82it/s, loss=2.56, v_num=18, loss/val=7.770, mae/val=2.380, pearsonr/val=0.548, f1 &gt; 3/val=0.0476, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  4.02it/s]\nEpoch 4: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.70it/s, loss=2.56, v_num=18, loss/val=2.720, mae/val=1.250, pearsonr/val=0.693, f1 &gt; 3/val=0.167, precision &gt; 3/val=nan.0] \nEpoch 5:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.62it/s, loss=2.14, v_num=18, loss/val=2.720, mae/val=1.250, pearsonr/val=0.693, f1 &gt; 3/val=0.167, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.45it/s]\nEpoch 5: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.49it/s, loss=2.14, v_num=18, loss/val=2.130, mae/val=1.140, pearsonr/val=0.753, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 6:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.64it/s, loss=1.78, v_num=18, loss/val=2.130, mae/val=1.140, pearsonr/val=0.753, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  4.03it/s]\nEpoch 6: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.56it/s, loss=1.78, v_num=18, loss/val=1.780, mae/val=1.120, pearsonr/val=0.828, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 7:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.37it/s, loss=1.47, v_num=18, loss/val=1.780, mae/val=1.120, pearsonr/val=0.828, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  4.04it/s]\nEpoch 7: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.34it/s, loss=1.47, v_num=18, loss/val=2.880, mae/val=1.510, pearsonr/val=0.861, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 8:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.61it/s, loss=1.23, v_num=18, loss/val=2.880, mae/val=1.510, pearsonr/val=0.861, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.62it/s]\nEpoch 8: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.51it/s, loss=1.23, v_num=18, loss/val=6.910, mae/val=2.470, pearsonr/val=0.842, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 9:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.34it/s, loss=1.05, v_num=18, loss/val=6.910, mae/val=2.470, pearsonr/val=0.842, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.22it/s]\nEpoch 9: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:03&lt;00:00,  2.24it/s, loss=1.05, v_num=18, loss/val=5.230, mae/val=2.150, pearsonr/val=0.890, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 10:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.13it/s, loss=0.918, v_num=18, loss/val=5.230, mae/val=2.150, pearsonr/val=0.890, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.35it/s]\nEpoch 10: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:03&lt;00:00,  2.10it/s, loss=0.918, v_num=18, loss/val=9.860, mae/val=3.030, pearsonr/val=0.869, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 11:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.45it/s, loss=0.805, v_num=18, loss/val=9.860, mae/val=3.030, pearsonr/val=0.869, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.83it/s]\nEpoch 11: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.39it/s, loss=0.805, v_num=18, loss/val=4.080, mae/val=1.900, pearsonr/val=0.899, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 12:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.36it/s, loss=0.736, v_num=18, loss/val=4.080, mae/val=1.900, pearsonr/val=0.899, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.51it/s]\nEpoch 12: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:03&lt;00:00,  2.27it/s, loss=0.736, v_num=18, loss/val=1.540, mae/val=1.100, pearsonr/val=0.934, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 13:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.37it/s, loss=0.694, v_num=18, loss/val=1.540, mae/val=1.100, pearsonr/val=0.934, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.66it/s]\nEpoch 13: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:03&lt;00:00,  2.30it/s, loss=0.694, v_num=18, loss/val=1.140, mae/val=0.928, pearsonr/val=0.927, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 14:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.55it/s, loss=0.662, v_num=18, loss/val=1.140, mae/val=0.928, pearsonr/val=0.927, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.63it/s]\nEpoch 14: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.45it/s, loss=0.662, v_num=18, loss/val=0.830, mae/val=0.711, pearsonr/val=0.908, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 15:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.61it/s, loss=0.658, v_num=18, loss/val=0.830, mae/val=0.711, pearsonr/val=0.908, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  4.09it/s]\nEpoch 15: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.54it/s, loss=0.658, v_num=18, loss/val=0.476, mae/val=0.527, pearsonr/val=0.930, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 16:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.63it/s, loss=0.64, v_num=18, loss/val=0.476, mae/val=0.527, pearsonr/val=0.930, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.60it/s]\nEpoch 16: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.51it/s, loss=0.64, v_num=18, loss/val=0.780, mae/val=0.727, pearsonr/val=0.924, f1 &gt; 3/val=0.400, precision &gt; 3/val=nan.0]\nEpoch 17:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.51it/s, loss=0.594, v_num=18, loss/val=0.780, mae/val=0.727, pearsonr/val=0.924, f1 &gt; 3/val=0.400, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.75it/s]\nEpoch 17: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.43it/s, loss=0.594, v_num=18, loss/val=0.593, mae/val=0.624, pearsonr/val=0.934, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 18:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.48it/s, loss=0.559, v_num=18, loss/val=0.593, mae/val=0.624, pearsonr/val=0.934, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.58it/s]\nEpoch 18: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.40it/s, loss=0.559, v_num=18, loss/val=0.846, mae/val=0.773, pearsonr/val=0.930, f1 &gt; 3/val=0.333, precision &gt; 3/val=nan.0]\nEpoch 19:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.25it/s, loss=0.515, v_num=18, loss/val=0.846, mae/val=0.773, pearsonr/val=0.930, f1 &gt; 3/val=0.333, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.82it/s]\nEpoch 19: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:03&lt;00:00,  2.24it/s, loss=0.515, v_num=18, loss/val=0.513, mae/val=0.572, pearsonr/val=0.928, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 20:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.60it/s, loss=0.491, v_num=18, loss/val=0.513, mae/val=0.572, pearsonr/val=0.928, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.61it/s]\nEpoch 20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.49it/s, loss=0.491, v_num=18, loss/val=0.559, mae/val=0.580, pearsonr/val=0.931, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 21:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.66it/s, loss=0.485, v_num=18, loss/val=0.559, mae/val=0.580, pearsonr/val=0.931, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.96it/s]\nEpoch 21: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.57it/s, loss=0.485, v_num=18, loss/val=0.380, mae/val=0.473, pearsonr/val=0.939, f1 &gt; 3/val=0.667, precision &gt; 3/val=nan.0]\nEpoch 22:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.65it/s, loss=0.471, v_num=18, loss/val=0.380, mae/val=0.473, pearsonr/val=0.939, f1 &gt; 3/val=0.667, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.69it/s]\nEpoch 22: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.55it/s, loss=0.471, v_num=18, loss/val=0.340, mae/val=0.433, pearsonr/val=0.942, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 23:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.48it/s, loss=0.467, v_num=18, loss/val=0.340, mae/val=0.433, pearsonr/val=0.942, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.96it/s]\nEpoch 23: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.43it/s, loss=0.467, v_num=18, loss/val=0.423, mae/val=0.501, pearsonr/val=0.938, f1 &gt; 3/val=0.667, precision &gt; 3/val=nan.0]\nEpoch 24:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6/7 [00:02&lt;00:00,  2.67it/s, loss=0.473, v_num=18, loss/val=0.423, mae/val=0.501, pearsonr/val=0.938, f1 &gt; 3/val=0.667, precision &gt; 3/val=nan.0]\nValidating: 0it [00:00, ?it/s]\nValidating:   0%|          | 0/2 [00:00&lt;?, ?it/s]\nValidating:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [00:00&lt;00:00,  3.97it/s]\nEpoch 24: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.59it/s, loss=0.473, v_num=18, loss/val=0.326, mae/val=0.430, pearsonr/val=0.946, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\nEpoch 24: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:02&lt;00:00,  2.53it/s, loss=0.473, v_num=18, loss/val=0.326, mae/val=0.430, pearsonr/val=0.946, f1 &gt; 3/val=0.000, precision &gt; 3/val=nan.0]\n</pre> In\u00a0[11]: Copied! <pre>ckpt_path = trainer.checkpoint_callbacks[0].best_model_path\ntrainer.test(model=predictor, datamodule=datamodule, ckpt_path=ckpt_path)\n</pre> ckpt_path = trainer.checkpoint_callbacks[0].best_model_path trainer.test(model=predictor, datamodule=datamodule, ckpt_path=ckpt_path) <pre>Testing: 0it [00:00, ?it/s]C:\\Users\\Domin\\miniconda3\\envs\\goli\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  warnings.warn(*args, **kwargs)\nTesting: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00,  3.52it/s]\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'MSELoss/test': 0.6393043398857117,\n 'f1 &gt; 3/test': 0.0,\n 'f1 &gt; 5/test': 0.0,\n 'loss/test': 0.6393043398857117,\n 'mae/test': 0.5762802362442017,\n 'mean_pred/test': -0.48094016313552856,\n 'mean_target/test': -0.6447566151618958,\n 'pearsonr/test': 0.9359009265899658,\n 'precision &gt; 3/test': nan,\n 'std_pred/test': 1.7718788385391235,\n 'std_target/test': 2.1336562633514404}\n--------------------------------------------------------------------------------\n</pre> Out[11]: <pre>[{'mean_pred/test': -0.48094016313552856,\n  'std_pred/test': 1.7718788385391235,\n  'mean_target/test': -0.6447566151618958,\n  'std_target/test': 2.1336562633514404,\n  'mae/test': 0.5762802362442017,\n  'pearsonr/test': 0.9359009265899658,\n  'f1 &gt; 3/test': 0.0,\n  'f1 &gt; 5/test': 0.0,\n  'precision &gt; 3/test': nan,\n  'MSELoss/test': 0.6393043398857117,\n  'loss/test': 0.6393043398857117}]</pre>"},{"location":"tutorials/model_training/simple-molecular-model.html#building-and-training-a-simple-model-from-configurations","title":"Building and training a simple model from configurations\u00b6","text":"<p>This tutorial will walk you through how to use a configuration file to define all the parameters of a model and of the trainer. This tutorial focuses on training from SMILES data in a CSV format.</p> <p>There are multiple examples of YAML files located in the folder <code>goli/expts</code> that one can refer to when training a new model. The file <code>config_ZINC_bench_gnn.yaml</code> shows an example of single task regression from a CSV file provided by goli. And the file <code>config_molpcba.yaml</code> shows an example of a multi-task classification on a dataset provided by OGB with some missing data.</p>"},{"location":"tutorials/model_training/simple-molecular-model.html#creating-the-yaml-file","title":"Creating the yaml file\u00b6","text":"<p>The first step is to create a YAML file containing all the required configurations, with an example given at <code>goli/expts/config_micro_ZINC.yaml</code>. We will go through each part of the configurations.</p>"},{"location":"tutorials/model_training/simple-molecular-model.html#constants","title":"Constants\u00b6","text":"<p>First, we define the constants such as the random seed and whether the model should raise or ignore an error.</p>"},{"location":"tutorials/model_training/simple-molecular-model.html#datamodule","title":"Datamodule\u00b6","text":"<p>Here, we define all the parameters required by the datamodule to run correctly, such as the dataset path, whether to cache, the columns for the training, the molecular featurization to use, the train/val/test splits and the batch size.</p> <p>For more details, see class <code>goli.data.datamodule.DGLFromSmilesDataModule</code></p>"},{"location":"tutorials/model_training/simple-molecular-model.html#architecture","title":"Architecture\u00b6","text":"<p>In the architecture, we define all the layers for the model, including the layers for the pre-processing MLP (input layers <code>pre-nn</code>), the post-processing MLP (output layers <code>post-nn</code>), and the main GNN (graph neural network <code>gnn</code>).</p> <p>The parameters allow to chose the feature size, the depth, the skip connections, the pooling and the virtual node. It also support different GNN layers such as <code>gcn</code>, <code>gin</code>, <code>gat</code>, <code>gated-gcn</code>, <code>pna-conv</code> and <code>pna-msgpass</code>.</p> <p>For more details, see the following classes:</p> <ul> <li><code>goli.nn.architecture.FullDGLNetwork</code>: Main class for the architecture</li> <li><code>goli.nn.architecture.FeedForwardNN</code>: Main class for the inputs and outputs MLP</li> <li><code>goli.nn.architecture.FeedForwardDGL</code>: Main class for the GNN layers</li> </ul>"},{"location":"tutorials/model_training/simple-molecular-model.html#predictor","title":"Predictor\u00b6","text":"<p>In the predictor, we define the loss functions, the metrics to track on the progress bar, and all the parameters necessary for the optimizer.</p>"},{"location":"tutorials/model_training/simple-molecular-model.html#metrics","title":"Metrics\u00b6","text":"<p>All the metrics can be defined there. If we want to use a classification metric, we can also define a threshold.</p> <p>See class <code>goli.trainer.metrics.MetricWrapper</code> for more details.</p> <p>See <code>goli.trainer.metrics.METRICS_CLASSIFICATION</code> and <code>goli.trainer.metrics.METRICS_REGRESSION</code> for a dictionnary of accepted metrics.</p>"},{"location":"tutorials/model_training/simple-molecular-model.html#trainer","title":"Trainer\u00b6","text":"<p>Finally, the Trainer defines the parameters for the number of epochs to train, the checkpoints, and the patience.</p>"},{"location":"tutorials/model_training/simple-molecular-model.html#training-the-model","title":"Training the model\u00b6","text":"<p>Now that we defined all the configuration files, we want to train the model. The steps are fairly easy using the config loaders, and are given below.</p>"},{"location":"tutorials/model_training/simple-molecular-model.html#testing-the-model","title":"Testing the model\u00b6","text":"<p>Once the model is trained, we can use the same datamodule to get the results on the test set. Here, <code>ckpt_path</code> refers to the checkpoint path where the model at the best validation step was saved. Thus, the results on the test set represent the early stopping.</p> <p>All the metrics that were computed on the validation set are then computed on the test set, printed, and saved into the <code>metrics.yaml</code> file.</p>"}]}